{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f8781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8264d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0fe6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcde4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "\n",
       "       11    12    13  \n",
       "0  396.90  4.98  24.0  \n",
       "1  396.90  9.14  21.6  \n",
       "2  392.83  4.03  34.7  \n",
       "3  394.63  2.94  33.4  \n",
       "4  396.90  5.33  36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"dataset/housing.csv\", delim_whitespace=True, header=None)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe565ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00, 2.4000e+01],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00, 2.1600e+01],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00, 3.4700e+01],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00, 3.3400e+01],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00, 3.6200e+01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "print(dataset.shape)\n",
    "dataset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbce0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "X = dataset[:, 0:13]\n",
    "y = dataset[:, 13]\n",
    "\n",
    "# sklearn의 train_test_split 사용해서 test 데이터 생성\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b50796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모델 선언\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))  # 입력층\n",
    "                                                       # 은닉층1\n",
    "    \n",
    "model.add(Dense(25, activation='relu'))                # 은닉층2\n",
    "model.add(Dense(15, activation='relu'))                # 은닉층3\n",
    "model.add(Dense(6, activation='relu'))                 # 은닉층4\n",
    "model.add(Dense(1))                                    # 출력층\n",
    "# 선형 회귀는 마지막에 참과 거짓을 구분할 필요가 없음. 출력층에 활성화 함수를 지정할 필요도 없음\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam', \n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed28953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_mse', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_mse', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1195484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/9 [==>...........................] - ETA: 11s - loss: 254.9194 - mse: 254.9194\n",
      "Epoch 1: val_mse improved from inf to 86.77802, saving model to ./model\\01-86.7780.hdf5\n",
      "9/9 [==============================] - 2s 44ms/step - loss: 202.1654 - mse: 202.1654 - val_loss: 86.7780 - val_mse: 86.7780\n",
      "Epoch 2/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 69.2782 - mse: 69.2782\n",
      "Epoch 2: val_mse improved from 86.77802 to 71.05354, saving model to ./model\\02-71.0535.hdf5\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 76.3943 - mse: 76.3943 - val_loss: 71.0535 - val_mse: 71.0535\n",
      "Epoch 3/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 80.8285 - mse: 80.8285\n",
      "Epoch 3: val_mse did not improve from 71.05354\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 70.4576 - mse: 70.4576 - val_loss: 72.9657 - val_mse: 72.9657\n",
      "Epoch 4/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 60.4732 - mse: 60.4732\n",
      "Epoch 4: val_mse improved from 71.05354 to 63.51756, saving model to ./model\\04-63.5176.hdf5\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 65.8633 - mse: 65.8633 - val_loss: 63.5176 - val_mse: 63.5176\n",
      "Epoch 5/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 62.7744 - mse: 62.7744\n",
      "Epoch 5: val_mse improved from 63.51756 to 56.94945, saving model to ./model\\05-56.9494.hdf5\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 61.5670 - mse: 61.5670 - val_loss: 56.9494 - val_mse: 56.9494\n",
      "Epoch 6/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 29.3154 - mse: 29.3154\n",
      "Epoch 6: val_mse improved from 56.94945 to 53.75165, saving model to ./model\\06-53.7517.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 59.9667 - mse: 59.9667 - val_loss: 53.7517 - val_mse: 53.7517\n",
      "Epoch 7/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 32.9966 - mse: 32.9966\n",
      "Epoch 7: val_mse improved from 53.75165 to 52.99246, saving model to ./model\\07-52.9925.hdf5\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 62.6310 - mse: 62.6310 - val_loss: 52.9925 - val_mse: 52.9925\n",
      "Epoch 8/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 62.2907 - mse: 62.2907\n",
      "Epoch 8: val_mse improved from 52.99246 to 51.10579, saving model to ./model\\08-51.1058.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 54.3720 - mse: 54.3720 - val_loss: 51.1058 - val_mse: 51.1058\n",
      "Epoch 9/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 89.4692 - mse: 89.4692\n",
      "Epoch 9: val_mse improved from 51.10579 to 48.23983, saving model to ./model\\09-48.2398.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 56.0030 - mse: 56.0030 - val_loss: 48.2398 - val_mse: 48.2398\n",
      "Epoch 10/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 35.0030 - mse: 35.0030\n",
      "Epoch 10: val_mse did not improve from 48.23983\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 53.7896 - mse: 53.7896 - val_loss: 51.4419 - val_mse: 51.4419\n",
      "Epoch 11/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 64.3323 - mse: 64.3323\n",
      "Epoch 11: val_mse did not improve from 48.23983\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 54.0811 - mse: 54.0811 - val_loss: 50.0979 - val_mse: 50.0979\n",
      "Epoch 12/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 115.1840 - mse: 115.1840\n",
      "Epoch 12: val_mse did not improve from 48.23983\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 51.9599 - mse: 51.9599 - val_loss: 55.5090 - val_mse: 55.5090\n",
      "Epoch 13/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 48.1956 - mse: 48.1956\n",
      "Epoch 13: val_mse did not improve from 48.23983\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 53.8637 - mse: 53.8637 - val_loss: 57.5805 - val_mse: 57.5805\n",
      "Epoch 14/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 62.0339 - mse: 62.0339\n",
      "Epoch 14: val_mse did not improve from 48.23983\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 57.1811 - mse: 57.1811 - val_loss: 59.5192 - val_mse: 59.5192\n",
      "Epoch 15/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 77.6674 - mse: 77.6674\n",
      "Epoch 15: val_mse did not improve from 48.23983\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 57.0029 - mse: 57.0029 - val_loss: 51.0156 - val_mse: 51.0156\n",
      "Epoch 16/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 37.4746 - mse: 37.4746\n",
      "Epoch 16: val_mse did not improve from 48.23983\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 51.2881 - mse: 51.2881 - val_loss: 49.9217 - val_mse: 49.9217\n",
      "Epoch 17/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.0121 - mse: 30.0121\n",
      "Epoch 17: val_mse improved from 48.23983 to 48.18997, saving model to ./model\\17-48.1900.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 49.9950 - mse: 49.9950 - val_loss: 48.1900 - val_mse: 48.1900\n",
      "Epoch 18/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 34.0531 - mse: 34.0531\n",
      "Epoch 18: val_mse improved from 48.18997 to 44.90442, saving model to ./model\\18-44.9044.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 52.5680 - mse: 52.5680 - val_loss: 44.9044 - val_mse: 44.9044\n",
      "Epoch 19/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 67.1178 - mse: 67.1178\n",
      "Epoch 19: val_mse did not improve from 44.90442\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 50.9197 - mse: 50.9197 - val_loss: 46.9782 - val_mse: 46.9782\n",
      "Epoch 20/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 58.7000 - mse: 58.7000\n",
      "Epoch 20: val_mse did not improve from 44.90442\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 51.1897 - mse: 51.1897 - val_loss: 47.8674 - val_mse: 47.8674\n",
      "Epoch 21/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 39.8527 - mse: 39.8527\n",
      "Epoch 21: val_mse did not improve from 44.90442\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 49.4912 - mse: 49.4912 - val_loss: 48.2177 - val_mse: 48.2177\n",
      "Epoch 22/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.6879 - mse: 22.6879\n",
      "Epoch 22: val_mse did not improve from 44.90442\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 47.7426 - mse: 47.7426 - val_loss: 47.0530 - val_mse: 47.0530\n",
      "Epoch 23/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.4204 - mse: 30.4204\n",
      "Epoch 23: val_mse improved from 44.90442 to 43.72709, saving model to ./model\\23-43.7271.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 49.2008 - mse: 49.2008 - val_loss: 43.7271 - val_mse: 43.7271\n",
      "Epoch 24/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 43.4162 - mse: 43.4162\n",
      "Epoch 24: val_mse did not improve from 43.72709\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 45.6786 - mse: 45.6786 - val_loss: 46.5890 - val_mse: 46.5890\n",
      "Epoch 25/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.9794 - mse: 23.9794\n",
      "Epoch 25: val_mse did not improve from 43.72709\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 46.4455 - mse: 46.4455 - val_loss: 46.3205 - val_mse: 46.3205\n",
      "Epoch 26/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 33.4438 - mse: 33.4438\n",
      "Epoch 26: val_mse improved from 43.72709 to 42.83254, saving model to ./model\\26-42.8325.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 46.8544 - mse: 46.8544 - val_loss: 42.8325 - val_mse: 42.8325\n",
      "Epoch 27/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 33.4062 - mse: 33.4062\n",
      "Epoch 27: val_mse did not improve from 42.83254\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 45.1151 - mse: 45.1151 - val_loss: 46.3961 - val_mse: 46.3961\n",
      "Epoch 28/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 48.4788 - mse: 48.4788\n",
      "Epoch 28: val_mse did not improve from 42.83254\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 45.5591 - mse: 45.5591 - val_loss: 45.8133 - val_mse: 45.8133\n",
      "Epoch 29/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 57.5042 - mse: 57.5042\n",
      "Epoch 29: val_mse did not improve from 42.83254\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 43.8513 - mse: 43.8513 - val_loss: 43.6902 - val_mse: 43.6902\n",
      "Epoch 30/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 0s - loss: 41.1587 - mse: 41.1587\n",
      "Epoch 30: val_mse improved from 42.83254 to 41.52848, saving model to ./model\\30-41.5285.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 43.5872 - mse: 43.5872 - val_loss: 41.5285 - val_mse: 41.5285\n",
      "Epoch 31/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 29.2761 - mse: 29.2761\n",
      "Epoch 31: val_mse did not improve from 41.52848\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 45.1981 - mse: 45.1981 - val_loss: 46.2281 - val_mse: 46.2281\n",
      "Epoch 32/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 67.3256 - mse: 67.3256\n",
      "Epoch 32: val_mse did not improve from 41.52848\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 44.0028 - mse: 44.0028 - val_loss: 41.7949 - val_mse: 41.7949\n",
      "Epoch 33/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.6235 - mse: 36.6235\n",
      "Epoch 33: val_mse did not improve from 41.52848\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 41.7785 - mse: 41.7785 - val_loss: 44.2024 - val_mse: 44.2024\n",
      "Epoch 34/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 53.5473 - mse: 53.5473\n",
      "Epoch 34: val_mse did not improve from 41.52848\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 40.7230 - mse: 40.7230 - val_loss: 46.2085 - val_mse: 46.2085\n",
      "Epoch 35/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 38.6456 - mse: 38.6456\n",
      "Epoch 35: val_mse did not improve from 41.52848\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 42.1778 - mse: 42.1778 - val_loss: 44.5512 - val_mse: 44.5512\n",
      "Epoch 36/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 45.7468 - mse: 45.7468\n",
      "Epoch 36: val_mse did not improve from 41.52848\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 40.4759 - mse: 40.4759 - val_loss: 41.8140 - val_mse: 41.8140\n",
      "Epoch 37/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.1096 - mse: 20.1096\n",
      "Epoch 37: val_mse improved from 41.52848 to 39.91009, saving model to ./model\\37-39.9101.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 39.5178 - mse: 39.5178 - val_loss: 39.9101 - val_mse: 39.9101\n",
      "Epoch 38/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 40.1707 - mse: 40.1707\n",
      "Epoch 38: val_mse improved from 39.91009 to 38.72198, saving model to ./model\\38-38.7220.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 39.2779 - mse: 39.2779 - val_loss: 38.7220 - val_mse: 38.7220\n",
      "Epoch 39/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 49.8089 - mse: 49.8089\n",
      "Epoch 39: val_mse did not improve from 38.72198\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 38.4306 - mse: 38.4306 - val_loss: 40.2328 - val_mse: 40.2328\n",
      "Epoch 40/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.6547 - mse: 21.6547\n",
      "Epoch 40: val_mse did not improve from 38.72198\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 38.5822 - mse: 38.5822 - val_loss: 39.8525 - val_mse: 39.8525\n",
      "Epoch 41/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 71.2605 - mse: 71.2605\n",
      "Epoch 41: val_mse did not improve from 38.72198\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 37.8300 - mse: 37.8300 - val_loss: 42.2875 - val_mse: 42.2875\n",
      "Epoch 42/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.2963 - mse: 22.2963\n",
      "Epoch 42: val_mse did not improve from 38.72198\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 38.8181 - mse: 38.8181 - val_loss: 41.5427 - val_mse: 41.5427\n",
      "Epoch 43/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 29.7000 - mse: 29.7000\n",
      "Epoch 43: val_mse improved from 38.72198 to 37.20838, saving model to ./model\\43-37.2084.hdf5\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 37.4264 - mse: 37.4264 - val_loss: 37.2084 - val_mse: 37.2084\n",
      "Epoch 44/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 40.0514 - mse: 40.0514\n",
      "Epoch 44: val_mse did not improve from 37.20838\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 37.3401 - mse: 37.3401 - val_loss: 40.1169 - val_mse: 40.1169\n",
      "Epoch 45/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 79.0573 - mse: 79.0573\n",
      "Epoch 45: val_mse did not improve from 37.20838\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 36.1518 - mse: 36.1518 - val_loss: 38.3590 - val_mse: 38.3590\n",
      "Epoch 46/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 34.9872 - mse: 34.9872\n",
      "Epoch 46: val_mse improved from 37.20838 to 36.76807, saving model to ./model\\46-36.7681.hdf5\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 36.4366 - mse: 36.4366 - val_loss: 36.7681 - val_mse: 36.7681\n",
      "Epoch 47/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 55.1954 - mse: 55.1954\n",
      "Epoch 47: val_mse did not improve from 36.76807\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 35.7290 - mse: 35.7290 - val_loss: 41.7317 - val_mse: 41.7317\n",
      "Epoch 48/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 41.6006 - mse: 41.6006\n",
      "Epoch 48: val_mse did not improve from 36.76807\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 36.0434 - mse: 36.0434 - val_loss: 46.2248 - val_mse: 46.2248\n",
      "Epoch 49/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 42.4162 - mse: 42.4162\n",
      "Epoch 49: val_mse did not improve from 36.76807\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 40.5431 - mse: 40.5431 - val_loss: 53.6629 - val_mse: 53.6629\n",
      "Epoch 50/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 38.5081 - mse: 38.5081\n",
      "Epoch 50: val_mse did not improve from 36.76807\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 46.6641 - mse: 46.6641 - val_loss: 42.6531 - val_mse: 42.6531\n",
      "Epoch 51/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 31.0826 - mse: 31.0826\n",
      "Epoch 51: val_mse did not improve from 36.76807\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 35.7259 - mse: 35.7259 - val_loss: 37.4734 - val_mse: 37.4734\n",
      "Epoch 52/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 46.0290 - mse: 46.0290\n",
      "Epoch 52: val_mse improved from 36.76807 to 34.39028, saving model to ./model\\52-34.3903.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 35.5589 - mse: 35.5589 - val_loss: 34.3903 - val_mse: 34.3903\n",
      "Epoch 53/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.2817 - mse: 18.2817\n",
      "Epoch 53: val_mse did not improve from 34.39028\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 32.7711 - mse: 32.7711 - val_loss: 36.7614 - val_mse: 36.7614\n",
      "Epoch 54/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 33.5245 - mse: 33.5245\n",
      "Epoch 54: val_mse did not improve from 34.39028\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 32.1770 - mse: 32.1770 - val_loss: 37.2260 - val_mse: 37.2260\n",
      "Epoch 55/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.7271 - mse: 18.7271\n",
      "Epoch 55: val_mse did not improve from 34.39028\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 32.1499 - mse: 32.1499 - val_loss: 39.9942 - val_mse: 39.9942\n",
      "Epoch 56/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.7390 - mse: 36.7390\n",
      "Epoch 56: val_mse did not improve from 34.39028\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 35.5660 - mse: 35.5660 - val_loss: 42.4979 - val_mse: 42.4979\n",
      "Epoch 57/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 68.2949 - mse: 68.2949\n",
      "Epoch 57: val_mse did not improve from 34.39028\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 37.1875 - mse: 37.1875 - val_loss: 37.3068 - val_mse: 37.3068\n",
      "Epoch 58/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.3902 - mse: 30.3902\n",
      "Epoch 58: val_mse improved from 34.39028 to 34.28165, saving model to ./model\\58-34.2817.hdf5\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 30.8691 - mse: 30.8691 - val_loss: 34.2817 - val_mse: 34.2817\n",
      "Epoch 59/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.1135 - mse: 15.1135\n",
      "Epoch 59: val_mse did not improve from 34.28165\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 31.3412 - mse: 31.3412 - val_loss: 36.6653 - val_mse: 36.6653\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 0s - loss: 49.5701 - mse: 49.5701\n",
      "Epoch 60: val_mse did not improve from 34.28165\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 32.2408 - mse: 32.2408 - val_loss: 35.4345 - val_mse: 35.4345\n",
      "Epoch 61/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.5738 - mse: 36.5738\n",
      "Epoch 61: val_mse did not improve from 34.28165\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 30.6384 - mse: 30.6384 - val_loss: 37.3829 - val_mse: 37.3829\n",
      "Epoch 62/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.5924 - mse: 18.5924\n",
      "Epoch 62: val_mse did not improve from 34.28165\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 30.5269 - mse: 30.5269 - val_loss: 37.3840 - val_mse: 37.3840\n",
      "Epoch 63/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 37.9586 - mse: 37.9586\n",
      "Epoch 63: val_mse did not improve from 34.28165\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 35.1235 - mse: 35.1235 - val_loss: 45.7295 - val_mse: 45.7295\n",
      "Epoch 64/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 38.7097 - mse: 38.7097\n",
      "Epoch 64: val_mse did not improve from 34.28165\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 33.7038 - mse: 33.7038 - val_loss: 39.7748 - val_mse: 39.7748\n",
      "Epoch 65/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 46.1770 - mse: 46.1770\n",
      "Epoch 65: val_mse did not improve from 34.28165\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 31.9735 - mse: 31.9735 - val_loss: 37.6343 - val_mse: 37.6343\n",
      "Epoch 66/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.0362 - mse: 14.0362\n",
      "Epoch 66: val_mse improved from 34.28165 to 34.07988, saving model to ./model\\66-34.0799.hdf5\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 31.8307 - mse: 31.8307 - val_loss: 34.0799 - val_mse: 34.0799\n",
      "Epoch 67/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.5659 - mse: 16.5659\n",
      "Epoch 67: val_mse improved from 34.07988 to 32.03274, saving model to ./model\\67-32.0327.hdf5\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 29.0249 - mse: 29.0249 - val_loss: 32.0327 - val_mse: 32.0327\n",
      "Epoch 68/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 54.7246 - mse: 54.7246\n",
      "Epoch 68: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 30.2621 - mse: 30.2621 - val_loss: 37.6887 - val_mse: 37.6887\n",
      "Epoch 69/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.1071 - mse: 20.1071\n",
      "Epoch 69: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 28.8257 - mse: 28.8257 - val_loss: 34.1241 - val_mse: 34.1241\n",
      "Epoch 70/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.8654 - mse: 19.8654\n",
      "Epoch 70: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 30.0454 - mse: 30.0454 - val_loss: 32.7593 - val_mse: 32.7593\n",
      "Epoch 71/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 6.6608 - mse: 6.6608\n",
      "Epoch 71: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 27.0867 - mse: 27.0867 - val_loss: 33.3230 - val_mse: 33.3230\n",
      "Epoch 72/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.2124 - mse: 13.2124\n",
      "Epoch 72: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 29.5542 - mse: 29.5542 - val_loss: 35.0079 - val_mse: 35.0079\n",
      "Epoch 73/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.4025 - mse: 23.4025\n",
      "Epoch 73: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 29.6102 - mse: 29.6102 - val_loss: 33.6723 - val_mse: 33.6723\n",
      "Epoch 74/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 29.0865 - mse: 29.0865\n",
      "Epoch 74: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 29.7267 - mse: 29.7267 - val_loss: 37.3678 - val_mse: 37.3678\n",
      "Epoch 75/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 24.6495 - mse: 24.6495\n",
      "Epoch 75: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 27.8526 - mse: 27.8526 - val_loss: 32.5008 - val_mse: 32.5008\n",
      "Epoch 76/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 29.9085 - mse: 29.9085\n",
      "Epoch 76: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 28.0359 - mse: 28.0359 - val_loss: 33.8464 - val_mse: 33.8464\n",
      "Epoch 77/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.4089 - mse: 23.4089\n",
      "Epoch 77: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 26.9413 - mse: 26.9413 - val_loss: 37.0040 - val_mse: 37.0040\n",
      "Epoch 78/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.0315 - mse: 36.0315\n",
      "Epoch 78: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 27.8303 - mse: 27.8303 - val_loss: 33.4981 - val_mse: 33.4981\n",
      "Epoch 79/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 37.7925 - mse: 37.7925\n",
      "Epoch 79: val_mse did not improve from 32.03274\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 27.8990 - mse: 27.8990 - val_loss: 32.5972 - val_mse: 32.5972\n",
      "Epoch 80/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.5605 - mse: 30.5605\n",
      "Epoch 80: val_mse improved from 32.03274 to 31.31282, saving model to ./model\\80-31.3128.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 25.7293 - mse: 25.7293 - val_loss: 31.3128 - val_mse: 31.3128\n",
      "Epoch 81/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.4886 - mse: 36.4886\n",
      "Epoch 81: val_mse did not improve from 31.31282\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 27.3321 - mse: 27.3321 - val_loss: 34.7426 - val_mse: 34.7426\n",
      "Epoch 82/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 28.0555 - mse: 28.0555\n",
      "Epoch 82: val_mse did not improve from 31.31282\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 26.4235 - mse: 26.4235 - val_loss: 31.9690 - val_mse: 31.9690\n",
      "Epoch 83/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.3280 - mse: 22.3280\n",
      "Epoch 83: val_mse did not improve from 31.31282\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 26.8197 - mse: 26.8197 - val_loss: 35.2220 - val_mse: 35.2220\n",
      "Epoch 84/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 37.9036 - mse: 37.9036\n",
      "Epoch 84: val_mse did not improve from 31.31282\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 28.0431 - mse: 28.0431 - val_loss: 32.7588 - val_mse: 32.7588\n",
      "Epoch 85/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 35.2224 - mse: 35.2224\n",
      "Epoch 85: val_mse did not improve from 31.31282\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 25.3990 - mse: 25.3990 - val_loss: 31.9527 - val_mse: 31.9527\n",
      "Epoch 86/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 24.2306 - mse: 24.2306\n",
      "Epoch 86: val_mse did not improve from 31.31282\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24.5563 - mse: 24.5563 - val_loss: 34.2832 - val_mse: 34.2832\n",
      "Epoch 87/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.9156 - mse: 16.9156\n",
      "Epoch 87: val_mse did not improve from 31.31282\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 25.6569 - mse: 25.6569 - val_loss: 33.3572 - val_mse: 33.3572\n",
      "Epoch 88/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 33.4517 - mse: 33.4517\n",
      "Epoch 88: val_mse did not improve from 31.31282\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 28.0912 - mse: 28.0912 - val_loss: 33.7961 - val_mse: 33.7961\n",
      "Epoch 89/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 28.8270 - mse: 28.8270\n",
      "Epoch 89: val_mse did not improve from 31.31282\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 28.7291 - mse: 28.7291 - val_loss: 39.0192 - val_mse: 39.0192\n",
      "Epoch 90/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.8833 - mse: 15.8833\n",
      "Epoch 90: val_mse improved from 31.31282 to 30.99672, saving model to ./model\\90-30.9967.hdf5\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 28.9924 - mse: 28.9924 - val_loss: 30.9967 - val_mse: 30.9967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 24.9037 - mse: 24.9037\n",
      "Epoch 91: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 26.9589 - mse: 26.9589 - val_loss: 33.0216 - val_mse: 33.0216\n",
      "Epoch 92/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 33.4616 - mse: 33.4616\n",
      "Epoch 92: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 25.5739 - mse: 25.5739 - val_loss: 31.7961 - val_mse: 31.7961\n",
      "Epoch 93/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.3341 - mse: 36.3341\n",
      "Epoch 93: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 23.6924 - mse: 23.6924 - val_loss: 31.3089 - val_mse: 31.3089\n",
      "Epoch 94/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.7339 - mse: 23.7339\n",
      "Epoch 94: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 23.4113 - mse: 23.4113 - val_loss: 34.6949 - val_mse: 34.6949\n",
      "Epoch 95/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.7257 - mse: 23.7257\n",
      "Epoch 95: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 26.2337 - mse: 26.2337 - val_loss: 56.3525 - val_mse: 56.3525\n",
      "Epoch 96/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 35.7034 - mse: 35.7034\n",
      "Epoch 96: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 33.7177 - mse: 33.7177 - val_loss: 32.3315 - val_mse: 32.3315\n",
      "Epoch 97/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.9533 - mse: 17.9533\n",
      "Epoch 97: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 28.8866 - mse: 28.8866 - val_loss: 35.0221 - val_mse: 35.0221\n",
      "Epoch 98/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.6265 - mse: 30.6265\n",
      "Epoch 98: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 27.8656 - mse: 27.8656 - val_loss: 34.5735 - val_mse: 34.5735\n",
      "Epoch 99/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.7697 - mse: 11.7697\n",
      "Epoch 99: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 24.0004 - mse: 24.0004 - val_loss: 32.1379 - val_mse: 32.1379\n",
      "Epoch 100/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.9963 - mse: 18.9963\n",
      "Epoch 100: val_mse did not improve from 30.99672\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 25.1690 - mse: 25.1690 - val_loss: 38.4913 - val_mse: 38.4913\n",
      "Epoch 101/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 44.1602 - mse: 44.1602\n",
      "Epoch 101: val_mse improved from 30.99672 to 30.51209, saving model to ./model\\101-30.5121.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 27.7434 - mse: 27.7434 - val_loss: 30.5121 - val_mse: 30.5121\n",
      "Epoch 102/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.9458 - mse: 22.9458\n",
      "Epoch 102: val_mse did not improve from 30.51209\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 24.2129 - mse: 24.2129 - val_loss: 30.7915 - val_mse: 30.7915\n",
      "Epoch 103/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.0850 - mse: 22.0850\n",
      "Epoch 103: val_mse did not improve from 30.51209\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 22.5918 - mse: 22.5918 - val_loss: 40.1728 - val_mse: 40.1728\n",
      "Epoch 104/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 34.5413 - mse: 34.5413\n",
      "Epoch 104: val_mse did not improve from 30.51209\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24.9903 - mse: 24.9903 - val_loss: 31.4944 - val_mse: 31.4944\n",
      "Epoch 105/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 31.7436 - mse: 31.7436\n",
      "Epoch 105: val_mse did not improve from 30.51209\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 23.6054 - mse: 23.6054 - val_loss: 31.3172 - val_mse: 31.3172\n",
      "Epoch 106/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.5776 - mse: 30.5776\n",
      "Epoch 106: val_mse did not improve from 30.51209\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 23.1996 - mse: 23.1996 - val_loss: 36.0413 - val_mse: 36.0413\n",
      "Epoch 107/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.9894 - mse: 13.9894\n",
      "Epoch 107: val_mse did not improve from 30.51209\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 24.3007 - mse: 24.3007 - val_loss: 33.5237 - val_mse: 33.5237\n",
      "Epoch 108/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.7483 - mse: 16.7483\n",
      "Epoch 108: val_mse did not improve from 30.51209\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 23.6032 - mse: 23.6032 - val_loss: 35.1669 - val_mse: 35.1669\n",
      "Epoch 109/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.2842 - mse: 17.2842\n",
      "Epoch 109: val_mse improved from 30.51209 to 29.59620, saving model to ./model\\109-29.5962.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 22.5187 - mse: 22.5187 - val_loss: 29.5962 - val_mse: 29.5962\n",
      "Epoch 110/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.8856 - mse: 14.8856\n",
      "Epoch 110: val_mse did not improve from 29.59620\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 22.7855 - mse: 22.7855 - val_loss: 59.3230 - val_mse: 59.3230\n",
      "Epoch 111/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 42.5703 - mse: 42.5703\n",
      "Epoch 111: val_mse did not improve from 29.59620\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 32.0296 - mse: 32.0296 - val_loss: 40.0805 - val_mse: 40.0805\n",
      "Epoch 112/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.5932 - mse: 18.5932\n",
      "Epoch 112: val_mse did not improve from 29.59620\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 23.9766 - mse: 23.9766 - val_loss: 31.1668 - val_mse: 31.1668\n",
      "Epoch 113/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.6288 - mse: 23.6288\n",
      "Epoch 113: val_mse did not improve from 29.59620\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 21.8314 - mse: 21.8314 - val_loss: 35.6308 - val_mse: 35.6308\n",
      "Epoch 114/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 24.9021 - mse: 24.9021\n",
      "Epoch 114: val_mse did not improve from 29.59620\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 22.6678 - mse: 22.6678 - val_loss: 30.1029 - val_mse: 30.1029\n",
      "Epoch 115/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.6530 - mse: 13.6530\n",
      "Epoch 115: val_mse did not improve from 29.59620\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 23.4876 - mse: 23.4876 - val_loss: 35.0215 - val_mse: 35.0215\n",
      "Epoch 116/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.0946 - mse: 17.0946\n",
      "Epoch 116: val_mse did not improve from 29.59620\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 22.9865 - mse: 22.9865 - val_loss: 31.6288 - val_mse: 31.6288\n",
      "Epoch 117/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 26.8616 - mse: 26.8616\n",
      "Epoch 117: val_mse improved from 29.59620 to 27.86534, saving model to ./model\\117-27.8653.hdf5\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 20.7535 - mse: 20.7535 - val_loss: 27.8653 - val_mse: 27.8653\n",
      "Epoch 118/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.3231 - mse: 18.3231\n",
      "Epoch 118: val_mse improved from 27.86534 to 27.73905, saving model to ./model\\118-27.7390.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 21.2148 - mse: 21.2148 - val_loss: 27.7390 - val_mse: 27.7390\n",
      "Epoch 119/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.4521 - mse: 22.4521\n",
      "Epoch 119: val_mse improved from 27.73905 to 27.55156, saving model to ./model\\119-27.5516.hdf5\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 21.8941 - mse: 21.8941 - val_loss: 27.5516 - val_mse: 27.5516\n",
      "Epoch 120/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.1329 - mse: 12.1329\n",
      "Epoch 120: val_mse did not improve from 27.55156\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 20.5977 - mse: 20.5977 - val_loss: 31.6048 - val_mse: 31.6048\n",
      "Epoch 121/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 0s - loss: 18.3078 - mse: 18.3078\n",
      "Epoch 121: val_mse did not improve from 27.55156\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 20.7283 - mse: 20.7283 - val_loss: 32.6502 - val_mse: 32.6502\n",
      "Epoch 122/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.5848 - mse: 16.5848\n",
      "Epoch 122: val_mse did not improve from 27.55156\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 21.0301 - mse: 21.0301 - val_loss: 29.8503 - val_mse: 29.8503\n",
      "Epoch 123/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.7804 - mse: 23.7804\n",
      "Epoch 123: val_mse improved from 27.55156 to 26.56929, saving model to ./model\\123-26.5693.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 19.8985 - mse: 19.8985 - val_loss: 26.5693 - val_mse: 26.5693\n",
      "Epoch 124/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 28.2141 - mse: 28.2141\n",
      "Epoch 124: val_mse improved from 26.56929 to 25.23614, saving model to ./model\\124-25.2361.hdf5\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 19.8168 - mse: 19.8168 - val_loss: 25.2361 - val_mse: 25.2361\n",
      "Epoch 125/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.3500 - mse: 12.3500\n",
      "Epoch 125: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 18.9042 - mse: 18.9042 - val_loss: 27.5609 - val_mse: 27.5609\n",
      "Epoch 126/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.7561 - mse: 15.7561\n",
      "Epoch 126: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19.1586 - mse: 19.1586 - val_loss: 28.0417 - val_mse: 28.0417\n",
      "Epoch 127/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 28.7141 - mse: 28.7141\n",
      "Epoch 127: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 20.2037 - mse: 20.2037 - val_loss: 25.8857 - val_mse: 25.8857\n",
      "Epoch 128/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.5240 - mse: 15.5240\n",
      "Epoch 128: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 19.1134 - mse: 19.1134 - val_loss: 26.2229 - val_mse: 26.2229\n",
      "Epoch 129/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.6142 - mse: 30.6142\n",
      "Epoch 129: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 18.4747 - mse: 18.4747 - val_loss: 27.0592 - val_mse: 27.0592\n",
      "Epoch 130/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.2038 - mse: 27.2038\n",
      "Epoch 130: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19.9759 - mse: 19.9759 - val_loss: 29.6021 - val_mse: 29.6021\n",
      "Epoch 131/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.9435 - mse: 16.9435\n",
      "Epoch 131: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 22.3470 - mse: 22.3470 - val_loss: 26.1669 - val_mse: 26.1669\n",
      "Epoch 132/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.1654 - mse: 15.1654\n",
      "Epoch 132: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 20.6471 - mse: 20.6471 - val_loss: 27.1882 - val_mse: 27.1882\n",
      "Epoch 133/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.9484 - mse: 16.9484\n",
      "Epoch 133: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 20.7718 - mse: 20.7718 - val_loss: 28.1985 - val_mse: 28.1985\n",
      "Epoch 134/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.5875 - mse: 30.5875\n",
      "Epoch 134: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 18.8913 - mse: 18.8913 - val_loss: 26.9165 - val_mse: 26.9165\n",
      "Epoch 135/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.8858 - mse: 16.8858\n",
      "Epoch 135: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 18.8985 - mse: 18.8985 - val_loss: 29.1063 - val_mse: 29.1063\n",
      "Epoch 136/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.4005 - mse: 13.4005\n",
      "Epoch 136: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 17.5321 - mse: 17.5321 - val_loss: 27.0851 - val_mse: 27.0851\n",
      "Epoch 137/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.8894 - mse: 17.8894\n",
      "Epoch 137: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 17.7930 - mse: 17.7930 - val_loss: 25.9062 - val_mse: 25.9062\n",
      "Epoch 138/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.9871 - mse: 11.9871\n",
      "Epoch 138: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 19.7614 - mse: 19.7614 - val_loss: 26.9506 - val_mse: 26.9506\n",
      "Epoch 139/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.2824 - mse: 17.2824\n",
      "Epoch 139: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 19.3599 - mse: 19.3599 - val_loss: 28.3003 - val_mse: 28.3003\n",
      "Epoch 140/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.9205 - mse: 10.9205\n",
      "Epoch 140: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19.1848 - mse: 19.1848 - val_loss: 25.4352 - val_mse: 25.4352\n",
      "Epoch 141/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.3641 - mse: 23.3641\n",
      "Epoch 141: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17.3579 - mse: 17.3579 - val_loss: 26.2002 - val_mse: 26.2002\n",
      "Epoch 142/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.7871 - mse: 21.7871\n",
      "Epoch 142: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 19.2378 - mse: 19.2378 - val_loss: 29.3671 - val_mse: 29.3671\n",
      "Epoch 143/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.0320 - mse: 16.0320\n",
      "Epoch 143: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 25.1646 - mse: 25.1646 - val_loss: 33.6309 - val_mse: 33.6309\n",
      "Epoch 144/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.6309 - mse: 9.6309\n",
      "Epoch 144: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 22.6482 - mse: 22.6482 - val_loss: 30.8465 - val_mse: 30.8465\n",
      "Epoch 145/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 25.1757 - mse: 25.1757\n",
      "Epoch 145: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 18.8800 - mse: 18.8800 - val_loss: 31.0183 - val_mse: 31.0183\n",
      "Epoch 146/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.4839 - mse: 18.4839\n",
      "Epoch 146: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17.3491 - mse: 17.3491 - val_loss: 26.2900 - val_mse: 26.2900\n",
      "Epoch 147/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.5347 - mse: 16.5347\n",
      "Epoch 147: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 19.4283 - mse: 19.4283 - val_loss: 26.3817 - val_mse: 26.3817\n",
      "Epoch 148/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.5962 - mse: 16.5962\n",
      "Epoch 148: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17.1264 - mse: 17.1264 - val_loss: 25.3236 - val_mse: 25.3236\n",
      "Epoch 149/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.8947 - mse: 15.8947\n",
      "Epoch 149: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16.7359 - mse: 16.7359 - val_loss: 27.4701 - val_mse: 27.4701\n",
      "Epoch 150/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 25.0696 - mse: 25.0696\n",
      "Epoch 150: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16.3178 - mse: 16.3178 - val_loss: 26.0540 - val_mse: 26.0540\n",
      "Epoch 151/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.1077 - mse: 11.1077\n",
      "Epoch 151: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 16.6756 - mse: 16.6756 - val_loss: 34.5656 - val_mse: 34.5656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.6538 - mse: 15.6538\n",
      "Epoch 152: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 18.6628 - mse: 18.6628 - val_loss: 28.4985 - val_mse: 28.4985\n",
      "Epoch 153/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.6018 - mse: 21.6018\n",
      "Epoch 153: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 16.4547 - mse: 16.4547 - val_loss: 45.1060 - val_mse: 45.1060\n",
      "Epoch 154/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.6848 - mse: 22.6848\n",
      "Epoch 154: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 23.0777 - mse: 23.0777 - val_loss: 28.4921 - val_mse: 28.4921\n",
      "Epoch 155/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.2499 - mse: 14.2499\n",
      "Epoch 155: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24.9204 - mse: 24.9204 - val_loss: 32.6318 - val_mse: 32.6318\n",
      "Epoch 156/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.3541 - mse: 13.3541\n",
      "Epoch 156: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 24.8143 - mse: 24.8143 - val_loss: 32.3756 - val_mse: 32.3756\n",
      "Epoch 157/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.7653 - mse: 13.7653\n",
      "Epoch 157: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 16.2942 - mse: 16.2942 - val_loss: 26.6556 - val_mse: 26.6556\n",
      "Epoch 158/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.8602 - mse: 11.8602\n",
      "Epoch 158: val_mse did not improve from 25.23614\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16.5021 - mse: 16.5021 - val_loss: 28.0597 - val_mse: 28.0597\n",
      "Epoch 159/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.9340 - mse: 22.9340\n",
      "Epoch 159: val_mse improved from 25.23614 to 24.89842, saving model to ./model\\159-24.8984.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 20.1157 - mse: 20.1157 - val_loss: 24.8984 - val_mse: 24.8984\n",
      "Epoch 160/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.4565 - mse: 8.4565\n",
      "Epoch 160: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 16.5705 - mse: 16.5705 - val_loss: 27.6839 - val_mse: 27.6839\n",
      "Epoch 161/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.3250 - mse: 8.3250\n",
      "Epoch 161: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 16.2865 - mse: 16.2865 - val_loss: 26.9567 - val_mse: 26.9567\n",
      "Epoch 162/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.9506 - mse: 15.9506\n",
      "Epoch 162: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 19.2277 - mse: 19.2277 - val_loss: 30.1232 - val_mse: 30.1232\n",
      "Epoch 163/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.2787 - mse: 14.2787\n",
      "Epoch 163: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 18.7028 - mse: 18.7028 - val_loss: 37.5222 - val_mse: 37.5222\n",
      "Epoch 164/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.4888 - mse: 22.4888\n",
      "Epoch 164: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 21.5228 - mse: 21.5228 - val_loss: 60.1821 - val_mse: 60.1821\n",
      "Epoch 165/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 44.6430 - mse: 44.6430\n",
      "Epoch 165: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 21.4794 - mse: 21.4794 - val_loss: 27.3743 - val_mse: 27.3743\n",
      "Epoch 166/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.0254 - mse: 14.0254\n",
      "Epoch 166: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 16.9819 - mse: 16.9819 - val_loss: 25.6009 - val_mse: 25.6009\n",
      "Epoch 167/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.9046 - mse: 16.9046\n",
      "Epoch 167: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 15.7249 - mse: 15.7249 - val_loss: 25.5596 - val_mse: 25.5596\n",
      "Epoch 168/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 6.4059 - mse: 6.4059\n",
      "Epoch 168: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 18.1111 - mse: 18.1111 - val_loss: 26.7907 - val_mse: 26.7907\n",
      "Epoch 169/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.6147 - mse: 15.6147\n",
      "Epoch 169: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 17.6131 - mse: 17.6131 - val_loss: 35.9228 - val_mse: 35.9228\n",
      "Epoch 170/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 25.8963 - mse: 25.8963\n",
      "Epoch 170: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 21.7494 - mse: 21.7494 - val_loss: 25.7236 - val_mse: 25.7236\n",
      "Epoch 171/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.1448 - mse: 10.1448\n",
      "Epoch 171: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19.5335 - mse: 19.5335 - val_loss: 34.1937 - val_mse: 34.1937\n",
      "Epoch 172/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.8464 - mse: 18.8464\n",
      "Epoch 172: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 18.6391 - mse: 18.6391 - val_loss: 31.4679 - val_mse: 31.4679\n",
      "Epoch 173/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.0489 - mse: 21.0489\n",
      "Epoch 173: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 16.1503 - mse: 16.1503 - val_loss: 25.1083 - val_mse: 25.1083\n",
      "Epoch 174/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.6227 - mse: 13.6227\n",
      "Epoch 174: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 16.0059 - mse: 16.0059 - val_loss: 29.1244 - val_mse: 29.1244\n",
      "Epoch 175/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.0284 - mse: 21.0284\n",
      "Epoch 175: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 15.3544 - mse: 15.3544 - val_loss: 25.3166 - val_mse: 25.3166\n",
      "Epoch 176/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.1641 - mse: 19.1641\n",
      "Epoch 176: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 15.2152 - mse: 15.2152 - val_loss: 26.6456 - val_mse: 26.6456\n",
      "Epoch 177/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 24.4572 - mse: 24.4572\n",
      "Epoch 177: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15.0661 - mse: 15.0661 - val_loss: 27.7508 - val_mse: 27.7508\n",
      "Epoch 178/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.4953 - mse: 22.4953\n",
      "Epoch 178: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14.1021 - mse: 14.1021 - val_loss: 25.4765 - val_mse: 25.4765\n",
      "Epoch 179/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.4257 - mse: 10.4257\n",
      "Epoch 179: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 14.6652 - mse: 14.6652 - val_loss: 32.4288 - val_mse: 32.4288\n",
      "Epoch 180/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.1231 - mse: 23.1231\n",
      "Epoch 180: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 17.6500 - mse: 17.6500 - val_loss: 31.9279 - val_mse: 31.9279\n",
      "Epoch 181/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.3515 - mse: 18.3515\n",
      "Epoch 181: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 15.9748 - mse: 15.9748 - val_loss: 29.5241 - val_mse: 29.5241\n",
      "Epoch 182/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.7124 - mse: 11.7124\n",
      "Epoch 182: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14.6725 - mse: 14.6725 - val_loss: 27.0233 - val_mse: 27.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.3310 - mse: 19.3310\n",
      "Epoch 183: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 21.1060 - mse: 21.1060 - val_loss: 27.0797 - val_mse: 27.0797\n",
      "Epoch 184/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.7276 - mse: 8.7276\n",
      "Epoch 184: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 17.4010 - mse: 17.4010 - val_loss: 28.3050 - val_mse: 28.3050\n",
      "Epoch 185/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.3856 - mse: 9.3856\n",
      "Epoch 185: val_mse did not improve from 24.89842\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14.9717 - mse: 14.9717 - val_loss: 28.1255 - val_mse: 28.1255\n",
      "Epoch 186/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.7020 - mse: 23.7020\n",
      "Epoch 186: val_mse improved from 24.89842 to 24.22343, saving model to ./model\\186-24.2234.hdf5\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 15.9556 - mse: 15.9556 - val_loss: 24.2234 - val_mse: 24.2234\n",
      "Epoch 187/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.0163 - mse: 19.0163\n",
      "Epoch 187: val_mse did not improve from 24.22343\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14.3359 - mse: 14.3359 - val_loss: 26.4346 - val_mse: 26.4346\n",
      "Epoch 188/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.3223 - mse: 16.3223\n",
      "Epoch 188: val_mse did not improve from 24.22343\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 15.3888 - mse: 15.3888 - val_loss: 26.2188 - val_mse: 26.2188\n",
      "Epoch 189/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.8663 - mse: 17.8663\n",
      "Epoch 189: val_mse did not improve from 24.22343\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 17.4810 - mse: 17.4810 - val_loss: 30.3136 - val_mse: 30.3136\n",
      "Epoch 190/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.0358 - mse: 17.0358\n",
      "Epoch 190: val_mse did not improve from 24.22343\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13.9064 - mse: 13.9064 - val_loss: 24.7428 - val_mse: 24.7428\n",
      "Epoch 191/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.6321 - mse: 12.6321\n",
      "Epoch 191: val_mse did not improve from 24.22343\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15.2337 - mse: 15.2337 - val_loss: 24.6987 - val_mse: 24.6987\n",
      "Epoch 192/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.3967 - mse: 21.3967\n",
      "Epoch 192: val_mse improved from 24.22343 to 24.01183, saving model to ./model\\192-24.0118.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 17.1620 - mse: 17.1620 - val_loss: 24.0118 - val_mse: 24.0118\n",
      "Epoch 193/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.7025 - mse: 13.7025\n",
      "Epoch 193: val_mse improved from 24.01183 to 23.81997, saving model to ./model\\193-23.8200.hdf5\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 15.5349 - mse: 15.5349 - val_loss: 23.8200 - val_mse: 23.8200\n",
      "Epoch 194/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.2337 - mse: 13.2337\n",
      "Epoch 194: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14.2916 - mse: 14.2916 - val_loss: 26.1960 - val_mse: 26.1960\n",
      "Epoch 195/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.7467 - mse: 10.7467\n",
      "Epoch 195: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.3898 - mse: 13.3898 - val_loss: 28.3599 - val_mse: 28.3599\n",
      "Epoch 196/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.4150 - mse: 9.4150\n",
      "Epoch 196: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 14.6717 - mse: 14.6717 - val_loss: 28.8885 - val_mse: 28.8885\n",
      "Epoch 197/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.0417 - mse: 11.0417\n",
      "Epoch 197: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 24.3208 - mse: 24.3208 - val_loss: 26.8963 - val_mse: 26.8963\n",
      "Epoch 198/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.4618 - mse: 9.4618\n",
      "Epoch 198: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 17.1603 - mse: 17.1603 - val_loss: 29.5406 - val_mse: 29.5406\n",
      "Epoch 199/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.1668 - mse: 12.1668\n",
      "Epoch 199: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 16.1668 - mse: 16.1668 - val_loss: 27.1668 - val_mse: 27.1668\n",
      "Epoch 200/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.0317 - mse: 16.0317\n",
      "Epoch 200: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13.8067 - mse: 13.8067 - val_loss: 25.1828 - val_mse: 25.1828\n",
      "Epoch 201/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.3278 - mse: 18.3278\n",
      "Epoch 201: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.3495 - mse: 13.3495 - val_loss: 28.1935 - val_mse: 28.1935\n",
      "Epoch 202/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.9421 - mse: 20.9421\n",
      "Epoch 202: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15.3131 - mse: 15.3131 - val_loss: 25.5431 - val_mse: 25.5431\n",
      "Epoch 203/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.7287 - mse: 13.7287\n",
      "Epoch 203: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14.7141 - mse: 14.7141 - val_loss: 27.7277 - val_mse: 27.7277\n",
      "Epoch 204/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.2579 - mse: 19.2579\n",
      "Epoch 204: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 18.7043 - mse: 18.7043 - val_loss: 26.3272 - val_mse: 26.3272\n",
      "Epoch 205/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.6982 - mse: 12.6982\n",
      "Epoch 205: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 15.5579 - mse: 15.5579 - val_loss: 26.9313 - val_mse: 26.9313\n",
      "Epoch 206/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.1555 - mse: 9.1555\n",
      "Epoch 206: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 13.9233 - mse: 13.9233 - val_loss: 25.6382 - val_mse: 25.6382\n",
      "Epoch 207/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.1532 - mse: 17.1532\n",
      "Epoch 207: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13.8428 - mse: 13.8428 - val_loss: 26.1811 - val_mse: 26.1811\n",
      "Epoch 208/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.1568 - mse: 12.1568\n",
      "Epoch 208: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.8999 - mse: 13.8999 - val_loss: 26.1996 - val_mse: 26.1996\n",
      "Epoch 209/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.2908 - mse: 9.2908\n",
      "Epoch 209: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14.5914 - mse: 14.5914 - val_loss: 28.7365 - val_mse: 28.7365\n",
      "Epoch 210/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 24.3414 - mse: 24.3414\n",
      "Epoch 210: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14.8914 - mse: 14.8914 - val_loss: 25.0108 - val_mse: 25.0108\n",
      "Epoch 211/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.8741 - mse: 8.8741\n",
      "Epoch 211: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.3882 - mse: 13.3882 - val_loss: 24.5920 - val_mse: 24.5920\n",
      "Epoch 212/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.4546 - mse: 8.4546\n",
      "Epoch 212: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14.0111 - mse: 14.0111 - val_loss: 24.1953 - val_mse: 24.1953\n",
      "Epoch 213/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.5939 - mse: 12.5939\n",
      "Epoch 213: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.6095 - mse: 13.6095 - val_loss: 26.3103 - val_mse: 26.3103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.8179 - mse: 16.8179\n",
      "Epoch 214: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.6023 - mse: 13.6023 - val_loss: 28.6094 - val_mse: 28.6094\n",
      "Epoch 215/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.6494 - mse: 14.6494\n",
      "Epoch 215: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14.2800 - mse: 14.2800 - val_loss: 31.1500 - val_mse: 31.1500\n",
      "Epoch 216/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.6819 - mse: 13.6819\n",
      "Epoch 216: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.6788 - mse: 13.6788 - val_loss: 25.0306 - val_mse: 25.0306\n",
      "Epoch 217/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.4184 - mse: 13.4184\n",
      "Epoch 217: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13.4466 - mse: 13.4466 - val_loss: 25.3495 - val_mse: 25.3495\n",
      "Epoch 218/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.8678 - mse: 14.8678\n",
      "Epoch 218: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.5662 - mse: 13.5662 - val_loss: 28.1113 - val_mse: 28.1113\n",
      "Epoch 219/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.1385 - mse: 11.1385\n",
      "Epoch 219: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13.9610 - mse: 13.9610 - val_loss: 26.4769 - val_mse: 26.4769\n",
      "Epoch 220/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.0512 - mse: 10.0512\n",
      "Epoch 220: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.9004 - mse: 12.9004 - val_loss: 25.7368 - val_mse: 25.7368\n",
      "Epoch 221/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.6817 - mse: 15.6817\n",
      "Epoch 221: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.7065 - mse: 12.7065 - val_loss: 28.3107 - val_mse: 28.3107\n",
      "Epoch 222/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.0133 - mse: 16.0133\n",
      "Epoch 222: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14.0818 - mse: 14.0818 - val_loss: 24.8861 - val_mse: 24.8861\n",
      "Epoch 223/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.9270 - mse: 14.9270\n",
      "Epoch 223: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 14.4075 - mse: 14.4075 - val_loss: 37.2140 - val_mse: 37.2140\n",
      "Epoch 224/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.9284 - mse: 20.9284\n",
      "Epoch 224: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 16.2635 - mse: 16.2635 - val_loss: 36.2987 - val_mse: 36.2987\n",
      "Epoch 225/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.7715 - mse: 18.7715\n",
      "Epoch 225: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 15.6898 - mse: 15.6898 - val_loss: 26.2691 - val_mse: 26.2691\n",
      "Epoch 226/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.9243 - mse: 13.9243\n",
      "Epoch 226: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.5435 - mse: 13.5435 - val_loss: 24.9887 - val_mse: 24.9887\n",
      "Epoch 227/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.0598 - mse: 8.0598\n",
      "Epoch 227: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.1768 - mse: 12.1768 - val_loss: 27.1344 - val_mse: 27.1344\n",
      "Epoch 228/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.5239 - mse: 16.5239\n",
      "Epoch 228: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.8351 - mse: 13.8351 - val_loss: 25.9113 - val_mse: 25.9113\n",
      "Epoch 229/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.2727 - mse: 12.2727\n",
      "Epoch 229: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 15.3830 - mse: 15.3830 - val_loss: 26.4062 - val_mse: 26.4062\n",
      "Epoch 230/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 6.9973 - mse: 6.9973\n",
      "Epoch 230: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 16.2514 - mse: 16.2514 - val_loss: 25.7565 - val_mse: 25.7565\n",
      "Epoch 231/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.4620 - mse: 16.4620\n",
      "Epoch 231: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16.2061 - mse: 16.2061 - val_loss: 33.9613 - val_mse: 33.9613\n",
      "Epoch 232/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.4732 - mse: 15.4732\n",
      "Epoch 232: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13.5059 - mse: 13.5059 - val_loss: 28.6222 - val_mse: 28.6222\n",
      "Epoch 233/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.9242 - mse: 9.9242\n",
      "Epoch 233: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.5596 - mse: 12.5596 - val_loss: 24.7667 - val_mse: 24.7667\n",
      "Epoch 234/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.0317 - mse: 16.0317\n",
      "Epoch 234: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.4036 - mse: 12.4036 - val_loss: 25.5620 - val_mse: 25.5620\n",
      "Epoch 235/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.7214 - mse: 10.7214\n",
      "Epoch 235: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.9606 - mse: 12.9606 - val_loss: 27.9709 - val_mse: 27.9709\n",
      "Epoch 236/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.7159 - mse: 11.7159\n",
      "Epoch 236: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.9947 - mse: 12.9947 - val_loss: 28.8941 - val_mse: 28.8941\n",
      "Epoch 237/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.7725 - mse: 11.7725\n",
      "Epoch 237: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 15.2359 - mse: 15.2359 - val_loss: 30.6248 - val_mse: 30.6248\n",
      "Epoch 238/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.1392 - mse: 22.1392\n",
      "Epoch 238: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 17.2317 - mse: 17.2317 - val_loss: 31.6209 - val_mse: 31.6209\n",
      "Epoch 239/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 7.3848 - mse: 7.3848\n",
      "Epoch 239: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.1916 - mse: 13.1916 - val_loss: 27.4253 - val_mse: 27.4253\n",
      "Epoch 240/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.0976 - mse: 13.0976\n",
      "Epoch 240: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.4411 - mse: 12.4411 - val_loss: 26.0632 - val_mse: 26.0632\n",
      "Epoch 241/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.9975 - mse: 10.9975\n",
      "Epoch 241: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.0214 - mse: 12.0214 - val_loss: 25.9816 - val_mse: 25.9816\n",
      "Epoch 242/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.8039 - mse: 17.8039\n",
      "Epoch 242: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 13.2455 - mse: 13.2455 - val_loss: 24.9353 - val_mse: 24.9353\n",
      "Epoch 243/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.2718 - mse: 9.2718\n",
      "Epoch 243: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 12.1011 - mse: 12.1011 - val_loss: 25.3921 - val_mse: 25.3921\n",
      "Epoch 244/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.5594 - mse: 9.5594\n",
      "Epoch 244: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.5806 - mse: 12.5806 - val_loss: 28.0476 - val_mse: 28.0476\n",
      "Epoch 245/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 0s - loss: 9.5911 - mse: 9.5911\n",
      "Epoch 245: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.2556 - mse: 13.2556 - val_loss: 27.3730 - val_mse: 27.3730\n",
      "Epoch 246/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.0534 - mse: 16.0534\n",
      "Epoch 246: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.8620 - mse: 11.8620 - val_loss: 26.7178 - val_mse: 26.7178\n",
      "Epoch 247/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 6.6803 - mse: 6.6803\n",
      "Epoch 247: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.6695 - mse: 11.6695 - val_loss: 26.5721 - val_mse: 26.5721\n",
      "Epoch 248/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.0728 - mse: 12.0728\n",
      "Epoch 248: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.4784 - mse: 12.4784 - val_loss: 31.2807 - val_mse: 31.2807\n",
      "Epoch 249/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.8347 - mse: 15.8347\n",
      "Epoch 249: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.4688 - mse: 12.4688 - val_loss: 28.4177 - val_mse: 28.4177\n",
      "Epoch 250/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.7129 - mse: 16.7129\n",
      "Epoch 250: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.6683 - mse: 12.6683 - val_loss: 34.1802 - val_mse: 34.1802\n",
      "Epoch 251/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.8769 - mse: 9.8769\n",
      "Epoch 251: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13.3433 - mse: 13.3433 - val_loss: 25.9473 - val_mse: 25.9473\n",
      "Epoch 252/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.2861 - mse: 11.2861\n",
      "Epoch 252: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.2190 - mse: 13.2190 - val_loss: 25.0653 - val_mse: 25.0653\n",
      "Epoch 253/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 7.2752 - mse: 7.2752\n",
      "Epoch 253: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.3683 - mse: 12.3683 - val_loss: 25.7837 - val_mse: 25.7837\n",
      "Epoch 254/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.4658 - mse: 16.4658\n",
      "Epoch 254: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.9222 - mse: 12.9222 - val_loss: 28.0509 - val_mse: 28.0509\n",
      "Epoch 255/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.8048 - mse: 9.8048\n",
      "Epoch 255: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.5195 - mse: 13.5195 - val_loss: 26.0097 - val_mse: 26.0097\n",
      "Epoch 256/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.0875 - mse: 11.0875\n",
      "Epoch 256: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.7411 - mse: 11.7411 - val_loss: 25.9213 - val_mse: 25.9213\n",
      "Epoch 257/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.7619 - mse: 11.7619\n",
      "Epoch 257: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.8868 - mse: 11.8868 - val_loss: 25.3327 - val_mse: 25.3327\n",
      "Epoch 258/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.6527 - mse: 15.6527\n",
      "Epoch 258: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.8663 - mse: 11.8663 - val_loss: 25.8705 - val_mse: 25.8705\n",
      "Epoch 259/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.3129 - mse: 10.3129\n",
      "Epoch 259: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.5959 - mse: 13.5959 - val_loss: 25.6334 - val_mse: 25.6334\n",
      "Epoch 260/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.6359 - mse: 9.6359\n",
      "Epoch 260: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.9601 - mse: 13.9601 - val_loss: 26.1432 - val_mse: 26.1432\n",
      "Epoch 261/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.7251 - mse: 22.7251\n",
      "Epoch 261: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.9290 - mse: 11.9290 - val_loss: 28.6826 - val_mse: 28.6826\n",
      "Epoch 262/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.4530 - mse: 8.4530\n",
      "Epoch 262: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.6684 - mse: 12.6684 - val_loss: 30.0176 - val_mse: 30.0176\n",
      "Epoch 263/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.2847 - mse: 14.2847\n",
      "Epoch 263: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 16.6186 - mse: 16.6186 - val_loss: 27.2582 - val_mse: 27.2582\n",
      "Epoch 264/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.6376 - mse: 9.6376\n",
      "Epoch 264: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 13.8428 - mse: 13.8428 - val_loss: 26.8403 - val_mse: 26.8403\n",
      "Epoch 265/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 7.1051 - mse: 7.1051\n",
      "Epoch 265: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.8904 - mse: 11.8904 - val_loss: 27.1768 - val_mse: 27.1768\n",
      "Epoch 266/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.2116 - mse: 10.2116\n",
      "Epoch 266: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.7787 - mse: 12.7787 - val_loss: 25.8210 - val_mse: 25.8210\n",
      "Epoch 267/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.8954 - mse: 8.8954\n",
      "Epoch 267: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.5652 - mse: 11.5652 - val_loss: 29.7990 - val_mse: 29.7990\n",
      "Epoch 268/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.4240 - mse: 16.4240\n",
      "Epoch 268: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.8683 - mse: 11.8683 - val_loss: 27.4053 - val_mse: 27.4053\n",
      "Epoch 269/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.9759 - mse: 12.9759\n",
      "Epoch 269: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.1041 - mse: 12.1041 - val_loss: 25.5051 - val_mse: 25.5051\n",
      "Epoch 270/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.1892 - mse: 14.1892\n",
      "Epoch 270: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.2192 - mse: 12.2192 - val_loss: 26.2188 - val_mse: 26.2188\n",
      "Epoch 271/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.0198 - mse: 10.0198\n",
      "Epoch 271: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.7765 - mse: 11.7765 - val_loss: 27.1843 - val_mse: 27.1843\n",
      "Epoch 272/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.5937 - mse: 11.5937\n",
      "Epoch 272: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.6937 - mse: 11.6937 - val_loss: 25.7663 - val_mse: 25.7663\n",
      "Epoch 273/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.4766 - mse: 13.4766\n",
      "Epoch 273: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 10.9363 - mse: 10.9363 - val_loss: 24.7769 - val_mse: 24.7769\n",
      "Epoch 274/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.2090 - mse: 13.2090\n",
      "Epoch 274: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.3686 - mse: 11.3686 - val_loss: 25.6856 - val_mse: 25.6856\n",
      "Epoch 275/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.3847 - mse: 13.3847\n",
      "Epoch 275: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.9296 - mse: 11.9296 - val_loss: 26.4303 - val_mse: 26.4303\n",
      "Epoch 276/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 0s - loss: 7.6113 - mse: 7.6113\n",
      "Epoch 276: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.9415 - mse: 12.9415 - val_loss: 24.8804 - val_mse: 24.8804\n",
      "Epoch 277/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.3075 - mse: 14.3075\n",
      "Epoch 277: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.7713 - mse: 11.7713 - val_loss: 30.2647 - val_mse: 30.2647\n",
      "Epoch 278/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.3505 - mse: 9.3505\n",
      "Epoch 278: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.8420 - mse: 11.8420 - val_loss: 24.9127 - val_mse: 24.9127\n",
      "Epoch 279/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 5.6154 - mse: 5.6154\n",
      "Epoch 279: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.1427 - mse: 12.1427 - val_loss: 28.0436 - val_mse: 28.0436\n",
      "Epoch 280/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.9268 - mse: 14.9268\n",
      "Epoch 280: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 13.7789 - mse: 13.7789 - val_loss: 26.5505 - val_mse: 26.5505\n",
      "Epoch 281/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.8850 - mse: 12.8850\n",
      "Epoch 281: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.0880 - mse: 11.0880 - val_loss: 28.1233 - val_mse: 28.1233\n",
      "Epoch 282/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 7.4276 - mse: 7.4276\n",
      "Epoch 282: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.9016 - mse: 11.9016 - val_loss: 24.3198 - val_mse: 24.3198\n",
      "Epoch 283/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.9681 - mse: 12.9681\n",
      "Epoch 283: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.8850 - mse: 11.8850 - val_loss: 25.7528 - val_mse: 25.7528\n",
      "Epoch 284/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.1340 - mse: 13.1340\n",
      "Epoch 284: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.9190 - mse: 11.9190 - val_loss: 25.1561 - val_mse: 25.1561\n",
      "Epoch 285/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.0138 - mse: 12.0138\n",
      "Epoch 285: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 11.1144 - mse: 11.1144 - val_loss: 24.7836 - val_mse: 24.7836\n",
      "Epoch 286/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.8531 - mse: 10.8531\n",
      "Epoch 286: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 12.4068 - mse: 12.4068 - val_loss: 24.8952 - val_mse: 24.8952\n",
      "Epoch 287/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.6981 - mse: 13.6981\n",
      "Epoch 287: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.6710 - mse: 11.6710 - val_loss: 27.0547 - val_mse: 27.0547\n",
      "Epoch 288/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 6.6464 - mse: 6.6464\n",
      "Epoch 288: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.3365 - mse: 11.3365 - val_loss: 25.9396 - val_mse: 25.9396\n",
      "Epoch 289/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 7.3395 - mse: 7.3395\n",
      "Epoch 289: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.6708 - mse: 11.6708 - val_loss: 25.3662 - val_mse: 25.3662\n",
      "Epoch 290/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.8287 - mse: 14.8287\n",
      "Epoch 290: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 12.4298 - mse: 12.4298 - val_loss: 28.3445 - val_mse: 28.3445\n",
      "Epoch 291/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.8773 - mse: 21.8773\n",
      "Epoch 291: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 16.1057 - mse: 16.1057 - val_loss: 27.6009 - val_mse: 27.6009\n",
      "Epoch 292/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.5749 - mse: 9.5749\n",
      "Epoch 292: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 13.2133 - mse: 13.2133 - val_loss: 24.0227 - val_mse: 24.0227\n",
      "Epoch 293/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.8044 - mse: 13.8044\n",
      "Epoch 293: val_mse did not improve from 23.81997\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 11.9362 - mse: 11.9362 - val_loss: 26.2495 - val_mse: 26.2495\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.3, \n",
    "                    epochs=2000, \n",
    "                    batch_size=30, \n",
    "                    verbose=1, \n",
    "                    callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cadebfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "14.2      15.953257\n",
      "15.6      18.447096\n",
      "23.7      26.334473\n",
      "20.4      23.590078\n",
      "23.1      24.972622\n",
      "50.0      51.45078\n",
      "23.2      16.75565\n",
      "36.0      32.751682\n",
      "17.1      18.648365\n",
      "14.1      11.5074\n"
     ]
    }
   ],
   "source": [
    "# 예측 값과 실제 값의 비교\n",
    "y_prediction = model.predict(X_test).flatten()\n",
    "# flatten : 데이터 배열이 몇 차원이든 모두 1차원으로 바꿔 읽기 쉽게 해 주는 함수\n",
    "\n",
    "# 10개 실제값과 예측값 비교\n",
    "for i in range(10):\n",
    "    label = y_test[i]\n",
    "    prediction = y_prediction[i]\n",
    "    print(label, \"    \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7650696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어느정도 실제값을 잘 예측하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529cd3b",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b4b948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 수: 293\n"
     ]
    }
   ],
   "source": [
    "# y_acc 에 학습 셋으로 측정한 정확도의 값을 저장\n",
    "y_vmse = history.history['val_mse']\n",
    "y_mse = history.history['mse']\n",
    "\n",
    "# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = np.arange(len(y_mse))\n",
    "print('epoch 수:', len(x_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81a7df03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_len, y_vmse, \"o\", c=\"red\", markersize=3, label='val_mse')\n",
    "plt.plot(x_len, y_mse, \"o\", c=\"blue\", markersize=3, label='mse')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(0, 70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a4655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
