{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f8781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.16\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8264d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0fe6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcde4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "\n",
       "       11    12    13  \n",
       "0  396.90  4.98  24.0  \n",
       "1  396.90  9.14  21.6  \n",
       "2  392.83  4.03  34.7  \n",
       "3  394.63  2.94  33.4  \n",
       "4  396.90  5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"../dataset/housing.csv\", delim_whitespace=True, header=None)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe565ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00, 2.4000e+01],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00, 2.1600e+01],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00, 3.4700e+01],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00, 3.3400e+01],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00, 3.6200e+01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "print(dataset.shape)\n",
    "dataset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbce0214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13)\n",
      "(152, 13)\n",
      "(354,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "X = dataset[:, 0:13]\n",
    "y = dataset[:, 13]\n",
    "\n",
    "# sklearn의 train_test_split 사용해서 test 데이터 생성\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.3, random_state=2023)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b50796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모델 선언\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))  # 입력층\n",
    "                                                       # 은닉층1\n",
    "    \n",
    "model.add(Dense(25, activation='relu'))                # 은닉층2\n",
    "model.add(Dense(15, activation='relu'))                # 은닉층3\n",
    "model.add(Dense(6, activation='relu'))                 # 은닉층4\n",
    "model.add(Dense(1))                                    # 출력층\n",
    "# 선형 회귀는 마지막에 참과 거짓을 구분할 필요가 없음. 출력층에 활성화 함수를 지정할 필요도 없음\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam', \n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed28953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_mse', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_mse', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1195484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/9 [==>...........................] - ETA: 5s - loss: 1002.2432 - mse: 1002.2432\n",
      "Epoch 1: val_mse improved from inf to 134.71857, saving model to ./model/01-134.7186.hdf5\n",
      "9/9 [==============================] - 1s 28ms/step - loss: 288.7239 - mse: 288.7239 - val_loss: 134.7186 - val_mse: 134.7186\n",
      "Epoch 2/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 80.0808 - mse: 80.0808\n",
      "Epoch 2: val_mse improved from 134.71857 to 97.83902, saving model to ./model/02-97.8390.hdf5\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 94.3073 - mse: 94.3073 - val_loss: 97.8390 - val_mse: 97.8390\n",
      "Epoch 3/2000\n",
      "5/9 [===============>..............] - ETA: 0s - loss: 109.6537 - mse: 109.6537\n",
      "Epoch 3: val_mse improved from 97.83902 to 64.46247, saving model to ./model/03-64.4625.hdf5\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 102.4770 - mse: 102.4770 - val_loss: 64.4625 - val_mse: 64.4625\n",
      "Epoch 4/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 69.7076 - mse: 69.7076\n",
      "Epoch 4: val_mse did not improve from 64.46247\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 77.3515 - mse: 77.3515 - val_loss: 67.2587 - val_mse: 67.2587\n",
      "Epoch 5/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 78.1970 - mse: 78.1970\n",
      "Epoch 5: val_mse did not improve from 64.46247\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 75.4026 - mse: 75.4026 - val_loss: 64.6214 - val_mse: 64.6214\n",
      "Epoch 6/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 57.8046 - mse: 57.8046\n",
      "Epoch 6: val_mse did not improve from 64.46247\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 72.8367 - mse: 72.8367 - val_loss: 64.8866 - val_mse: 64.8866\n",
      "Epoch 7/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 26.9206 - mse: 26.9206\n",
      "Epoch 7: val_mse did not improve from 64.46247\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 67.1698 - mse: 67.1698 - val_loss: 65.1306 - val_mse: 65.1306\n",
      "Epoch 8/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 79.2146 - mse: 79.2146\n",
      "Epoch 8: val_mse did not improve from 64.46247\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 68.7046 - mse: 68.7046 - val_loss: 65.3873 - val_mse: 65.3873\n",
      "Epoch 9/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 111.8323 - mse: 111.8323\n",
      "Epoch 9: val_mse improved from 64.46247 to 59.71521, saving model to ./model/09-59.7152.hdf5\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 68.2317 - mse: 68.2317 - val_loss: 59.7152 - val_mse: 59.7152\n",
      "Epoch 10/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.5964 - mse: 27.5964\n",
      "Epoch 10: val_mse did not improve from 59.71521\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 64.7470 - mse: 64.7470 - val_loss: 63.3740 - val_mse: 63.3740\n",
      "Epoch 11/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 63.4252 - mse: 63.4252\n",
      "Epoch 11: val_mse did not improve from 59.71521\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 63.2948 - mse: 63.2948 - val_loss: 61.7993 - val_mse: 61.7993\n",
      "Epoch 12/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 133.3979 - mse: 133.3979\n",
      "Epoch 12: val_mse did not improve from 59.71521\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 63.7834 - mse: 63.7834 - val_loss: 59.8524 - val_mse: 59.8524\n",
      "Epoch 13/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 61.4230 - mse: 61.4230\n",
      "Epoch 13: val_mse improved from 59.71521 to 58.41122, saving model to ./model/13-58.4112.hdf5\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 63.2461 - mse: 63.2461 - val_loss: 58.4112 - val_mse: 58.4112\n",
      "Epoch 14/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 70.6773 - mse: 70.6773\n",
      "Epoch 14: val_mse improved from 58.41122 to 57.45892, saving model to ./model/14-57.4589.hdf5\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 69.0574 - mse: 69.0574 - val_loss: 57.4589 - val_mse: 57.4589\n",
      "Epoch 15/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 85.1019 - mse: 85.1019\n",
      "Epoch 15: val_mse improved from 57.45892 to 55.99799, saving model to ./model/15-55.9980.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 67.8384 - mse: 67.8384 - val_loss: 55.9980 - val_mse: 55.9980\n",
      "Epoch 16/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 38.8525 - mse: 38.8525\n",
      "Epoch 16: val_mse did not improve from 55.99799\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 62.5321 - mse: 62.5321 - val_loss: 57.4745 - val_mse: 57.4745\n",
      "Epoch 17/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.6953 - mse: 36.6953\n",
      "Epoch 17: val_mse did not improve from 55.99799\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 58.6660 - mse: 58.6660 - val_loss: 57.5271 - val_mse: 57.5271\n",
      "Epoch 18/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 43.7715 - mse: 43.7715\n",
      "Epoch 18: val_mse improved from 55.99799 to 55.44391, saving model to ./model/18-55.4439.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 61.7842 - mse: 61.7842 - val_loss: 55.4439 - val_mse: 55.4439\n",
      "Epoch 19/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 88.1123 - mse: 88.1123\n",
      "Epoch 19: val_mse improved from 55.44391 to 53.80613, saving model to ./model/19-53.8061.hdf5\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 57.7954 - mse: 57.7954 - val_loss: 53.8061 - val_mse: 53.8061\n",
      "Epoch 20/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 56.5198 - mse: 56.5198\n",
      "Epoch 20: val_mse improved from 53.80613 to 52.85545, saving model to ./model/20-52.8555.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 55.4594 - mse: 55.4594 - val_loss: 52.8555 - val_mse: 52.8555\n",
      "Epoch 21/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 35.9710 - mse: 35.9710\n",
      "Epoch 21: val_mse did not improve from 52.85545\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 54.2291 - mse: 54.2291 - val_loss: 55.9878 - val_mse: 55.9878\n",
      "Epoch 22/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.8740 - mse: 22.8740\n",
      "Epoch 22: val_mse did not improve from 52.85545\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 54.5213 - mse: 54.5213 - val_loss: 55.5392 - val_mse: 55.5392\n",
      "Epoch 23/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 38.9991 - mse: 38.9991\n",
      "Epoch 23: val_mse did not improve from 52.85545\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 54.5900 - mse: 54.5900 - val_loss: 53.1141 - val_mse: 53.1141\n",
      "Epoch 24/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 50.9246 - mse: 50.9246\n",
      "Epoch 24: val_mse did not improve from 52.85545\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 52.4676 - mse: 52.4676 - val_loss: 54.0712 - val_mse: 54.0712\n",
      "Epoch 25/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.2365 - mse: 27.2365\n",
      "Epoch 25: val_mse improved from 52.85545 to 52.28609, saving model to ./model/25-52.2861.hdf5\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 51.7450 - mse: 51.7450 - val_loss: 52.2861 - val_mse: 52.2861\n",
      "Epoch 26/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 26.4841 - mse: 26.4841\n",
      "Epoch 26: val_mse did not improve from 52.28609\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 51.1672 - mse: 51.1672 - val_loss: 52.4364 - val_mse: 52.4364\n",
      "Epoch 27/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 38.9573 - mse: 38.9573\n",
      "Epoch 27: val_mse did not improve from 52.28609\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 50.8438 - mse: 50.8438 - val_loss: 54.7311 - val_mse: 54.7311\n",
      "Epoch 28/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 51.8366 - mse: 51.8366\n",
      "Epoch 28: val_mse did not improve from 52.28609\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 50.7512 - mse: 50.7512 - val_loss: 54.5637 - val_mse: 54.5637\n",
      "Epoch 29/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 63.9436 - mse: 63.9436\n",
      "Epoch 29: val_mse did not improve from 52.28609\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 49.0490 - mse: 49.0490 - val_loss: 52.5767 - val_mse: 52.5767\n",
      "Epoch 30/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 55.1941 - mse: 55.1941\n",
      "Epoch 30: val_mse improved from 52.28609 to 51.48079, saving model to ./model/30-51.4808.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 8ms/step - loss: 48.5183 - mse: 48.5183 - val_loss: 51.4808 - val_mse: 51.4808\n",
      "Epoch 31/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.0755 - mse: 27.0755\n",
      "Epoch 31: val_mse did not improve from 51.48079\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 50.3378 - mse: 50.3378 - val_loss: 52.6756 - val_mse: 52.6756\n",
      "Epoch 32/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 75.0408 - mse: 75.0408\n",
      "Epoch 32: val_mse improved from 51.48079 to 49.53249, saving model to ./model/32-49.5325.hdf5\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 48.2626 - mse: 48.2626 - val_loss: 49.5325 - val_mse: 49.5325\n",
      "Epoch 33/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 37.0513 - mse: 37.0513\n",
      "Epoch 33: val_mse did not improve from 49.53249\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 47.6963 - mse: 47.6963 - val_loss: 50.2783 - val_mse: 50.2783\n",
      "Epoch 34/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 58.0957 - mse: 58.0957\n",
      "Epoch 34: val_mse did not improve from 49.53249\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 45.9442 - mse: 45.9442 - val_loss: 51.1128 - val_mse: 51.1128\n",
      "Epoch 35/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 39.0190 - mse: 39.0190\n",
      "Epoch 35: val_mse did not improve from 49.53249\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 45.8487 - mse: 45.8487 - val_loss: 56.4858 - val_mse: 56.4858\n",
      "Epoch 36/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 52.7849 - mse: 52.7849\n",
      "Epoch 36: val_mse did not improve from 49.53249\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 47.0338 - mse: 47.0338 - val_loss: 50.6859 - val_mse: 50.6859\n",
      "Epoch 37/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.0465 - mse: 22.0465\n",
      "Epoch 37: val_mse improved from 49.53249 to 48.97083, saving model to ./model/37-48.9708.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 43.0673 - mse: 43.0673 - val_loss: 48.9708 - val_mse: 48.9708\n",
      "Epoch 38/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 49.4054 - mse: 49.4054\n",
      "Epoch 38: val_mse improved from 48.97083 to 48.59412, saving model to ./model/38-48.5941.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 43.1369 - mse: 43.1369 - val_loss: 48.5941 - val_mse: 48.5941\n",
      "Epoch 39/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 55.4919 - mse: 55.4919\n",
      "Epoch 39: val_mse improved from 48.59412 to 47.66567, saving model to ./model/39-47.6657.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 43.7693 - mse: 43.7693 - val_loss: 47.6657 - val_mse: 47.6657\n",
      "Epoch 40/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.5389 - mse: 20.5389\n",
      "Epoch 40: val_mse did not improve from 47.66567\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 44.0602 - mse: 44.0602 - val_loss: 51.5699 - val_mse: 51.5699\n",
      "Epoch 41/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 76.4436 - mse: 76.4436\n",
      "Epoch 41: val_mse did not improve from 47.66567\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 42.1774 - mse: 42.1774 - val_loss: 48.2084 - val_mse: 48.2084\n",
      "Epoch 42/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.4571 - mse: 20.4571\n",
      "Epoch 42: val_mse improved from 47.66567 to 46.45669, saving model to ./model/42-46.4567.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 40.9826 - mse: 40.9826 - val_loss: 46.4567 - val_mse: 46.4567\n",
      "Epoch 43/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 32.5431 - mse: 32.5431\n",
      "Epoch 43: val_mse improved from 46.45669 to 45.47689, saving model to ./model/43-45.4769.hdf5\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 41.6926 - mse: 41.6926 - val_loss: 45.4769 - val_mse: 45.4769\n",
      "Epoch 44/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 48.9642 - mse: 48.9642\n",
      "Epoch 44: val_mse did not improve from 45.47689\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 41.0114 - mse: 41.0114 - val_loss: 48.2251 - val_mse: 48.2251\n",
      "Epoch 45/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 92.7613 - mse: 92.7613\n",
      "Epoch 45: val_mse did not improve from 45.47689\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 40.0315 - mse: 40.0315 - val_loss: 46.0043 - val_mse: 46.0043\n",
      "Epoch 46/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.6465 - mse: 36.6465\n",
      "Epoch 46: val_mse improved from 45.47689 to 43.23768, saving model to ./model/46-43.2377.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 39.3450 - mse: 39.3450 - val_loss: 43.2377 - val_mse: 43.2377\n",
      "Epoch 47/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 61.1493 - mse: 61.1493\n",
      "Epoch 47: val_mse did not improve from 43.23768\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 38.9270 - mse: 38.9270 - val_loss: 47.1512 - val_mse: 47.1512\n",
      "Epoch 48/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 52.1039 - mse: 52.1039\n",
      "Epoch 48: val_mse did not improve from 43.23768\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 38.4335 - mse: 38.4335 - val_loss: 45.5170 - val_mse: 45.5170\n",
      "Epoch 49/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.4645 - mse: 21.4645\n",
      "Epoch 49: val_mse did not improve from 43.23768\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 38.9169 - mse: 38.9169 - val_loss: 50.6922 - val_mse: 50.6922\n",
      "Epoch 50/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 35.3155 - mse: 35.3155\n",
      "Epoch 50: val_mse did not improve from 43.23768\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 43.5556 - mse: 43.5556 - val_loss: 50.2578 - val_mse: 50.2578\n",
      "Epoch 51/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 28.4170 - mse: 28.4170\n",
      "Epoch 51: val_mse improved from 43.23768 to 42.64492, saving model to ./model/51-42.6449.hdf5\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 37.3101 - mse: 37.3101 - val_loss: 42.6449 - val_mse: 42.6449\n",
      "Epoch 52/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 58.4315 - mse: 58.4315\n",
      "Epoch 52: val_mse improved from 42.64492 to 40.18704, saving model to ./model/52-40.1870.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 37.8302 - mse: 37.8302 - val_loss: 40.1870 - val_mse: 40.1870\n",
      "Epoch 53/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.9964 - mse: 20.9964\n",
      "Epoch 53: val_mse did not improve from 40.18704\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35.4749 - mse: 35.4749 - val_loss: 44.5598 - val_mse: 44.5598\n",
      "Epoch 54/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 37.9916 - mse: 37.9916\n",
      "Epoch 54: val_mse did not improve from 40.18704\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 36.2585 - mse: 36.2585 - val_loss: 45.6125 - val_mse: 45.6125\n",
      "Epoch 55/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.4706 - mse: 14.4706\n",
      "Epoch 55: val_mse did not improve from 40.18704\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35.4819 - mse: 35.4819 - val_loss: 40.9712 - val_mse: 40.9712\n",
      "Epoch 56/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 39.6702 - mse: 39.6702\n",
      "Epoch 56: val_mse improved from 40.18704 to 38.32761, saving model to ./model/56-38.3276.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 39.9168 - mse: 39.9168 - val_loss: 38.3276 - val_mse: 38.3276\n",
      "Epoch 57/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 66.2260 - mse: 66.2260\n",
      "Epoch 57: val_mse did not improve from 38.32761\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 37.7173 - mse: 37.7173 - val_loss: 45.6567 - val_mse: 45.6567\n",
      "Epoch 58/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 38.1038 - mse: 38.1038\n",
      "Epoch 58: val_mse did not improve from 38.32761\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35.5975 - mse: 35.5975 - val_loss: 38.3849 - val_mse: 38.3849\n",
      "Epoch 59/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.2545 - mse: 16.2545\n",
      "Epoch 59: val_mse did not improve from 38.32761\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 34.5585 - mse: 34.5585 - val_loss: 41.2908 - val_mse: 41.2908\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 0s - loss: 57.9397 - mse: 57.9397\n",
      "Epoch 60: val_mse did not improve from 38.32761\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 34.6334 - mse: 34.6334 - val_loss: 41.5993 - val_mse: 41.5993\n",
      "Epoch 61/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 34.2211 - mse: 34.2211\n",
      "Epoch 61: val_mse did not improve from 38.32761\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 32.8794 - mse: 32.8794 - val_loss: 39.6108 - val_mse: 39.6108\n",
      "Epoch 62/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.7258 - mse: 17.7258\n",
      "Epoch 62: val_mse did not improve from 38.32761\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 32.9999 - mse: 32.9999 - val_loss: 43.2377 - val_mse: 43.2377\n",
      "Epoch 63/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 46.7358 - mse: 46.7358\n",
      "Epoch 63: val_mse did not improve from 38.32761\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 36.5315 - mse: 36.5315 - val_loss: 46.7875 - val_mse: 46.7875\n",
      "Epoch 64/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 35.7909 - mse: 35.7909\n",
      "Epoch 64: val_mse improved from 38.32761 to 38.14637, saving model to ./model/64-38.1464.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 35.5557 - mse: 35.5557 - val_loss: 38.1464 - val_mse: 38.1464\n",
      "Epoch 65/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 45.2851 - mse: 45.2851\n",
      "Epoch 65: val_mse did not improve from 38.14637\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 31.1106 - mse: 31.1106 - val_loss: 40.9410 - val_mse: 40.9410\n",
      "Epoch 66/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.8620 - mse: 14.8620\n",
      "Epoch 66: val_mse did not improve from 38.14637\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 30.9968 - mse: 30.9968 - val_loss: 38.4647 - val_mse: 38.4647\n",
      "Epoch 67/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.2624 - mse: 17.2624\n",
      "Epoch 67: val_mse improved from 38.14637 to 36.73549, saving model to ./model/67-36.7355.hdf5\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 31.7343 - mse: 31.7343 - val_loss: 36.7355 - val_mse: 36.7355\n",
      "Epoch 68/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 66.0553 - mse: 66.0553\n",
      "Epoch 68: val_mse did not improve from 36.73549\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 32.5981 - mse: 32.5981 - val_loss: 41.6879 - val_mse: 41.6879\n",
      "Epoch 69/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.6323 - mse: 21.6323\n",
      "Epoch 69: val_mse did not improve from 36.73549\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 30.0771 - mse: 30.0771 - val_loss: 39.3190 - val_mse: 39.3190\n",
      "Epoch 70/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.2851 - mse: 22.2851\n",
      "Epoch 70: val_mse did not improve from 36.73549\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 34.6056 - mse: 34.6056 - val_loss: 39.7568 - val_mse: 39.7568\n",
      "Epoch 71/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 4.8391 - mse: 4.8391\n",
      "Epoch 71: val_mse did not improve from 36.73549\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 29.9423 - mse: 29.9423 - val_loss: 37.3618 - val_mse: 37.3618\n",
      "Epoch 72/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.6263 - mse: 11.6263\n",
      "Epoch 72: val_mse did not improve from 36.73549\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 31.8229 - mse: 31.8229 - val_loss: 38.0954 - val_mse: 38.0954\n",
      "Epoch 73/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.8177 - mse: 20.8177\n",
      "Epoch 73: val_mse improved from 36.73549 to 36.31136, saving model to ./model/73-36.3114.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 28.8943 - mse: 28.8943 - val_loss: 36.3114 - val_mse: 36.3114\n",
      "Epoch 74/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 29.8435 - mse: 29.8435\n",
      "Epoch 74: val_mse did not improve from 36.31136\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 30.6081 - mse: 30.6081 - val_loss: 40.2309 - val_mse: 40.2309\n",
      "Epoch 75/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.5566 - mse: 21.5566\n",
      "Epoch 75: val_mse improved from 36.31136 to 35.90536, saving model to ./model/75-35.9054.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 30.1769 - mse: 30.1769 - val_loss: 35.9054 - val_mse: 35.9054\n",
      "Epoch 76/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 25.3494 - mse: 25.3494\n",
      "Epoch 76: val_mse did not improve from 35.90536\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 31.0069 - mse: 31.0069 - val_loss: 40.5585 - val_mse: 40.5585\n",
      "Epoch 77/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 25.8633 - mse: 25.8633\n",
      "Epoch 77: val_mse did not improve from 35.90536\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 31.3775 - mse: 31.3775 - val_loss: 44.0195 - val_mse: 44.0195\n",
      "Epoch 78/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 39.5732 - mse: 39.5732\n",
      "Epoch 78: val_mse did not improve from 35.90536\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 32.2533 - mse: 32.2533 - val_loss: 36.1044 - val_mse: 36.1044\n",
      "Epoch 79/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 39.2856 - mse: 39.2856\n",
      "Epoch 79: val_mse did not improve from 35.90536\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 31.7511 - mse: 31.7511 - val_loss: 38.2657 - val_mse: 38.2657\n",
      "Epoch 80/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 37.3184 - mse: 37.3184\n",
      "Epoch 80: val_mse improved from 35.90536 to 34.56664, saving model to ./model/80-34.5666.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 28.0915 - mse: 28.0915 - val_loss: 34.5666 - val_mse: 34.5666\n",
      "Epoch 81/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 40.3445 - mse: 40.3445\n",
      "Epoch 81: val_mse did not improve from 34.56664\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 28.1466 - mse: 28.1466 - val_loss: 39.9645 - val_mse: 39.9645\n",
      "Epoch 82/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 37.6401 - mse: 37.6401\n",
      "Epoch 82: val_mse improved from 34.56664 to 33.64468, saving model to ./model/82-33.6447.hdf5\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 27.9345 - mse: 27.9345 - val_loss: 33.6447 - val_mse: 33.6447\n",
      "Epoch 83/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.4893 - mse: 27.4893\n",
      "Epoch 83: val_mse did not improve from 33.64468\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 27.1908 - mse: 27.1908 - val_loss: 34.4724 - val_mse: 34.4724\n",
      "Epoch 84/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.6274 - mse: 27.6274\n",
      "Epoch 84: val_mse did not improve from 33.64468\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 27.5554 - mse: 27.5554 - val_loss: 35.7035 - val_mse: 35.7035\n",
      "Epoch 85/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 33.1861 - mse: 33.1861\n",
      "Epoch 85: val_mse did not improve from 33.64468\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 25.1660 - mse: 25.1660 - val_loss: 34.4217 - val_mse: 34.4217\n",
      "Epoch 86/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.5869 - mse: 22.5869\n",
      "Epoch 86: val_mse did not improve from 33.64468\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 25.2969 - mse: 25.2969 - val_loss: 40.5631 - val_mse: 40.5631\n",
      "Epoch 87/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.1237 - mse: 23.1237\n",
      "Epoch 87: val_mse did not improve from 33.64468\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 27.7346 - mse: 27.7346 - val_loss: 34.4601 - val_mse: 34.4601\n",
      "Epoch 88/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.3149 - mse: 36.3149\n",
      "Epoch 88: val_mse did not improve from 33.64468\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 25.9421 - mse: 25.9421 - val_loss: 35.3721 - val_mse: 35.3721\n",
      "Epoch 89/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.1355 - mse: 27.1355\n",
      "Epoch 89: val_mse did not improve from 33.64468\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 29.8728 - mse: 29.8728 - val_loss: 33.7193 - val_mse: 33.7193\n",
      "Epoch 90/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.6114 - mse: 9.6114\n",
      "Epoch 90: val_mse did not improve from 33.64468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 26.8289 - mse: 26.8289 - val_loss: 34.2521 - val_mse: 34.2521\n",
      "Epoch 91/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.8604 - mse: 23.8604\n",
      "Epoch 91: val_mse did not improve from 33.64468\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 25.5522 - mse: 25.5522 - val_loss: 34.2018 - val_mse: 34.2018\n",
      "Epoch 92/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 33.1357 - mse: 33.1357\n",
      "Epoch 92: val_mse improved from 33.64468 to 33.00857, saving model to ./model/92-33.0086.hdf5\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 24.3642 - mse: 24.3642 - val_loss: 33.0086 - val_mse: 33.0086\n",
      "Epoch 93/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 38.6122 - mse: 38.6122\n",
      "Epoch 93: val_mse improved from 33.00857 to 32.32452, saving model to ./model/93-32.3245.hdf5\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 24.1246 - mse: 24.1246 - val_loss: 32.3245 - val_mse: 32.3245\n",
      "Epoch 94/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.8475 - mse: 23.8475\n",
      "Epoch 94: val_mse did not improve from 32.32452\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 24.0290 - mse: 24.0290 - val_loss: 32.3922 - val_mse: 32.3922\n",
      "Epoch 95/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.5454 - mse: 20.5454\n",
      "Epoch 95: val_mse did not improve from 32.32452\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 25.9750 - mse: 25.9750 - val_loss: 46.3260 - val_mse: 46.3260\n",
      "Epoch 96/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 31.6306 - mse: 31.6306\n",
      "Epoch 96: val_mse improved from 32.32452 to 31.57047, saving model to ./model/96-31.5705.hdf5\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 32.2239 - mse: 32.2239 - val_loss: 31.5705 - val_mse: 31.5705\n",
      "Epoch 97/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.9327 - mse: 16.9327\n",
      "Epoch 97: val_mse did not improve from 31.57047\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 27.1978 - mse: 27.1978 - val_loss: 37.4252 - val_mse: 37.4252\n",
      "Epoch 98/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 38.7269 - mse: 38.7269\n",
      "Epoch 98: val_mse did not improve from 31.57047\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 28.9170 - mse: 28.9170 - val_loss: 39.7763 - val_mse: 39.7763\n",
      "Epoch 99/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.6275 - mse: 11.6275\n",
      "Epoch 99: val_mse did not improve from 31.57047\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 26.8068 - mse: 26.8068 - val_loss: 34.0067 - val_mse: 34.0067\n",
      "Epoch 100/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.5338 - mse: 13.5338\n",
      "Epoch 100: val_mse did not improve from 31.57047\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 25.6443 - mse: 25.6443 - val_loss: 31.8211 - val_mse: 31.8211\n",
      "Epoch 101/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 33.4802 - mse: 33.4802\n",
      "Epoch 101: val_mse did not improve from 31.57047\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 24.8560 - mse: 24.8560 - val_loss: 33.0088 - val_mse: 33.0088\n",
      "Epoch 102/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.6376 - mse: 18.6376\n",
      "Epoch 102: val_mse did not improve from 31.57047\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 23.9782 - mse: 23.9782 - val_loss: 32.9562 - val_mse: 32.9562\n",
      "Epoch 103/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.3638 - mse: 23.3638\n",
      "Epoch 103: val_mse did not improve from 31.57047\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 23.6587 - mse: 23.6587 - val_loss: 37.4880 - val_mse: 37.4880\n",
      "Epoch 104/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 40.1513 - mse: 40.1513\n",
      "Epoch 104: val_mse did not improve from 31.57047\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 25.8643 - mse: 25.8643 - val_loss: 31.5783 - val_mse: 31.5783\n",
      "Epoch 105/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 31.9298 - mse: 31.9298\n",
      "Epoch 105: val_mse improved from 31.57047 to 30.41055, saving model to ./model/105-30.4106.hdf5\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 22.9180 - mse: 22.9180 - val_loss: 30.4106 - val_mse: 30.4106\n",
      "Epoch 106/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.9443 - mse: 27.9443\n",
      "Epoch 106: val_mse did not improve from 30.41055\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 23.2904 - mse: 23.2904 - val_loss: 33.7336 - val_mse: 33.7336\n",
      "Epoch 107/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.7410 - mse: 11.7410\n",
      "Epoch 107: val_mse did not improve from 30.41055\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 23.9768 - mse: 23.9768 - val_loss: 33.6968 - val_mse: 33.6968\n",
      "Epoch 108/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.3621 - mse: 17.3621\n",
      "Epoch 108: val_mse did not improve from 30.41055\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 23.3542 - mse: 23.3542 - val_loss: 38.5321 - val_mse: 38.5321\n",
      "Epoch 109/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.4407 - mse: 22.4407\n",
      "Epoch 109: val_mse did not improve from 30.41055\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 23.2992 - mse: 23.2992 - val_loss: 32.0172 - val_mse: 32.0172\n",
      "Epoch 110/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.9045 - mse: 15.9045\n",
      "Epoch 110: val_mse did not improve from 30.41055\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 22.2605 - mse: 22.2605 - val_loss: 48.9949 - val_mse: 48.9949\n",
      "Epoch 111/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 35.8957 - mse: 35.8957\n",
      "Epoch 111: val_mse did not improve from 30.41055\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 34.8263 - mse: 34.8263 - val_loss: 32.3522 - val_mse: 32.3522\n",
      "Epoch 112/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.8203 - mse: 11.8203\n",
      "Epoch 112: val_mse did not improve from 30.41055\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 22.9586 - mse: 22.9586 - val_loss: 31.7830 - val_mse: 31.7830\n",
      "Epoch 113/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.8263 - mse: 22.8263\n",
      "Epoch 113: val_mse improved from 30.41055 to 30.00502, saving model to ./model/113-30.0050.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 20.7992 - mse: 20.7992 - val_loss: 30.0050 - val_mse: 30.0050\n",
      "Epoch 114/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.4007 - mse: 21.4007\n",
      "Epoch 114: val_mse did not improve from 30.00502\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 21.7837 - mse: 21.7837 - val_loss: 30.0788 - val_mse: 30.0788\n",
      "Epoch 115/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.3462 - mse: 19.3462\n",
      "Epoch 115: val_mse did not improve from 30.00502\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 21.8796 - mse: 21.8796 - val_loss: 31.1829 - val_mse: 31.1829\n",
      "Epoch 116/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.0286 - mse: 11.0286\n",
      "Epoch 116: val_mse did not improve from 30.00502\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 21.0762 - mse: 21.0762 - val_loss: 30.8075 - val_mse: 30.8075\n",
      "Epoch 117/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 26.3199 - mse: 26.3199\n",
      "Epoch 117: val_mse improved from 30.00502 to 29.56311, saving model to ./model/117-29.5631.hdf5\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 20.5955 - mse: 20.5955 - val_loss: 29.5631 - val_mse: 29.5631\n",
      "Epoch 118/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.0924 - mse: 16.0924\n",
      "Epoch 118: val_mse did not improve from 29.56311\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 21.9293 - mse: 21.9293 - val_loss: 30.8429 - val_mse: 30.8429\n",
      "Epoch 119/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 26.3067 - mse: 26.3067\n",
      "Epoch 119: val_mse improved from 29.56311 to 29.31315, saving model to ./model/119-29.3131.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 22.6843 - mse: 22.6843 - val_loss: 29.3131 - val_mse: 29.3131\n",
      "Epoch 120/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.7449 - mse: 10.7449\n",
      "Epoch 120: val_mse did not improve from 29.31315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 20.2559 - mse: 20.2559 - val_loss: 32.8891 - val_mse: 32.8891\n",
      "Epoch 121/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 24.1399 - mse: 24.1399\n",
      "Epoch 121: val_mse did not improve from 29.31315\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 21.5613 - mse: 21.5613 - val_loss: 32.4843 - val_mse: 32.4843\n",
      "Epoch 122/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.1183 - mse: 16.1183\n",
      "Epoch 122: val_mse did not improve from 29.31315\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 20.9809 - mse: 20.9809 - val_loss: 30.6253 - val_mse: 30.6253\n",
      "Epoch 123/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.0337 - mse: 21.0337\n",
      "Epoch 123: val_mse did not improve from 29.31315\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 20.7980 - mse: 20.7980 - val_loss: 29.8082 - val_mse: 29.8082\n",
      "Epoch 124/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 26.6372 - mse: 26.6372\n",
      "Epoch 124: val_mse did not improve from 29.31315\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 20.1119 - mse: 20.1119 - val_loss: 32.6079 - val_mse: 32.6079\n",
      "Epoch 125/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.7172 - mse: 15.7172\n",
      "Epoch 125: val_mse did not improve from 29.31315\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 20.3855 - mse: 20.3855 - val_loss: 29.8930 - val_mse: 29.8930\n",
      "Epoch 126/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.0584 - mse: 14.0584\n",
      "Epoch 126: val_mse did not improve from 29.31315\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 21.4976 - mse: 21.4976 - val_loss: 30.0245 - val_mse: 30.0245\n",
      "Epoch 127/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.5577 - mse: 27.5577\n",
      "Epoch 127: val_mse improved from 29.31315 to 28.77290, saving model to ./model/127-28.7729.hdf5\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 22.4036 - mse: 22.4036 - val_loss: 28.7729 - val_mse: 28.7729\n",
      "Epoch 128/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.6022 - mse: 17.6022\n",
      "Epoch 128: val_mse did not improve from 28.77290\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 20.1541 - mse: 20.1541 - val_loss: 33.4374 - val_mse: 33.4374\n",
      "Epoch 129/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 32.4287 - mse: 32.4287\n",
      "Epoch 129: val_mse did not improve from 28.77290\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 21.0460 - mse: 21.0460 - val_loss: 29.7507 - val_mse: 29.7507\n",
      "Epoch 130/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 26.1942 - mse: 26.1942\n",
      "Epoch 130: val_mse did not improve from 28.77290\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 19.0599 - mse: 19.0599 - val_loss: 36.6293 - val_mse: 36.6293\n",
      "Epoch 131/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.3468 - mse: 22.3468\n",
      "Epoch 131: val_mse did not improve from 28.77290\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 27.5903 - mse: 27.5903 - val_loss: 31.3557 - val_mse: 31.3557\n",
      "Epoch 132/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.1414 - mse: 19.1414\n",
      "Epoch 132: val_mse did not improve from 28.77290\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 24.0616 - mse: 24.0616 - val_loss: 30.7692 - val_mse: 30.7692\n",
      "Epoch 133/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.4369 - mse: 19.4369\n",
      "Epoch 133: val_mse improved from 28.77290 to 28.57398, saving model to ./model/133-28.5740.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 19.3048 - mse: 19.3048 - val_loss: 28.5740 - val_mse: 28.5740\n",
      "Epoch 134/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.8667 - mse: 30.8667\n",
      "Epoch 134: val_mse improved from 28.57398 to 28.17153, saving model to ./model/134-28.1715.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 18.9211 - mse: 18.9211 - val_loss: 28.1715 - val_mse: 28.1715\n",
      "Epoch 135/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.7949 - mse: 18.7949\n",
      "Epoch 135: val_mse did not improve from 28.17153\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 18.4651 - mse: 18.4651 - val_loss: 31.8249 - val_mse: 31.8249\n",
      "Epoch 136/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.4849 - mse: 13.4849\n",
      "Epoch 136: val_mse did not improve from 28.17153\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 18.6419 - mse: 18.6419 - val_loss: 29.2394 - val_mse: 29.2394\n",
      "Epoch 137/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.1717 - mse: 17.1717\n",
      "Epoch 137: val_mse improved from 28.17153 to 27.47906, saving model to ./model/137-27.4791.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 18.9184 - mse: 18.9184 - val_loss: 27.4791 - val_mse: 27.4791\n",
      "Epoch 138/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.1923 - mse: 11.1923\n",
      "Epoch 138: val_mse improved from 27.47906 to 27.21838, saving model to ./model/138-27.2184.hdf5\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 20.4510 - mse: 20.4510 - val_loss: 27.2184 - val_mse: 27.2184\n",
      "Epoch 139/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.9077 - mse: 14.9077\n",
      "Epoch 139: val_mse did not improve from 27.21838\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 18.3022 - mse: 18.3022 - val_loss: 28.5635 - val_mse: 28.5635\n",
      "Epoch 140/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.1599 - mse: 8.1599\n",
      "Epoch 140: val_mse improved from 27.21838 to 26.70508, saving model to ./model/140-26.7051.hdf5\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 18.7519 - mse: 18.7519 - val_loss: 26.7051 - val_mse: 26.7051\n",
      "Epoch 141/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 31.4308 - mse: 31.4308\n",
      "Epoch 141: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 17.7002 - mse: 17.7002 - val_loss: 27.8246 - val_mse: 27.8246\n",
      "Epoch 142/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.3724 - mse: 21.3724\n",
      "Epoch 142: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 19.4286 - mse: 19.4286 - val_loss: 28.2335 - val_mse: 28.2335\n",
      "Epoch 143/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.0345 - mse: 13.0345\n",
      "Epoch 143: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 24.2504 - mse: 24.2504 - val_loss: 30.9430 - val_mse: 30.9430\n",
      "Epoch 144/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 6.0571 - mse: 6.0571\n",
      "Epoch 144: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 21.2163 - mse: 21.2163 - val_loss: 33.0875 - val_mse: 33.0875\n",
      "Epoch 145/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 30.4084 - mse: 30.4084\n",
      "Epoch 145: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 18.6175 - mse: 18.6175 - val_loss: 28.9587 - val_mse: 28.9587\n",
      "Epoch 146/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 21.1759 - mse: 21.1759\n",
      "Epoch 146: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 19.4202 - mse: 19.4202 - val_loss: 29.4303 - val_mse: 29.4303\n",
      "Epoch 147/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.9301 - mse: 23.9301\n",
      "Epoch 147: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 19.2111 - mse: 19.2111 - val_loss: 29.6903 - val_mse: 29.6903\n",
      "Epoch 148/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.6010 - mse: 14.6010\n",
      "Epoch 148: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 18.0333 - mse: 18.0333 - val_loss: 26.9327 - val_mse: 26.9327\n",
      "Epoch 149/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.8586 - mse: 12.8586\n",
      "Epoch 149: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 17.3572 - mse: 17.3572 - val_loss: 27.9399 - val_mse: 27.9399\n",
      "Epoch 150/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 28.1641 - mse: 28.1641\n",
      "Epoch 150: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 17.7030 - mse: 17.7030 - val_loss: 27.8409 - val_mse: 27.8409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.8152 - mse: 11.8152\n",
      "Epoch 151: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 18.1687 - mse: 18.1687 - val_loss: 36.9727 - val_mse: 36.9727\n",
      "Epoch 152/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.1916 - mse: 20.1916\n",
      "Epoch 152: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 19.4107 - mse: 19.4107 - val_loss: 29.2495 - val_mse: 29.2495\n",
      "Epoch 153/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 24.5690 - mse: 24.5690\n",
      "Epoch 153: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.7260 - mse: 17.7260 - val_loss: 33.4938 - val_mse: 33.4938\n",
      "Epoch 154/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.1910 - mse: 19.1910\n",
      "Epoch 154: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 26.9696 - mse: 26.9696 - val_loss: 30.5612 - val_mse: 30.5612\n",
      "Epoch 155/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.4938 - mse: 18.4938\n",
      "Epoch 155: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 24.1920 - mse: 24.1920 - val_loss: 33.0320 - val_mse: 33.0320\n",
      "Epoch 156/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.6590 - mse: 17.6590\n",
      "Epoch 156: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 22.1072 - mse: 22.1072 - val_loss: 27.5831 - val_mse: 27.5831\n",
      "Epoch 157/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.9219 - mse: 11.9219\n",
      "Epoch 157: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.7235 - mse: 15.7235 - val_loss: 27.6170 - val_mse: 27.6170\n",
      "Epoch 158/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.1085 - mse: 19.1085\n",
      "Epoch 158: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.6962 - mse: 16.6962 - val_loss: 26.8451 - val_mse: 26.8451\n",
      "Epoch 159/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.3143 - mse: 16.3143\n",
      "Epoch 159: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 18.3888 - mse: 18.3888 - val_loss: 31.7051 - val_mse: 31.7051\n",
      "Epoch 160/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.3898 - mse: 20.3898\n",
      "Epoch 160: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 18.9758 - mse: 18.9758 - val_loss: 32.6257 - val_mse: 32.6257\n",
      "Epoch 161/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.2284 - mse: 12.2284\n",
      "Epoch 161: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 16.6823 - mse: 16.6823 - val_loss: 28.9649 - val_mse: 28.9649\n",
      "Epoch 162/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.2521 - mse: 13.2521\n",
      "Epoch 162: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 16.5977 - mse: 16.5977 - val_loss: 30.2640 - val_mse: 30.2640\n",
      "Epoch 163/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.0172 - mse: 12.0172\n",
      "Epoch 163: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 17.8207 - mse: 17.8207 - val_loss: 34.7172 - val_mse: 34.7172\n",
      "Epoch 164/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.5839 - mse: 19.5839\n",
      "Epoch 164: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 20.9194 - mse: 20.9194 - val_loss: 50.0408 - val_mse: 50.0408\n",
      "Epoch 165/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 36.2999 - mse: 36.2999\n",
      "Epoch 165: val_mse did not improve from 26.70508\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 23.4858 - mse: 23.4858 - val_loss: 26.9650 - val_mse: 26.9650\n",
      "Epoch 166/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.9746 - mse: 17.9746\n",
      "Epoch 166: val_mse improved from 26.70508 to 26.53576, saving model to ./model/166-26.5358.hdf5\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 17.6235 - mse: 17.6235 - val_loss: 26.5358 - val_mse: 26.5358\n",
      "Epoch 167/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.1893 - mse: 18.1893\n",
      "Epoch 167: val_mse improved from 26.53576 to 25.32522, saving model to ./model/167-25.3252.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 15.5892 - mse: 15.5892 - val_loss: 25.3252 - val_mse: 25.3252\n",
      "Epoch 168/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 4.3370 - mse: 4.3370\n",
      "Epoch 168: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.1394 - mse: 17.1394 - val_loss: 26.7248 - val_mse: 26.7248\n",
      "Epoch 169/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.7436 - mse: 9.7436\n",
      "Epoch 169: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.7616 - mse: 16.7616 - val_loss: 30.0208 - val_mse: 30.0208\n",
      "Epoch 170/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.6283 - mse: 19.6283\n",
      "Epoch 170: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 18.3140 - mse: 18.3140 - val_loss: 26.3574 - val_mse: 26.3574\n",
      "Epoch 171/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.7748 - mse: 9.7748\n",
      "Epoch 171: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.8132 - mse: 16.8132 - val_loss: 27.1835 - val_mse: 27.1835\n",
      "Epoch 172/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.5717 - mse: 10.5717\n",
      "Epoch 172: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 18.5310 - mse: 18.5310 - val_loss: 28.2347 - val_mse: 28.2347\n",
      "Epoch 173/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.5227 - mse: 12.5227\n",
      "Epoch 173: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.4168 - mse: 17.4168 - val_loss: 27.2757 - val_mse: 27.2757\n",
      "Epoch 174/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.5977 - mse: 13.5977\n",
      "Epoch 174: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.2867 - mse: 15.2867 - val_loss: 28.8678 - val_mse: 28.8678\n",
      "Epoch 175/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.4213 - mse: 18.4213\n",
      "Epoch 175: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.6585 - mse: 14.6585 - val_loss: 25.9767 - val_mse: 25.9767\n",
      "Epoch 176/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.6219 - mse: 18.6219\n",
      "Epoch 176: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.8732 - mse: 14.8732 - val_loss: 27.0612 - val_mse: 27.0612\n",
      "Epoch 177/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.5115 - mse: 19.5115\n",
      "Epoch 177: val_mse did not improve from 25.32522\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.7496 - mse: 15.7496 - val_loss: 26.5940 - val_mse: 26.5940\n",
      "Epoch 178/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.2289 - mse: 16.2289\n",
      "Epoch 178: val_mse improved from 25.32522 to 25.03893, saving model to ./model/178-25.0389.hdf5\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 14.4131 - mse: 14.4131 - val_loss: 25.0389 - val_mse: 25.0389\n",
      "Epoch 179/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.8340 - mse: 10.8340\n",
      "Epoch 179: val_mse did not improve from 25.03893\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 14.2052 - mse: 14.2052 - val_loss: 27.9966 - val_mse: 27.9966\n",
      "Epoch 180/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.7479 - mse: 14.7479\n",
      "Epoch 180: val_mse did not improve from 25.03893\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 21.2967 - mse: 21.2967 - val_loss: 40.1316 - val_mse: 40.1316\n",
      "Epoch 181/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.2358 - mse: 19.2358\n",
      "Epoch 181: val_mse did not improve from 25.03893\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 18.0771 - mse: 18.0771 - val_loss: 29.4738 - val_mse: 29.4738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.9721 - mse: 13.9721\n",
      "Epoch 182: val_mse did not improve from 25.03893\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 15.4042 - mse: 15.4042 - val_loss: 27.6036 - val_mse: 27.6036\n",
      "Epoch 183/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.9283 - mse: 19.9283\n",
      "Epoch 183: val_mse did not improve from 25.03893\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.5965 - mse: 17.5965 - val_loss: 29.9571 - val_mse: 29.9571\n",
      "Epoch 184/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.6976 - mse: 11.6976\n",
      "Epoch 184: val_mse did not improve from 25.03893\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.3851 - mse: 15.3851 - val_loss: 26.5560 - val_mse: 26.5560\n",
      "Epoch 185/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.1354 - mse: 11.1354\n",
      "Epoch 185: val_mse did not improve from 25.03893\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.7660 - mse: 14.7660 - val_loss: 29.5015 - val_mse: 29.5015\n",
      "Epoch 186/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.2342 - mse: 18.2342\n",
      "Epoch 186: val_mse improved from 25.03893 to 24.91884, saving model to ./model/186-24.9188.hdf5\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 16.2771 - mse: 16.2771 - val_loss: 24.9188 - val_mse: 24.9188\n",
      "Epoch 187/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.7316 - mse: 17.7316\n",
      "Epoch 187: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.3177 - mse: 14.3177 - val_loss: 29.1606 - val_mse: 29.1606\n",
      "Epoch 188/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.3047 - mse: 9.3047\n",
      "Epoch 188: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.1176 - mse: 16.1176 - val_loss: 32.5643 - val_mse: 32.5643\n",
      "Epoch 189/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 27.9991 - mse: 27.9991\n",
      "Epoch 189: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.9462 - mse: 16.9462 - val_loss: 30.6918 - val_mse: 30.6918\n",
      "Epoch 190/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 20.7167 - mse: 20.7167\n",
      "Epoch 190: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.6259 - mse: 14.6259 - val_loss: 27.5709 - val_mse: 27.5709\n",
      "Epoch 191/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.0280 - mse: 11.0280\n",
      "Epoch 191: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 15.4446 - mse: 15.4446 - val_loss: 25.9850 - val_mse: 25.9850\n",
      "Epoch 192/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.5060 - mse: 23.5060\n",
      "Epoch 192: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.7421 - mse: 16.7421 - val_loss: 25.1687 - val_mse: 25.1687\n",
      "Epoch 193/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.5934 - mse: 17.5934\n",
      "Epoch 193: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.9070 - mse: 15.9070 - val_loss: 25.9079 - val_mse: 25.9079\n",
      "Epoch 194/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.1121 - mse: 12.1121\n",
      "Epoch 194: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 13.7909 - mse: 13.7909 - val_loss: 26.1884 - val_mse: 26.1884\n",
      "Epoch 195/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 5.1637 - mse: 5.1637\n",
      "Epoch 195: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 13.5729 - mse: 13.5729 - val_loss: 31.6118 - val_mse: 31.6118\n",
      "Epoch 196/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.0202 - mse: 14.0202\n",
      "Epoch 196: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 15.2752 - mse: 15.2752 - val_loss: 32.0121 - val_mse: 32.0121\n",
      "Epoch 197/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.2998 - mse: 12.2998\n",
      "Epoch 197: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 18.2001 - mse: 18.2001 - val_loss: 31.8951 - val_mse: 31.8951\n",
      "Epoch 198/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.2125 - mse: 15.2125\n",
      "Epoch 198: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 18.6945 - mse: 18.6945 - val_loss: 38.5386 - val_mse: 38.5386\n",
      "Epoch 199/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.8110 - mse: 14.8110\n",
      "Epoch 199: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 20.5375 - mse: 20.5375 - val_loss: 29.0713 - val_mse: 29.0713\n",
      "Epoch 200/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.7368 - mse: 18.7368\n",
      "Epoch 200: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.5592 - mse: 16.5592 - val_loss: 27.0928 - val_mse: 27.0928\n",
      "Epoch 201/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.5489 - mse: 16.5489\n",
      "Epoch 201: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.1439 - mse: 15.1439 - val_loss: 33.3506 - val_mse: 33.3506\n",
      "Epoch 202/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.6995 - mse: 18.6995\n",
      "Epoch 202: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 21.2283 - mse: 21.2283 - val_loss: 25.8576 - val_mse: 25.8576\n",
      "Epoch 203/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.2206 - mse: 12.2206\n",
      "Epoch 203: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 16.2906 - mse: 16.2906 - val_loss: 25.0961 - val_mse: 25.0961\n",
      "Epoch 204/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.7804 - mse: 17.7804\n",
      "Epoch 204: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 15.7401 - mse: 15.7401 - val_loss: 26.3535 - val_mse: 26.3535\n",
      "Epoch 205/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.0319 - mse: 15.0319\n",
      "Epoch 205: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 13.6123 - mse: 13.6123 - val_loss: 26.4870 - val_mse: 26.4870\n",
      "Epoch 206/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.0939 - mse: 9.0939\n",
      "Epoch 206: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 12.7272 - mse: 12.7272 - val_loss: 25.3604 - val_mse: 25.3604\n",
      "Epoch 207/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.5490 - mse: 13.5490\n",
      "Epoch 207: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 12.7532 - mse: 12.7532 - val_loss: 25.5832 - val_mse: 25.5832\n",
      "Epoch 208/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.1104 - mse: 10.1104\n",
      "Epoch 208: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 13.4172 - mse: 13.4172 - val_loss: 28.2159 - val_mse: 28.2159\n",
      "Epoch 209/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.7081 - mse: 13.7081\n",
      "Epoch 209: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 16.5245 - mse: 16.5245 - val_loss: 26.6602 - val_mse: 26.6602\n",
      "Epoch 210/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.7350 - mse: 22.7350\n",
      "Epoch 210: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.5151 - mse: 14.5151 - val_loss: 27.0213 - val_mse: 27.0213\n",
      "Epoch 211/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.0973 - mse: 11.0973\n",
      "Epoch 211: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.4837 - mse: 12.4837 - val_loss: 26.1888 - val_mse: 26.1888\n",
      "Epoch 212/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.2982 - mse: 9.2982\n",
      "Epoch 212: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.4678 - mse: 15.4678 - val_loss: 30.7658 - val_mse: 30.7658\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 0s - loss: 11.7168 - mse: 11.7168\n",
      "Epoch 213: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 14.1818 - mse: 14.1818 - val_loss: 26.8957 - val_mse: 26.8957\n",
      "Epoch 214/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.0296 - mse: 13.0296\n",
      "Epoch 214: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.3697 - mse: 13.3697 - val_loss: 28.7749 - val_mse: 28.7749\n",
      "Epoch 215/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.0570 - mse: 17.0570\n",
      "Epoch 215: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.7659 - mse: 13.7659 - val_loss: 27.8236 - val_mse: 27.8236\n",
      "Epoch 216/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.8679 - mse: 10.8679\n",
      "Epoch 216: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.7104 - mse: 12.7104 - val_loss: 25.8123 - val_mse: 25.8123\n",
      "Epoch 217/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.0293 - mse: 14.0293\n",
      "Epoch 217: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.3959 - mse: 13.3959 - val_loss: 26.8773 - val_mse: 26.8773\n",
      "Epoch 218/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.1879 - mse: 12.1879\n",
      "Epoch 218: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.2064 - mse: 14.2064 - val_loss: 28.0750 - val_mse: 28.0750\n",
      "Epoch 219/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.8216 - mse: 9.8216\n",
      "Epoch 219: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 13.3741 - mse: 13.3741 - val_loss: 28.8704 - val_mse: 28.8704\n",
      "Epoch 220/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.3212 - mse: 10.3212\n",
      "Epoch 220: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.6657 - mse: 12.6657 - val_loss: 25.7152 - val_mse: 25.7152\n",
      "Epoch 221/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.3038 - mse: 11.3038\n",
      "Epoch 221: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 16.4128 - mse: 16.4128 - val_loss: 28.5262 - val_mse: 28.5262\n",
      "Epoch 222/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.1068 - mse: 14.1068\n",
      "Epoch 222: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.9231 - mse: 17.9231 - val_loss: 28.3675 - val_mse: 28.3675\n",
      "Epoch 223/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.1134 - mse: 15.1134\n",
      "Epoch 223: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.4318 - mse: 15.4318 - val_loss: 43.1710 - val_mse: 43.1710\n",
      "Epoch 224/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 22.8010 - mse: 22.8010\n",
      "Epoch 224: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 22.3158 - mse: 22.3158 - val_loss: 32.1848 - val_mse: 32.1848\n",
      "Epoch 225/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 19.1738 - mse: 19.1738\n",
      "Epoch 225: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.6772 - mse: 17.6772 - val_loss: 31.2406 - val_mse: 31.2406\n",
      "Epoch 226/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.8720 - mse: 17.8720\n",
      "Epoch 226: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 15.6209 - mse: 15.6209 - val_loss: 30.3364 - val_mse: 30.3364\n",
      "Epoch 227/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.6361 - mse: 13.6361\n",
      "Epoch 227: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 12.9870 - mse: 12.9870 - val_loss: 28.2202 - val_mse: 28.2202\n",
      "Epoch 228/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.2468 - mse: 15.2468\n",
      "Epoch 228: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.8687 - mse: 14.8687 - val_loss: 27.1828 - val_mse: 27.1828\n",
      "Epoch 229/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.8050 - mse: 8.8050\n",
      "Epoch 229: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.4062 - mse: 14.4062 - val_loss: 35.6816 - val_mse: 35.6816\n",
      "Epoch 230/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.1106 - mse: 15.1106\n",
      "Epoch 230: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.4878 - mse: 17.4878 - val_loss: 38.6599 - val_mse: 38.6599\n",
      "Epoch 231/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.9090 - mse: 23.9090\n",
      "Epoch 231: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 17.1821 - mse: 17.1821 - val_loss: 30.1641 - val_mse: 30.1641\n",
      "Epoch 232/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.7506 - mse: 12.7506\n",
      "Epoch 232: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 12.9073 - mse: 12.9073 - val_loss: 27.5461 - val_mse: 27.5461\n",
      "Epoch 233/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.0436 - mse: 8.0436\n",
      "Epoch 233: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.3594 - mse: 13.3594 - val_loss: 26.7561 - val_mse: 26.7561\n",
      "Epoch 234/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.8752 - mse: 14.8752\n",
      "Epoch 234: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.4108 - mse: 12.4108 - val_loss: 30.0316 - val_mse: 30.0316\n",
      "Epoch 235/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.4717 - mse: 10.4717\n",
      "Epoch 235: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.8816 - mse: 11.8816 - val_loss: 28.4466 - val_mse: 28.4466\n",
      "Epoch 236/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.8252 - mse: 11.8252\n",
      "Epoch 236: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.2352 - mse: 14.2352 - val_loss: 28.3779 - val_mse: 28.3779\n",
      "Epoch 237/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.7468 - mse: 10.7468\n",
      "Epoch 237: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.3088 - mse: 17.3088 - val_loss: 37.7442 - val_mse: 37.7442\n",
      "Epoch 238/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 29.3661 - mse: 29.3661\n",
      "Epoch 238: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 18.8298 - mse: 18.8298 - val_loss: 31.8999 - val_mse: 31.8999\n",
      "Epoch 239/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.4081 - mse: 12.4081\n",
      "Epoch 239: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 14.3286 - mse: 14.3286 - val_loss: 27.2300 - val_mse: 27.2300\n",
      "Epoch 240/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.4310 - mse: 11.4310\n",
      "Epoch 240: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 11.1438 - mse: 11.1438 - val_loss: 28.8728 - val_mse: 28.8728\n",
      "Epoch 241/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 7.8480 - mse: 7.8480\n",
      "Epoch 241: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 11.9540 - mse: 11.9540 - val_loss: 28.2451 - val_mse: 28.2451\n",
      "Epoch 242/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.7543 - mse: 15.7543\n",
      "Epoch 242: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.8314 - mse: 12.8314 - val_loss: 26.4115 - val_mse: 26.4115\n",
      "Epoch 243/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.9708 - mse: 8.9708\n",
      "Epoch 243: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.7543 - mse: 11.7543 - val_loss: 28.2507 - val_mse: 28.2507\n",
      "Epoch 244/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 0s - loss: 11.3011 - mse: 11.3011\n",
      "Epoch 244: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.8959 - mse: 12.8959 - val_loss: 27.1062 - val_mse: 27.1062\n",
      "Epoch 245/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.5547 - mse: 8.5547\n",
      "Epoch 245: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 13.4211 - mse: 13.4211 - val_loss: 29.8013 - val_mse: 29.8013\n",
      "Epoch 246/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.4295 - mse: 11.4295\n",
      "Epoch 246: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.5931 - mse: 11.5931 - val_loss: 32.7375 - val_mse: 32.7375\n",
      "Epoch 247/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.7935 - mse: 8.7935\n",
      "Epoch 247: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.2389 - mse: 13.2389 - val_loss: 29.8687 - val_mse: 29.8687\n",
      "Epoch 248/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.8320 - mse: 10.8320\n",
      "Epoch 248: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.5602 - mse: 12.5602 - val_loss: 26.3585 - val_mse: 26.3585\n",
      "Epoch 249/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.9751 - mse: 8.9751\n",
      "Epoch 249: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.0024 - mse: 12.0024 - val_loss: 25.2812 - val_mse: 25.2812\n",
      "Epoch 250/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.1334 - mse: 13.1334\n",
      "Epoch 250: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.5963 - mse: 11.5963 - val_loss: 26.8312 - val_mse: 26.8312\n",
      "Epoch 251/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 4.5671 - mse: 4.5671\n",
      "Epoch 251: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.9620 - mse: 13.9620 - val_loss: 31.5922 - val_mse: 31.5922\n",
      "Epoch 252/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 18.2563 - mse: 18.2563\n",
      "Epoch 252: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.9106 - mse: 14.9106 - val_loss: 29.9502 - val_mse: 29.9502\n",
      "Epoch 253/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.8833 - mse: 10.8833\n",
      "Epoch 253: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 17.1808 - mse: 17.1808 - val_loss: 28.2627 - val_mse: 28.2627\n",
      "Epoch 254/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 14.9821 - mse: 14.9821\n",
      "Epoch 254: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 16.5947 - mse: 16.5947 - val_loss: 31.1378 - val_mse: 31.1378\n",
      "Epoch 255/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 17.1862 - mse: 17.1862\n",
      "Epoch 255: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 13.6154 - mse: 13.6154 - val_loss: 35.1748 - val_mse: 35.1748\n",
      "Epoch 256/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.8144 - mse: 15.8144\n",
      "Epoch 256: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.3380 - mse: 14.3380 - val_loss: 33.0703 - val_mse: 33.0703\n",
      "Epoch 257/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.5569 - mse: 15.5569\n",
      "Epoch 257: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 12.1577 - mse: 12.1577 - val_loss: 29.0930 - val_mse: 29.0930\n",
      "Epoch 258/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.5352 - mse: 10.5352\n",
      "Epoch 258: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 13.0993 - mse: 13.0993 - val_loss: 25.9677 - val_mse: 25.9677\n",
      "Epoch 259/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 15.7026 - mse: 15.7026\n",
      "Epoch 259: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 13.7009 - mse: 13.7009 - val_loss: 29.8648 - val_mse: 29.8648\n",
      "Epoch 260/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.5149 - mse: 13.5149\n",
      "Epoch 260: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.1918 - mse: 14.1918 - val_loss: 29.1103 - val_mse: 29.1103\n",
      "Epoch 261/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 23.2062 - mse: 23.2062\n",
      "Epoch 261: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.6424 - mse: 11.6424 - val_loss: 30.3268 - val_mse: 30.3268\n",
      "Epoch 262/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.3670 - mse: 9.3670\n",
      "Epoch 262: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 12.1756 - mse: 12.1756 - val_loss: 28.2742 - val_mse: 28.2742\n",
      "Epoch 263/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 12.8212 - mse: 12.8212\n",
      "Epoch 263: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 14.1753 - mse: 14.1753 - val_loss: 29.3125 - val_mse: 29.3125\n",
      "Epoch 264/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.7218 - mse: 13.7218\n",
      "Epoch 264: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.9082 - mse: 11.9082 - val_loss: 28.0384 - val_mse: 28.0384\n",
      "Epoch 265/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 6.1074 - mse: 6.1074\n",
      "Epoch 265: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.0607 - mse: 11.0607 - val_loss: 28.7986 - val_mse: 28.7986\n",
      "Epoch 266/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 6.7875 - mse: 6.7875\n",
      "Epoch 266: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.9466 - mse: 10.9466 - val_loss: 27.9169 - val_mse: 27.9169\n",
      "Epoch 267/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.0784 - mse: 8.0784\n",
      "Epoch 267: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.3953 - mse: 10.3953 - val_loss: 32.2733 - val_mse: 32.2733\n",
      "Epoch 268/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 16.9858 - mse: 16.9858\n",
      "Epoch 268: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.8146 - mse: 11.8146 - val_loss: 27.5008 - val_mse: 27.5008\n",
      "Epoch 269/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.6417 - mse: 8.6417\n",
      "Epoch 269: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.9686 - mse: 11.9686 - val_loss: 25.6490 - val_mse: 25.6490\n",
      "Epoch 270/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.1583 - mse: 10.1583\n",
      "Epoch 270: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.6027 - mse: 10.6027 - val_loss: 26.4326 - val_mse: 26.4326\n",
      "Epoch 271/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.0891 - mse: 9.0891\n",
      "Epoch 271: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.7592 - mse: 10.7592 - val_loss: 27.1519 - val_mse: 27.1519\n",
      "Epoch 272/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.3190 - mse: 10.3190\n",
      "Epoch 272: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 11.2512 - mse: 11.2512 - val_loss: 27.2153 - val_mse: 27.2153\n",
      "Epoch 273/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.8250 - mse: 10.8250\n",
      "Epoch 273: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.0216 - mse: 11.0216 - val_loss: 26.6585 - val_mse: 26.6585\n",
      "Epoch 274/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.7974 - mse: 13.7974\n",
      "Epoch 274: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.1399 - mse: 11.1399 - val_loss: 28.8106 - val_mse: 28.8106\n",
      "Epoch 275/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 [==>...........................] - ETA: 0s - loss: 13.6016 - mse: 13.6016\n",
      "Epoch 275: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.4821 - mse: 10.4821 - val_loss: 26.3620 - val_mse: 26.3620\n",
      "Epoch 276/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 6.4475 - mse: 6.4475\n",
      "Epoch 276: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 11.4765 - mse: 11.4765 - val_loss: 28.8438 - val_mse: 28.8438\n",
      "Epoch 277/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 7.2092 - mse: 7.2092\n",
      "Epoch 277: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.2877 - mse: 11.2877 - val_loss: 29.6936 - val_mse: 29.6936\n",
      "Epoch 278/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.9918 - mse: 9.9918\n",
      "Epoch 278: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 11.9214 - mse: 11.9214 - val_loss: 28.5495 - val_mse: 28.5495\n",
      "Epoch 279/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 5.6778 - mse: 5.6778\n",
      "Epoch 279: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.3808 - mse: 10.3808 - val_loss: 27.3161 - val_mse: 27.3161\n",
      "Epoch 280/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.3723 - mse: 13.3723\n",
      "Epoch 280: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 12.5375 - mse: 12.5375 - val_loss: 28.0920 - val_mse: 28.0920\n",
      "Epoch 281/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 11.8463 - mse: 11.8463\n",
      "Epoch 281: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.5188 - mse: 10.5188 - val_loss: 27.9477 - val_mse: 27.9477\n",
      "Epoch 282/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 8.1399 - mse: 8.1399\n",
      "Epoch 282: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 11.1194 - mse: 11.1194 - val_loss: 27.2622 - val_mse: 27.2622\n",
      "Epoch 283/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 13.8770 - mse: 13.8770\n",
      "Epoch 283: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 10.0361 - mse: 10.0361 - val_loss: 29.3126 - val_mse: 29.3126\n",
      "Epoch 284/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 10.5765 - mse: 10.5765\n",
      "Epoch 284: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 10.7976 - mse: 10.7976 - val_loss: 26.9232 - val_mse: 26.9232\n",
      "Epoch 285/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 7.9790 - mse: 7.9790\n",
      "Epoch 285: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.2202 - mse: 10.2202 - val_loss: 26.4915 - val_mse: 26.4915\n",
      "Epoch 286/2000\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 9.4234 - mse: 9.4234\n",
      "Epoch 286: val_mse did not improve from 24.91884\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 10.7826 - mse: 10.7826 - val_loss: 27.7588 - val_mse: 27.7588\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.3, \n",
    "                    epochs=2000, \n",
    "                    batch_size=30, \n",
    "                    verbose=1, \n",
    "                    callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cadebfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "14.2      16.38325\n",
      "15.6      17.874159\n",
      "23.7      26.424591\n",
      "20.4      21.68967\n",
      "23.1      23.597746\n",
      "50.0      51.399967\n",
      "23.2      15.900731\n",
      "36.0      31.577705\n",
      "17.1      20.147186\n",
      "14.1      16.911844\n"
     ]
    }
   ],
   "source": [
    "# 예측 값과 실제 값의 비교\n",
    "y_prediction = model.predict(X_test).flatten()\n",
    "# flatten : 데이터 배열이 몇 차원이든 모두 1차원으로 바꿔 읽기 쉽게 해 주는 함수\n",
    "\n",
    "# 10개 실제값과 예측값 비교\n",
    "for i in range(10):\n",
    "    label = y_test[i]\n",
    "    prediction = y_prediction[i]\n",
    "    print(label, \"    \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어느정도 실제값을 잘 예측하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529cd3b",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b4b948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 수: 286\n"
     ]
    }
   ],
   "source": [
    "# y_acc 에 학습 셋으로 측정한 정확도의 값을 저장\n",
    "y_vmse = history.history['val_mse']\n",
    "y_mse = history.history['mse']\n",
    "\n",
    "# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = np.arange(len(y_mse))\n",
    "print('epoch 수:', len(x_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81a7df03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_len, y_vmse, \"o\", c=\"red\", markersize=3, label='val_mse')\n",
    "plt.plot(x_len, y_mse, \"o\", c=\"blue\", markersize=3, label='mse')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(0, 70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a4655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
