{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ee7b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "babb9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afc32012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.034</td>\n",
       "      <td>23.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99405</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.64</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.028</td>\n",
       "      <td>16.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.99311</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.142</td>\n",
       "      <td>52.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.99370</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.032</td>\n",
       "      <td>9.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.034</td>\n",
       "      <td>71.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.99420</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.69</td>\n",
       "      <td>10.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2    3      4     5      6        7     8     9     10  11  12\n",
       "0  7.1  0.21  0.28  2.7  0.034  23.0  111.0  0.99405  3.35  0.64  10.2   4   0\n",
       "1  6.5  0.22  0.29  7.4  0.028  16.0   87.0  0.99311  3.15  0.56  10.9   7   0\n",
       "2  6.8  0.29  0.49  1.4  0.142  52.0  148.0  0.99370  3.08  0.49   9.0   6   0\n",
       "3  7.4  0.24  0.40  4.3  0.032   9.0   95.0  0.99200  3.09  0.39  11.1   6   0\n",
       "4  6.8  0.19  0.23  5.1  0.034  71.0  204.0  0.99420  3.23  0.69  10.1   5   0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre = pd.read_csv('../dataset/wine_train.csv', header=None)\n",
    "\n",
    "print(df_pre.shape)\n",
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edb6403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피쳐, 타깃값 분리\n",
    "dataset = df_pre.values\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72d7c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0bbc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03ed959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48480668",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71689a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74eb0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e5ebea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.54069, saving model to ./model/01-0.5407.hdf5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.54069 to 0.35177, saving model to ./model/02-0.3518.hdf5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.35177 to 0.32616, saving model to ./model/03-0.3262.hdf5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.32616 to 0.31237, saving model to ./model/04-0.3124.hdf5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.31237 to 0.29692, saving model to ./model/05-0.2969.hdf5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.29692 to 0.28252, saving model to ./model/06-0.2825.hdf5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.28252 to 0.26772, saving model to ./model/07-0.2677.hdf5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.26772 to 0.25227, saving model to ./model/08-0.2523.hdf5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.25227 to 0.23646, saving model to ./model/09-0.2365.hdf5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.23646 to 0.22307, saving model to ./model/10-0.2231.hdf5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.22307 to 0.21380, saving model to ./model/11-0.2138.hdf5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.21380 to 0.20841, saving model to ./model/12-0.2084.hdf5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.20841 to 0.20507, saving model to ./model/13-0.2051.hdf5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.20507 to 0.20172, saving model to ./model/14-0.2017.hdf5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.20172 to 0.19809, saving model to ./model/15-0.1981.hdf5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.19809 to 0.19375, saving model to ./model/16-0.1937.hdf5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.19375 to 0.19081, saving model to ./model/17-0.1908.hdf5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.19081 to 0.18855, saving model to ./model/18-0.1886.hdf5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.18855 to 0.18744, saving model to ./model/19-0.1874.hdf5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.18744 to 0.18534, saving model to ./model/20-0.1853.hdf5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.18534 to 0.18372, saving model to ./model/21-0.1837.hdf5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.18372 to 0.18285, saving model to ./model/22-0.1828.hdf5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.18285 to 0.18072, saving model to ./model/23-0.1807.hdf5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.18072 to 0.18010, saving model to ./model/24-0.1801.hdf5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.18010 to 0.17774, saving model to ./model/25-0.1777.hdf5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.17774 to 0.17636, saving model to ./model/26-0.1764.hdf5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.17636 to 0.17498, saving model to ./model/27-0.1750.hdf5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.17498 to 0.17316, saving model to ./model/28-0.1732.hdf5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.17316 to 0.17137, saving model to ./model/29-0.1714.hdf5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.17137 to 0.17063, saving model to ./model/30-0.1706.hdf5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.17063 to 0.16851, saving model to ./model/31-0.1685.hdf5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.16851 to 0.16743, saving model to ./model/32-0.1674.hdf5\n",
      "\n",
      "Epoch 33: val_loss improved from 0.16743 to 0.16575, saving model to ./model/33-0.1657.hdf5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.16575 to 0.16374, saving model to ./model/34-0.1637.hdf5\n",
      "\n",
      "Epoch 35: val_loss improved from 0.16374 to 0.16257, saving model to ./model/35-0.1626.hdf5\n",
      "\n",
      "Epoch 36: val_loss improved from 0.16257 to 0.16046, saving model to ./model/36-0.1605.hdf5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.16046 to 0.15921, saving model to ./model/37-0.1592.hdf5\n",
      "\n",
      "Epoch 38: val_loss improved from 0.15921 to 0.15663, saving model to ./model/38-0.1566.hdf5\n",
      "\n",
      "Epoch 39: val_loss improved from 0.15663 to 0.15426, saving model to ./model/39-0.1543.hdf5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.15426 to 0.15238, saving model to ./model/40-0.1524.hdf5\n",
      "\n",
      "Epoch 41: val_loss improved from 0.15238 to 0.14915, saving model to ./model/41-0.1491.hdf5\n",
      "\n",
      "Epoch 42: val_loss improved from 0.14915 to 0.14559, saving model to ./model/42-0.1456.hdf5\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.14559\n",
      "\n",
      "Epoch 44: val_loss improved from 0.14559 to 0.14080, saving model to ./model/44-0.1408.hdf5\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.14080\n",
      "\n",
      "Epoch 46: val_loss improved from 0.14080 to 0.13586, saving model to ./model/46-0.1359.hdf5\n",
      "\n",
      "Epoch 47: val_loss improved from 0.13586 to 0.13577, saving model to ./model/47-0.1358.hdf5\n",
      "\n",
      "Epoch 48: val_loss improved from 0.13577 to 0.13278, saving model to ./model/48-0.1328.hdf5\n",
      "\n",
      "Epoch 49: val_loss improved from 0.13278 to 0.12944, saving model to ./model/49-0.1294.hdf5\n",
      "\n",
      "Epoch 50: val_loss improved from 0.12944 to 0.12693, saving model to ./model/50-0.1269.hdf5\n",
      "\n",
      "Epoch 51: val_loss improved from 0.12693 to 0.12471, saving model to ./model/51-0.1247.hdf5\n",
      "\n",
      "Epoch 52: val_loss improved from 0.12471 to 0.12271, saving model to ./model/52-0.1227.hdf5\n",
      "\n",
      "Epoch 53: val_loss improved from 0.12271 to 0.12044, saving model to ./model/53-0.1204.hdf5\n",
      "\n",
      "Epoch 54: val_loss improved from 0.12044 to 0.11851, saving model to ./model/54-0.1185.hdf5\n",
      "\n",
      "Epoch 55: val_loss improved from 0.11851 to 0.11733, saving model to ./model/55-0.1173.hdf5\n",
      "\n",
      "Epoch 56: val_loss improved from 0.11733 to 0.11560, saving model to ./model/56-0.1156.hdf5\n",
      "\n",
      "Epoch 57: val_loss improved from 0.11560 to 0.11295, saving model to ./model/57-0.1129.hdf5\n",
      "\n",
      "Epoch 58: val_loss improved from 0.11295 to 0.11075, saving model to ./model/58-0.1108.hdf5\n",
      "\n",
      "Epoch 59: val_loss improved from 0.11075 to 0.11031, saving model to ./model/59-0.1103.hdf5\n",
      "\n",
      "Epoch 60: val_loss improved from 0.11031 to 0.10957, saving model to ./model/60-0.1096.hdf5\n",
      "\n",
      "Epoch 61: val_loss improved from 0.10957 to 0.10808, saving model to ./model/61-0.1081.hdf5\n",
      "\n",
      "Epoch 62: val_loss improved from 0.10808 to 0.10478, saving model to ./model/62-0.1048.hdf5\n",
      "\n",
      "Epoch 63: val_loss improved from 0.10478 to 0.10286, saving model to ./model/63-0.1029.hdf5\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.10286\n",
      "\n",
      "Epoch 65: val_loss improved from 0.10286 to 0.10034, saving model to ./model/65-0.1003.hdf5\n",
      "\n",
      "Epoch 66: val_loss improved from 0.10034 to 0.09915, saving model to ./model/66-0.0992.hdf5\n",
      "\n",
      "Epoch 67: val_loss improved from 0.09915 to 0.09742, saving model to ./model/67-0.0974.hdf5\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.09742\n",
      "\n",
      "Epoch 69: val_loss improved from 0.09742 to 0.09559, saving model to ./model/69-0.0956.hdf5\n",
      "\n",
      "Epoch 70: val_loss improved from 0.09559 to 0.09424, saving model to ./model/70-0.0942.hdf5\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.09424\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.09424\n",
      "\n",
      "Epoch 73: val_loss improved from 0.09424 to 0.09109, saving model to ./model/73-0.0911.hdf5\n",
      "\n",
      "Epoch 74: val_loss improved from 0.09109 to 0.09060, saving model to ./model/74-0.0906.hdf5\n",
      "\n",
      "Epoch 75: val_loss improved from 0.09060 to 0.08960, saving model to ./model/75-0.0896.hdf5\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.08960\n",
      "\n",
      "Epoch 77: val_loss improved from 0.08960 to 0.08859, saving model to ./model/77-0.0886.hdf5\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.08859\n",
      "\n",
      "Epoch 79: val_loss improved from 0.08859 to 0.08651, saving model to ./model/79-0.0865.hdf5\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.08651\n",
      "\n",
      "Epoch 81: val_loss improved from 0.08651 to 0.08417, saving model to ./model/81-0.0842.hdf5\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.08417\n",
      "\n",
      "Epoch 83: val_loss improved from 0.08417 to 0.08261, saving model to ./model/83-0.0826.hdf5\n",
      "\n",
      "Epoch 84: val_loss improved from 0.08261 to 0.08194, saving model to ./model/84-0.0819.hdf5\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.08194\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.08194\n",
      "\n",
      "Epoch 87: val_loss improved from 0.08194 to 0.07969, saving model to ./model/87-0.0797.hdf5\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.07969\n",
      "\n",
      "Epoch 89: val_loss improved from 0.07969 to 0.07906, saving model to ./model/89-0.0791.hdf5\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.07906\n",
      "\n",
      "Epoch 91: val_loss improved from 0.07906 to 0.07837, saving model to ./model/91-0.0784.hdf5\n",
      "\n",
      "Epoch 92: val_loss improved from 0.07837 to 0.07787, saving model to ./model/92-0.0779.hdf5\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.07787\n",
      "\n",
      "Epoch 94: val_loss improved from 0.07787 to 0.07476, saving model to ./model/94-0.0748.hdf5\n",
      "\n",
      "Epoch 95: val_loss improved from 0.07476 to 0.07447, saving model to ./model/95-0.0745.hdf5\n",
      "\n",
      "Epoch 96: val_loss improved from 0.07447 to 0.07314, saving model to ./model/96-0.0731.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97: val_loss did not improve from 0.07314\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.07314\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.07314\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.07314\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.07314\n",
      "\n",
      "Epoch 102: val_loss improved from 0.07314 to 0.06983, saving model to ./model/102-0.0698.hdf5\n",
      "\n",
      "Epoch 103: val_loss improved from 0.06983 to 0.06910, saving model to ./model/103-0.0691.hdf5\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.06910\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.06910\n",
      "\n",
      "Epoch 106: val_loss improved from 0.06910 to 0.06789, saving model to ./model/106-0.0679.hdf5\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.06789\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.06789\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.06789\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.06789\n",
      "\n",
      "Epoch 111: val_loss improved from 0.06789 to 0.06605, saving model to ./model/111-0.0661.hdf5\n",
      "\n",
      "Epoch 112: val_loss improved from 0.06605 to 0.06513, saving model to ./model/112-0.0651.hdf5\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.06513\n",
      "\n",
      "Epoch 117: val_loss improved from 0.06513 to 0.06310, saving model to ./model/117-0.0631.hdf5\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.06310\n",
      "\n",
      "Epoch 119: val_loss improved from 0.06310 to 0.06272, saving model to ./model/119-0.0627.hdf5\n",
      "\n",
      "Epoch 120: val_loss improved from 0.06272 to 0.06065, saving model to ./model/120-0.0607.hdf5\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.06065\n",
      "\n",
      "Epoch 122: val_loss improved from 0.06065 to 0.05935, saving model to ./model/122-0.0593.hdf5\n",
      "\n",
      "Epoch 123: val_loss improved from 0.05935 to 0.05888, saving model to ./model/123-0.0589.hdf5\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.05888\n",
      "\n",
      "Epoch 125: val_loss improved from 0.05888 to 0.05834, saving model to ./model/125-0.0583.hdf5\n",
      "\n",
      "Epoch 126: val_loss improved from 0.05834 to 0.05746, saving model to ./model/126-0.0575.hdf5\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.05746\n",
      "\n",
      "Epoch 128: val_loss improved from 0.05746 to 0.05683, saving model to ./model/128-0.0568.hdf5\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.05683\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.05683\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.05683\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.05683\n",
      "\n",
      "Epoch 133: val_loss improved from 0.05683 to 0.05524, saving model to ./model/133-0.0552.hdf5\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.05524\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.05524\n",
      "\n",
      "Epoch 136: val_loss improved from 0.05524 to 0.05487, saving model to ./model/136-0.0549.hdf5\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.05487\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.05487\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.05487\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.05487\n",
      "\n",
      "Epoch 141: val_loss improved from 0.05487 to 0.05435, saving model to ./model/141-0.0544.hdf5\n",
      "\n",
      "Epoch 142: val_loss improved from 0.05435 to 0.05394, saving model to ./model/142-0.0539.hdf5\n",
      "\n",
      "Epoch 143: val_loss improved from 0.05394 to 0.05347, saving model to ./model/143-0.0535.hdf5\n",
      "\n",
      "Epoch 144: val_loss improved from 0.05347 to 0.05286, saving model to ./model/144-0.0529.hdf5\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.05286\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.05286\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.05286\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.05286\n",
      "\n",
      "Epoch 149: val_loss improved from 0.05286 to 0.05233, saving model to ./model/149-0.0523.hdf5\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.05233\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.05233\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.05233\n",
      "\n",
      "Epoch 153: val_loss improved from 0.05233 to 0.05194, saving model to ./model/153-0.0519.hdf5\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.05194\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.05194\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.05194\n",
      "\n",
      "Epoch 157: val_loss improved from 0.05194 to 0.05163, saving model to ./model/157-0.0516.hdf5\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.05163\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.05163\n",
      "\n",
      "Epoch 160: val_loss improved from 0.05163 to 0.05159, saving model to ./model/160-0.0516.hdf5\n",
      "\n",
      "Epoch 161: val_loss improved from 0.05159 to 0.05153, saving model to ./model/161-0.0515.hdf5\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.05153\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.05153\n",
      "\n",
      "Epoch 164: val_loss improved from 0.05153 to 0.05122, saving model to ./model/164-0.0512.hdf5\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.05122\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.05122\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.05122\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.05122\n",
      "\n",
      "Epoch 169: val_loss improved from 0.05122 to 0.05104, saving model to ./model/169-0.0510.hdf5\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.05104\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.05104\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.05104\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.05104\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.05104\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.05104\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.05104\n",
      "\n",
      "Epoch 177: val_loss improved from 0.05104 to 0.05016, saving model to ./model/177-0.0502.hdf5\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.05016\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.05016\n",
      "\n",
      "Epoch 180: val_loss improved from 0.05016 to 0.04992, saving model to ./model/180-0.0499.hdf5\n",
      "\n",
      "Epoch 181: val_loss improved from 0.04992 to 0.04930, saving model to ./model/181-0.0493.hdf5\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.04930\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.04930\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.04930\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.04930\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.04930\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.04930\n",
      "\n",
      "Epoch 188: val_loss improved from 0.04930 to 0.04922, saving model to ./model/188-0.0492.hdf5\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.04922\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.04922\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.04922\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.04922\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.04922\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.04922\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.04922\n",
      "\n",
      "Epoch 196: val_loss improved from 0.04922 to 0.04911, saving model to ./model/196-0.0491.hdf5\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.04911\n",
      "\n",
      "Epoch 198: val_loss improved from 0.04911 to 0.04906, saving model to ./model/198-0.0491.hdf5\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.04906\n",
      "\n",
      "Epoch 215: val_loss improved from 0.04906 to 0.04865, saving model to ./model/215-0.0486.hdf5\n",
      "\n",
      "Epoch 216: val_loss improved from 0.04865 to 0.04819, saving model to ./model/216-0.0482.hdf5\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.04819\n",
      "\n",
      "Epoch 228: val_loss improved from 0.04819 to 0.04806, saving model to ./model/228-0.0481.hdf5\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.04806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 230: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 233: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.04806\n",
      "\n",
      "Epoch 245: val_loss improved from 0.04806 to 0.04785, saving model to ./model/245-0.0479.hdf5\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.04785\n",
      "\n",
      "Epoch 270: val_loss improved from 0.04785 to 0.04681, saving model to ./model/270-0.0468.hdf5\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.04681\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.04681\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, validation_split=0.2, \n",
    "                  epochs=3500, \n",
    "                  batch_size=500, verbose=0, \n",
    "                  callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7e97256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800 epoch에서 학습 조기 멈추고(earlystop) 모델 파일 저장됨.\n",
    "# 900 epoch까지 학습을 진행해봤지만 더이상 val_loss가 향상되지 않았음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b8daebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차값 저장|\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 정확도 저장\n",
    "y_acc = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7cb64fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x축을 지정하고 정확도를 파란색, 오차는 빨간색 선으로 표시\n",
    "x_len = np.arange(len(y_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e07ed340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_len, y_vloss, 'o', c='red', markersize=3, label='valid_loss')\n",
    "plt.plot(x_len, y_acc, 'o', c='blue', markersize=3, label='accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b011355",
   "metadata": {},
   "source": [
    "### [실습] wine_test.csv => evaluate 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e08de8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1497, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.059</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.57</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.047</td>\n",
       "      <td>17.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.055</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99394</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.031</td>\n",
       "      <td>27.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.39</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.098</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99892</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5      6        7     8     9     10  11  \\\n",
       "0  10.0  0.73  0.43  2.3  0.059  15.0   31.0  0.99660  3.15  0.57  11.0   5   \n",
       "1   8.2  0.68  0.30  2.1  0.047  17.0  138.0  0.99500  3.22  0.71  10.8   4   \n",
       "2   8.8  0.24  0.35  1.7  0.055  13.0   27.0  0.99394  3.14  0.59  11.3   7   \n",
       "3   7.0  0.24  0.34  1.4  0.031  27.0  107.0  0.99000  3.06  0.39  11.9   6   \n",
       "4   7.5  0.77  0.20  8.1  0.098  30.0   92.0  0.99892  3.20  0.58   9.2   5   \n",
       "\n",
       "   12  \n",
       "0   1  \n",
       "1   0  \n",
       "2   1  \n",
       "3   0  \n",
       "4   1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../dataset/wine_test.csv', header=None)\n",
    "\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aca6de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_test.values\n",
    "\n",
    "X_test = dataset[:, 0:12]\n",
    "y_test = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dacdc12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0550062470138073, 0.9799599051475525]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a47fe",
   "metadata": {},
   "source": [
    "# 저장된 모델을 불러와서 평가해본다면?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06afaad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fcba18d7130>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "model2 = keras.models.load_model(\"./model/01-0.5407.hdf5\")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd4fe746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 856us/step - loss: 0.5412 - accuracy: 0.8497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5412479639053345, 0.8496993780136108]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d952091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 30)                390       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeed6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
