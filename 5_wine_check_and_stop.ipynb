{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ee7b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "babb9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afc32012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.034</td>\n",
       "      <td>23.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99405</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.64</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.028</td>\n",
       "      <td>16.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.99311</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.142</td>\n",
       "      <td>52.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.99370</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.032</td>\n",
       "      <td>9.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.39</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.034</td>\n",
       "      <td>71.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.99420</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.69</td>\n",
       "      <td>10.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2    3      4     5      6        7     8     9     10  11  12\n",
       "0  7.1  0.21  0.28  2.7  0.034  23.0  111.0  0.99405  3.35  0.64  10.2   4   0\n",
       "1  6.5  0.22  0.29  7.4  0.028  16.0   87.0  0.99311  3.15  0.56  10.9   7   0\n",
       "2  6.8  0.29  0.49  1.4  0.142  52.0  148.0  0.99370  3.08  0.49   9.0   6   0\n",
       "3  7.4  0.24  0.40  4.3  0.032   9.0   95.0  0.99200  3.09  0.39  11.1   6   0\n",
       "4  6.8  0.19  0.23  5.1  0.034  71.0  204.0  0.99420  3.23  0.69  10.1   5   0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre = pd.read_csv('dataset/wine_train.csv', header=None)\n",
    "\n",
    "print(df_pre.shape)\n",
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edb6403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피쳐, 타깃값 분리\n",
    "dataset = df_pre.values\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72d7c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0bbc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03ed959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48480668",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71689a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74eb0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e5ebea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.88528, saving model to ./model\\01-0.8853.hdf5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.88528 to 0.46214, saving model to ./model\\02-0.4621.hdf5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.46214 to 0.34757, saving model to ./model\\03-0.3476.hdf5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.34757 to 0.32276, saving model to ./model\\04-0.3228.hdf5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.32276 to 0.29932, saving model to ./model\\05-0.2993.hdf5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.29932 to 0.27963, saving model to ./model\\06-0.2796.hdf5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.27963 to 0.26560, saving model to ./model\\07-0.2656.hdf5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.26560 to 0.25341, saving model to ./model\\08-0.2534.hdf5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.25341 to 0.24568, saving model to ./model\\09-0.2457.hdf5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.24568 to 0.24108, saving model to ./model\\10-0.2411.hdf5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.24108 to 0.23725, saving model to ./model\\11-0.2373.hdf5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.23725 to 0.23419, saving model to ./model\\12-0.2342.hdf5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.23419 to 0.23102, saving model to ./model\\13-0.2310.hdf5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.23102 to 0.22806, saving model to ./model\\14-0.2281.hdf5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.22806 to 0.22508, saving model to ./model\\15-0.2251.hdf5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.22508 to 0.22336, saving model to ./model\\16-0.2234.hdf5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.22336 to 0.22209, saving model to ./model\\17-0.2221.hdf5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.22209 to 0.22021, saving model to ./model\\18-0.2202.hdf5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.22021 to 0.21788, saving model to ./model\\19-0.2179.hdf5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.21788 to 0.21611, saving model to ./model\\20-0.2161.hdf5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.21611 to 0.21409, saving model to ./model\\21-0.2141.hdf5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.21409 to 0.21258, saving model to ./model\\22-0.2126.hdf5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.21258 to 0.21077, saving model to ./model\\23-0.2108.hdf5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.21077 to 0.20947, saving model to ./model\\24-0.2095.hdf5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.20947 to 0.20799, saving model to ./model\\25-0.2080.hdf5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.20799 to 0.20659, saving model to ./model\\26-0.2066.hdf5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.20659 to 0.20510, saving model to ./model\\27-0.2051.hdf5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.20510 to 0.20357, saving model to ./model\\28-0.2036.hdf5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.20357 to 0.20238, saving model to ./model\\29-0.2024.hdf5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.20238 to 0.20129, saving model to ./model\\30-0.2013.hdf5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.20129 to 0.19959, saving model to ./model\\31-0.1996.hdf5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.19959 to 0.19820, saving model to ./model\\32-0.1982.hdf5\n",
      "\n",
      "Epoch 33: val_loss improved from 0.19820 to 0.19708, saving model to ./model\\33-0.1971.hdf5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.19708 to 0.19586, saving model to ./model\\34-0.1959.hdf5\n",
      "\n",
      "Epoch 35: val_loss improved from 0.19586 to 0.19453, saving model to ./model\\35-0.1945.hdf5\n",
      "\n",
      "Epoch 36: val_loss improved from 0.19453 to 0.19302, saving model to ./model\\36-0.1930.hdf5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.19302 to 0.19200, saving model to ./model\\37-0.1920.hdf5\n",
      "\n",
      "Epoch 38: val_loss improved from 0.19200 to 0.19056, saving model to ./model\\38-0.1906.hdf5\n",
      "\n",
      "Epoch 39: val_loss improved from 0.19056 to 0.18904, saving model to ./model\\39-0.1890.hdf5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.18904 to 0.18858, saving model to ./model\\40-0.1886.hdf5\n",
      "\n",
      "Epoch 41: val_loss improved from 0.18858 to 0.18744, saving model to ./model\\41-0.1874.hdf5\n",
      "\n",
      "Epoch 42: val_loss improved from 0.18744 to 0.18609, saving model to ./model\\42-0.1861.hdf5\n",
      "\n",
      "Epoch 43: val_loss improved from 0.18609 to 0.18503, saving model to ./model\\43-0.1850.hdf5\n",
      "\n",
      "Epoch 44: val_loss improved from 0.18503 to 0.18348, saving model to ./model\\44-0.1835.hdf5\n",
      "\n",
      "Epoch 45: val_loss improved from 0.18348 to 0.18246, saving model to ./model\\45-0.1825.hdf5\n",
      "\n",
      "Epoch 46: val_loss improved from 0.18246 to 0.18150, saving model to ./model\\46-0.1815.hdf5\n",
      "\n",
      "Epoch 47: val_loss improved from 0.18150 to 0.18022, saving model to ./model\\47-0.1802.hdf5\n",
      "\n",
      "Epoch 48: val_loss improved from 0.18022 to 0.17873, saving model to ./model\\48-0.1787.hdf5\n",
      "\n",
      "Epoch 49: val_loss improved from 0.17873 to 0.17802, saving model to ./model\\49-0.1780.hdf5\n",
      "\n",
      "Epoch 50: val_loss improved from 0.17802 to 0.17700, saving model to ./model\\50-0.1770.hdf5\n",
      "\n",
      "Epoch 51: val_loss improved from 0.17700 to 0.17503, saving model to ./model\\51-0.1750.hdf5\n",
      "\n",
      "Epoch 52: val_loss improved from 0.17503 to 0.17350, saving model to ./model\\52-0.1735.hdf5\n",
      "\n",
      "Epoch 53: val_loss improved from 0.17350 to 0.17283, saving model to ./model\\53-0.1728.hdf5\n",
      "\n",
      "Epoch 54: val_loss improved from 0.17283 to 0.17238, saving model to ./model\\54-0.1724.hdf5\n",
      "\n",
      "Epoch 55: val_loss improved from 0.17238 to 0.17043, saving model to ./model\\55-0.1704.hdf5\n",
      "\n",
      "Epoch 56: val_loss improved from 0.17043 to 0.16774, saving model to ./model\\56-0.1677.hdf5\n",
      "\n",
      "Epoch 57: val_loss improved from 0.16774 to 0.16649, saving model to ./model\\57-0.1665.hdf5\n",
      "\n",
      "Epoch 58: val_loss improved from 0.16649 to 0.16567, saving model to ./model\\58-0.1657.hdf5\n",
      "\n",
      "Epoch 59: val_loss improved from 0.16567 to 0.16387, saving model to ./model\\59-0.1639.hdf5\n",
      "\n",
      "Epoch 60: val_loss improved from 0.16387 to 0.16271, saving model to ./model\\60-0.1627.hdf5\n",
      "\n",
      "Epoch 61: val_loss improved from 0.16271 to 0.16108, saving model to ./model\\61-0.1611.hdf5\n",
      "\n",
      "Epoch 62: val_loss improved from 0.16108 to 0.16047, saving model to ./model\\62-0.1605.hdf5\n",
      "\n",
      "Epoch 63: val_loss improved from 0.16047 to 0.15725, saving model to ./model\\63-0.1572.hdf5\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.15725\n",
      "\n",
      "Epoch 65: val_loss improved from 0.15725 to 0.15378, saving model to ./model\\65-0.1538.hdf5\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.15378\n",
      "\n",
      "Epoch 67: val_loss improved from 0.15378 to 0.15062, saving model to ./model\\67-0.1506.hdf5\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.15062\n",
      "\n",
      "Epoch 69: val_loss improved from 0.15062 to 0.14740, saving model to ./model\\69-0.1474.hdf5\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.14740\n",
      "\n",
      "Epoch 71: val_loss improved from 0.14740 to 0.14495, saving model to ./model\\71-0.1450.hdf5\n",
      "\n",
      "Epoch 72: val_loss improved from 0.14495 to 0.14318, saving model to ./model\\72-0.1432.hdf5\n",
      "\n",
      "Epoch 73: val_loss improved from 0.14318 to 0.14149, saving model to ./model\\73-0.1415.hdf5\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.14149\n",
      "\n",
      "Epoch 75: val_loss improved from 0.14149 to 0.13990, saving model to ./model\\75-0.1399.hdf5\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.13990\n",
      "\n",
      "Epoch 77: val_loss improved from 0.13990 to 0.13471, saving model to ./model\\77-0.1347.hdf5\n",
      "\n",
      "Epoch 78: val_loss improved from 0.13471 to 0.13384, saving model to ./model\\78-0.1338.hdf5\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.13384\n",
      "\n",
      "Epoch 80: val_loss improved from 0.13384 to 0.13224, saving model to ./model\\80-0.1322.hdf5\n",
      "\n",
      "Epoch 81: val_loss improved from 0.13224 to 0.12991, saving model to ./model\\81-0.1299.hdf5\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.12991\n",
      "\n",
      "Epoch 83: val_loss improved from 0.12991 to 0.12790, saving model to ./model\\83-0.1279.hdf5\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.12790\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.12790\n",
      "\n",
      "Epoch 86: val_loss improved from 0.12790 to 0.12363, saving model to ./model\\86-0.1236.hdf5\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.12363\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.12363\n",
      "\n",
      "Epoch 89: val_loss improved from 0.12363 to 0.12180, saving model to ./model\\89-0.1218.hdf5\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.12180\n",
      "\n",
      "Epoch 91: val_loss improved from 0.12180 to 0.11854, saving model to ./model\\91-0.1185.hdf5\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.11854\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.11854\n",
      "\n",
      "Epoch 94: val_loss improved from 0.11854 to 0.11752, saving model to ./model\\94-0.1175.hdf5\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.11752\n",
      "\n",
      "Epoch 96: val_loss improved from 0.11752 to 0.11475, saving model to ./model\\96-0.1147.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97: val_loss improved from 0.11475 to 0.11301, saving model to ./model\\97-0.1130.hdf5\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.11301\n",
      "\n",
      "Epoch 99: val_loss improved from 0.11301 to 0.11272, saving model to ./model\\99-0.1127.hdf5\n",
      "\n",
      "Epoch 100: val_loss improved from 0.11272 to 0.11063, saving model to ./model\\100-0.1106.hdf5\n",
      "\n",
      "Epoch 101: val_loss improved from 0.11063 to 0.10984, saving model to ./model\\101-0.1098.hdf5\n",
      "\n",
      "Epoch 102: val_loss improved from 0.10984 to 0.10950, saving model to ./model\\102-0.1095.hdf5\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.10950\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.10950\n",
      "\n",
      "Epoch 105: val_loss improved from 0.10950 to 0.10627, saving model to ./model\\105-0.1063.hdf5\n",
      "\n",
      "Epoch 106: val_loss improved from 0.10627 to 0.10598, saving model to ./model\\106-0.1060.hdf5\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.10598\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.10598\n",
      "\n",
      "Epoch 109: val_loss improved from 0.10598 to 0.10388, saving model to ./model\\109-0.1039.hdf5\n",
      "\n",
      "Epoch 110: val_loss improved from 0.10388 to 0.10272, saving model to ./model\\110-0.1027.hdf5\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.10272\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.10272\n",
      "\n",
      "Epoch 113: val_loss improved from 0.10272 to 0.10113, saving model to ./model\\113-0.1011.hdf5\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.10113\n",
      "\n",
      "Epoch 115: val_loss improved from 0.10113 to 0.10101, saving model to ./model\\115-0.1010.hdf5\n",
      "\n",
      "Epoch 116: val_loss improved from 0.10101 to 0.09848, saving model to ./model\\116-0.0985.hdf5\n",
      "\n",
      "Epoch 117: val_loss improved from 0.09848 to 0.09727, saving model to ./model\\117-0.0973.hdf5\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.09727\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.09727\n",
      "\n",
      "Epoch 120: val_loss improved from 0.09727 to 0.09706, saving model to ./model\\120-0.0971.hdf5\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.09706\n",
      "\n",
      "Epoch 122: val_loss improved from 0.09706 to 0.09469, saving model to ./model\\122-0.0947.hdf5\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.09469\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.09469\n",
      "\n",
      "Epoch 125: val_loss improved from 0.09469 to 0.09322, saving model to ./model\\125-0.0932.hdf5\n",
      "\n",
      "Epoch 126: val_loss improved from 0.09322 to 0.09266, saving model to ./model\\126-0.0927.hdf5\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.09266\n",
      "\n",
      "Epoch 128: val_loss improved from 0.09266 to 0.09111, saving model to ./model\\128-0.0911.hdf5\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.09111\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.09111\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.09111\n",
      "\n",
      "Epoch 132: val_loss improved from 0.09111 to 0.08989, saving model to ./model\\132-0.0899.hdf5\n",
      "\n",
      "Epoch 133: val_loss improved from 0.08989 to 0.08895, saving model to ./model\\133-0.0890.hdf5\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.08895\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.08895\n",
      "\n",
      "Epoch 136: val_loss improved from 0.08895 to 0.08871, saving model to ./model\\136-0.0887.hdf5\n",
      "\n",
      "Epoch 137: val_loss improved from 0.08871 to 0.08788, saving model to ./model\\137-0.0879.hdf5\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.08788\n",
      "\n",
      "Epoch 139: val_loss improved from 0.08788 to 0.08531, saving model to ./model\\139-0.0853.hdf5\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.08531\n",
      "\n",
      "Epoch 141: val_loss improved from 0.08531 to 0.08478, saving model to ./model\\141-0.0848.hdf5\n",
      "\n",
      "Epoch 142: val_loss improved from 0.08478 to 0.08229, saving model to ./model\\142-0.0823.hdf5\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.08229\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.08229\n",
      "\n",
      "Epoch 145: val_loss improved from 0.08229 to 0.08185, saving model to ./model\\145-0.0819.hdf5\n",
      "\n",
      "Epoch 146: val_loss improved from 0.08185 to 0.08139, saving model to ./model\\146-0.0814.hdf5\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.08139\n",
      "\n",
      "Epoch 148: val_loss improved from 0.08139 to 0.08137, saving model to ./model\\148-0.0814.hdf5\n",
      "\n",
      "Epoch 149: val_loss improved from 0.08137 to 0.08037, saving model to ./model\\149-0.0804.hdf5\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.08037\n",
      "\n",
      "Epoch 151: val_loss improved from 0.08037 to 0.08028, saving model to ./model\\151-0.0803.hdf5\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.08028\n",
      "\n",
      "Epoch 153: val_loss improved from 0.08028 to 0.07784, saving model to ./model\\153-0.0778.hdf5\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.07784\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.07784\n",
      "\n",
      "Epoch 156: val_loss improved from 0.07784 to 0.07778, saving model to ./model\\156-0.0778.hdf5\n",
      "\n",
      "Epoch 157: val_loss improved from 0.07778 to 0.07617, saving model to ./model\\157-0.0762.hdf5\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.07617\n",
      "\n",
      "Epoch 159: val_loss improved from 0.07617 to 0.07579, saving model to ./model\\159-0.0758.hdf5\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.07579\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.07579\n",
      "\n",
      "Epoch 162: val_loss improved from 0.07579 to 0.07539, saving model to ./model\\162-0.0754.hdf5\n",
      "\n",
      "Epoch 163: val_loss improved from 0.07539 to 0.07412, saving model to ./model\\163-0.0741.hdf5\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.07412\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.07412\n",
      "\n",
      "Epoch 166: val_loss improved from 0.07412 to 0.07353, saving model to ./model\\166-0.0735.hdf5\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.07353\n",
      "\n",
      "Epoch 168: val_loss improved from 0.07353 to 0.07301, saving model to ./model\\168-0.0730.hdf5\n",
      "\n",
      "Epoch 169: val_loss improved from 0.07301 to 0.07266, saving model to ./model\\169-0.0727.hdf5\n",
      "\n",
      "Epoch 170: val_loss improved from 0.07266 to 0.07262, saving model to ./model\\170-0.0726.hdf5\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.07262\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.07262\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.07262\n",
      "\n",
      "Epoch 174: val_loss improved from 0.07262 to 0.07142, saving model to ./model\\174-0.0714.hdf5\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.07142\n",
      "\n",
      "Epoch 176: val_loss improved from 0.07142 to 0.07028, saving model to ./model\\176-0.0703.hdf5\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.07028\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.07028\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.07028\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.07028\n",
      "\n",
      "Epoch 181: val_loss improved from 0.07028 to 0.07024, saving model to ./model\\181-0.0702.hdf5\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.07024\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.07024\n",
      "\n",
      "Epoch 184: val_loss improved from 0.07024 to 0.06847, saving model to ./model\\184-0.0685.hdf5\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.06847\n",
      "\n",
      "Epoch 186: val_loss improved from 0.06847 to 0.06790, saving model to ./model\\186-0.0679.hdf5\n",
      "\n",
      "Epoch 187: val_loss improved from 0.06790 to 0.06767, saving model to ./model\\187-0.0677.hdf5\n",
      "\n",
      "Epoch 188: val_loss improved from 0.06767 to 0.06729, saving model to ./model\\188-0.0673.hdf5\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.06729\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.06729\n",
      "\n",
      "Epoch 191: val_loss improved from 0.06729 to 0.06661, saving model to ./model\\191-0.0666.hdf5\n",
      "\n",
      "Epoch 192: val_loss improved from 0.06661 to 0.06637, saving model to ./model\\192-0.0664.hdf5\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.06637\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.06637\n",
      "\n",
      "Epoch 195: val_loss improved from 0.06637 to 0.06461, saving model to ./model\\195-0.0646.hdf5\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.06461\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.06461\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.06461\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.06461\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.06461\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.06461\n",
      "\n",
      "Epoch 202: val_loss improved from 0.06461 to 0.06453, saving model to ./model\\202-0.0645.hdf5\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.06453\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.06453\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.06453\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.06453\n",
      "\n",
      "Epoch 207: val_loss improved from 0.06453 to 0.06306, saving model to ./model\\207-0.0631.hdf5\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.06306\n",
      "\n",
      "Epoch 209: val_loss did not improve from 0.06306\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.06306\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.06306\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.06306\n",
      "\n",
      "Epoch 213: val_loss did not improve from 0.06306\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.06306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 215: val_loss improved from 0.06306 to 0.06204, saving model to ./model\\215-0.0620.hdf5\n",
      "\n",
      "Epoch 216: val_loss improved from 0.06204 to 0.06149, saving model to ./model\\216-0.0615.hdf5\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.06149\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.06149\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.06149\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.06149\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.06149\n",
      "\n",
      "Epoch 222: val_loss improved from 0.06149 to 0.06119, saving model to ./model\\222-0.0612.hdf5\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.06119\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.06119\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.06119\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.06119\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.06119\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.06119\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.06119\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.06119\n",
      "\n",
      "Epoch 231: val_loss improved from 0.06119 to 0.06097, saving model to ./model\\231-0.0610.hdf5\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.06097\n",
      "\n",
      "Epoch 233: val_loss improved from 0.06097 to 0.06031, saving model to ./model\\233-0.0603.hdf5\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.06031\n",
      "\n",
      "Epoch 235: val_loss improved from 0.06031 to 0.06002, saving model to ./model\\235-0.0600.hdf5\n",
      "\n",
      "Epoch 236: val_loss did not improve from 0.06002\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.06002\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.06002\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.06002\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.06002\n",
      "\n",
      "Epoch 241: val_loss improved from 0.06002 to 0.05953, saving model to ./model\\241-0.0595.hdf5\n",
      "\n",
      "Epoch 242: val_loss improved from 0.05953 to 0.05939, saving model to ./model\\242-0.0594.hdf5\n",
      "\n",
      "Epoch 243: val_loss did not improve from 0.05939\n",
      "\n",
      "Epoch 244: val_loss did not improve from 0.05939\n",
      "\n",
      "Epoch 245: val_loss improved from 0.05939 to 0.05928, saving model to ./model\\245-0.0593.hdf5\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.05928\n",
      "\n",
      "Epoch 247: val_loss did not improve from 0.05928\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.05928\n",
      "\n",
      "Epoch 249: val_loss improved from 0.05928 to 0.05903, saving model to ./model\\249-0.0590.hdf5\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.05903\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.05903\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.05903\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.05903\n",
      "\n",
      "Epoch 254: val_loss did not improve from 0.05903\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.05903\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.05903\n",
      "\n",
      "Epoch 257: val_loss improved from 0.05903 to 0.05800, saving model to ./model\\257-0.0580.hdf5\n",
      "\n",
      "Epoch 258: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 261: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.05800\n",
      "\n",
      "Epoch 269: val_loss improved from 0.05800 to 0.05606, saving model to ./model\\269-0.0561.hdf5\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 291: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 296: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 300: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.05606\n",
      "\n",
      "Epoch 304: val_loss improved from 0.05606 to 0.05604, saving model to ./model\\304-0.0560.hdf5\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 306: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 316: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 317: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.05604\n",
      "\n",
      "Epoch 320: val_loss improved from 0.05604 to 0.05453, saving model to ./model\\320-0.0545.hdf5\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 327: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.05453\n",
      "\n",
      "Epoch 346: val_loss improved from 0.05453 to 0.05329, saving model to ./model\\346-0.0533.hdf5\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.05329\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.05329\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.05329\n",
      "\n",
      "Epoch 350: val_loss did not improve from 0.05329\n",
      "\n",
      "Epoch 351: val_loss did not improve from 0.05329\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.05329\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.05329\n",
      "\n",
      "Epoch 354: val_loss did not improve from 0.05329\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.05329\n",
      "\n",
      "Epoch 356: val_loss improved from 0.05329 to 0.05321, saving model to ./model\\356-0.0532.hdf5\n",
      "\n",
      "Epoch 357: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.05321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 365: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.05321\n",
      "\n",
      "Epoch 373: val_loss improved from 0.05321 to 0.05316, saving model to ./model\\373-0.0532.hdf5\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 375: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 401: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 408: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.05316\n",
      "\n",
      "Epoch 422: val_loss improved from 0.05316 to 0.05262, saving model to ./model\\422-0.0526.hdf5\n",
      "\n",
      "Epoch 423: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 429: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 430: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 438: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 441: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.05262\n",
      "\n",
      "Epoch 443: val_loss improved from 0.05262 to 0.05217, saving model to ./model\\443-0.0522.hdf5\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 449: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 453: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 504: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 507: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 514: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 525: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.05217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 527: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 529: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 531: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 532: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 533: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 534: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 536: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 537: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 538: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 539: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 541: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 542: val_loss did not improve from 0.05217\n",
      "\n",
      "Epoch 543: val_loss did not improve from 0.05217\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, validation_split=0.2, \n",
    "                  epochs=3500, \n",
    "                  batch_size=500, verbose=0, \n",
    "                  callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7e97256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800 epoch에서 학습 조기 멈추고(earlystop) 모델 파일 저장됨.\n",
    "# 900 epoch까지 학습을 진행해봤지만 더이상 val_loss가 향상되지 않았음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b8daebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차값 저장|\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 정확도 저장\n",
    "y_acc = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7cb64fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x축을 지정하고 정확도를 파란색, 오차는 빨간색 선으로 표시\n",
    "x_len = np.arange(len(y_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e07ed340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9xUlEQVR4nO3de1xUdeL/8fcMCmiGeElAQbCFSvOaFyLrWylFZabuzdAtM8ts7WqaUl66bGKmrm1ZXhZrv7/yspX6bdW1bVG7qHlB3bLMtFWRVvBWkKhYzPn9cXYGBgaYQZgDzOv5eMwDOdfPfMA5bz6fz/kcm2EYhgAAACxit7oAAAAgsBFGAACApQgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWamR1AbzhcDj0n//8RxdffLFsNpvVxQEAAF4wDEM//vij2rZtK7u94vaPehFG/vOf/ygmJsbqYgAAgGo4cuSIoqOjK1xfL8LIxRdfLMl8M2FhYRaXBgAAeKOgoEAxMTGu63hF6kUYcXbNhIWFEUYAAKhnqhpiwQBWAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBShBEAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwlM9h5OOPP9bAgQPVtm1b2Ww2rVq1qsp9Nm7cqKuuukohISGKj4/Xm2++WY2iAgCAhsjnMFJYWKhu3bpp3rx5Xm1/8OBBDRgwQDfeeKN2796txx57TPfdd58++OADnwsLAAAanka+7nDrrbfq1ltv9Xr7+fPnq0OHDpo9e7YkqWPHjvr000/1xz/+USkpKb6eHgAANDC1PmZky5YtSk5OdluWkpKiLVu2VLhPUVGRCgoK3F4AAKBhqvUwkpubq4iICLdlERERKigo0NmzZz3uk56erubNm7teMTExtV1MAABgEZ+7afwhLS1N48aNc31fUFBAIAFQ63JypP37pYQEKTra+3W+HNPTcXJypM2bpZMnze9btZKuuaby7ffvl5o1kw4eNJddc435df9+qbBQ2rZNCg2VWrQwj9e0qbksKkoaONDcdvPmkn1Lv6fS53Ru5yyb0/ffS8eOSZdfXnK8v/1N2rdPatNGio8vKZNzf+f7quiYzvfeoYO0Y4d09KjUp4905oy5rfOcbdqY76t0OWpimfPcBw96Lq9krj99uqTuS7+H77+Xzp0rKbNze0/beVM+T0rXe69e5rEPHKj8ePHxnsvh6efoy+92Tar1MBIZGam8vDy3ZXl5eQoLC1OTJk087hMSEqKQkJDaLhpQ79XEBVJyvyhJvl0snetLX4gq+kD0dNHbvLnkw7T0B6ynC5Wni4fzIuu88HrazptlX30lvf12ybkeeEDq1s3cZv1682UY5rrBg6XY2KqP/+GH0qpVJfslJppldX4/bJhks7mft7SOHaWvv3Y/748/upelNJvN8/Kyfv/78sueesp8v8uWuZfZG56Oh/pn7Fhp0SJp1Cj/n9tmGL78ypXZ2WbTypUrNXjw4Aq3mThxotauXasvvvjCtWzYsGE6deqU1q1b59V5CgoK1Lx5c+Xn5yssLKy6xQXqLE9/PVf2l1irVtLnn0vTp5dcNEaPlu67r+QvyoEDzb+CS1/snRfdJUu8u9gMGyadPSutXOl5/eDB0kUXVXwxrWifLl2kH36QXn3Vt4segNplt0uHD9dcC4m312+fw8jp06d14MABSVKPHj00Z84c3XjjjWrZsqXat2+vtLQ0fffdd/rf//1fSeatvZ07d9bYsWN17733av369XrkkUe0Zs0ar++mIYygLijbmuDp36WDREXNymV5+ut569ZafzsA4NGGDdINN9TMsby9fvvcTbNjxw7deOONru+dYztGjBihN998U0ePHlV2drZrfYcOHbRmzRo9/vjjevnllxUdHa0///nP3NaLWlW6ZaFs14Pz36X71avqUy3dTG+zmcud4aF003jHjtLevRdWdoIIAKvY7ebnob9dUDeNv9AygrLKjjUo209fUbeC5H2/OgAEEput5seM1FrLCFAbyo6RqGzUd3Z25WGjKgQR1GU12U03ZIg5pmfJEsnhuPDj2WzmOKJrrzX/P27YIP3zn+7/p5KTpbAw8/+oN//Xhg83j+upjM4/HJznvfJK6fhx6ZJL3AcO18Qy5wDm6nw+DB9u1onzD6GKjuHczpvybdpUUiee6j0zs2Td4MFSXJzn4x0+bHYDl67bssc7fly67DLp9tutu5uGlhH4Vdm7MqSqWzJQdyQmmh9kn33meX1ystSvn+cPxMo+pG+5RSouLvmAlcpfiMp+iDsH4jq3HzJEuvlm9/P6eoHydAFwXgAvu0zq2VM6dMhskfP2+EVF5h1CZ896vkPIqVUrKSmpZNzR6tXSN994Pq9zWWGhGTYOHSoZ2BwXZy6Pj3e/2+nAgZLmd+eck3Fx0uLF0sKF7he2rl1LyuzcruwxnXJySo7nLH/p5c5yJSWVnLv0srJlvOiiknNJJeX2x0Wy7HspW15nPTjrvOx7Lv0+ytZ12e28LU9F77+ydRUdp3Td+it01NoAVisQRuoXT3MgdOggZWRICxZYW7aGouyFuqK/LJ2GDHH/y6lVK+mTT0ruZgkKktLTpYsvlnJz3S+ezgvqgAFS797m8bZvl9askUJCSo5X1Yet84N+2bKSYGK3SzNmSBMmlGxT+oO8qg9bXz6QvVUbx6zrAvE9wz8II6gVnlo2JPcuFF/nKGiohg8v36xc0V/env56ruwvMan8xaM6f5FZdRHi4gcEBsIIqq10y8aOHSUTWZWdFKqh6NFD+te/qu5TPX68fJ/y8OHSoEFmaMjKKmlWr6zvlQsxgEBBGEGFnLNleppquexMk3Vd2e4Hyb1bISqqpM/XyVO/urd9qhX1jwMAyiOMwM327WYA2bOn/g0W9TQCPT6eMAAAdR239gYoT2M6/vKXujmRVumQUbolw6pR3wAAaxBG6rnS4WPTpro9psM5DmPQoMpbNQgfABBYCCP1SNlWj7oQPirqQomLK7n7o7I5CgAAIIzUMRVNc25l8Cg9kVVFkyp54pyTAgCAyhBGLGR1S0dFUy2Xnt2R1gwAQG0jjPiZM4C8/741LR1DhkipqRVPnAUAgL8RRmqZ1QNMnWM6KpqumxACALAaYaQGle128fcD4ErPBkoXCwCgviCM1ICcHGnSJP+2ejhbPCTvHlIGAEBdRRipBudspqGhtfe8Fk/TnEsEDwBAw0MY8dFvfyu9807tHf+BB6TJkwkbAIDAQRjxUk6O9MgjNTsGxBk8JO5qAQAELsKIF2bNkiZMuLBjJCZK99xj/ttTVwshBAAQqAgjVXjkEemVV3zbxxk8Sj8AjtlIAQDwjDBSidtvl9as8X77gQOlKVMIHgAA+IIw4oFzfEhVQeSWW8x5PbjDBQCA6iOMlJGRId13X9XbzZx54eNIAAAAYcRNTo50//2VbzNkiPSnP9EKAgBATSGMlLJ/v/kU24oMGCCtWOG/8gAAEAjsVhegLklIkGw2z+seflhavdq/5QEAIBAQRkr54IPyy2w2c3zIn/7k//IAABAI6Kb5r5wcafRo924am03aupVbdQEAqE2BHUZycsyBIgkJ2r8/Wg6H+2rDkAoLrSkaAACBInC7aTIypNhYqV8/KTZWzf65SvYytREUZD4vBgAA1J7ADCPOPpn/NoVkOO7R1dMHurWMBAVJCxZwCy8AALUtMMPI/v2uIJKjdhqthXIoyG2TSZOkUaOsKBwAAIElMMNIQoKcfTL7lVAuiEhSerrZgAIAAGpXYIaR6Ghp4UIpKEgJ2i+bistt4nBIBw5YUDYAAAJMYIYRyeyDOXRI0RveUtrDP3rc5KKL/FwmAAACUOCGEclsIbnhBiUPCfe4mtt6AQCofYEdRv6r1BASF27rBQDAPwgjchtCIonbegEA8KfAnoG1lFGjpJQUc9BqfDxBBAAAfyGMlBIdTQgBAMDf6KYBAACWIowAAABLEUYAAIClCCMAAMBShBEAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEUk5OdKGDeZXAADgXwEfRjIypNhYqV8/82tGhtUlAgAgsAR0GMnJkUaPlhwO83uHQ3rgAVpIAADwp2qFkXnz5ikuLk6hoaFKTEzUtm3bKt1+7ty5uvzyy9WkSRPFxMTo8ccf17lz56pV4Jq0f39JEHEqLpYOHLCmPAAABCKfw8jy5cs1btw4TZs2TTt37lS3bt2UkpKiY8eOedx+yZIlmjRpkqZNm6a9e/cqIyNDy5cv11NPPXXBhb9QCQmSvUwNBAVJ8fHWlAcAgEDkcxiZM2eO7r//fo0cOVKdOnXS/Pnz1bRpUy1evNjj9ps3b1bfvn01bNgwxcXF6eabb1ZqamqVrSn+EB0tLVxoBhDJ/LpggbkcAAD4h09h5Pz588rKylJycnLJAex2JScna8uWLR73ueaaa5SVleUKH//+97+1du1a3XbbbRWep6ioSAUFBW6v2jJqlHTokHk3zaFD5vcAAMB/Gvmy8YkTJ1RcXKyIiAi35REREfr666897jNs2DCdOHFC1157rQzD0M8//6wxY8ZU2k2Tnp6uZ5991peiXZDoaFpDAACwSq3fTbNx40ZNnz5dr732mnbu3KkVK1ZozZo1ev755yvcJy0tTfn5+a7XkSNHaruYAADAIj61jLRu3VpBQUHKy8tzW56Xl6fIyEiP+0yZMkV33XWX7rvvPklSly5dVFhYqNGjR+vpp5+WvewIUkkhISEKCQnxpWgAAKCe8qllJDg4WD179lRmZqZrmcPhUGZmppKSkjzuc+bMmXKBI+i/I0YNw/C1vAAAoIHxqWVEksaNG6cRI0aoV69e6tOnj+bOnavCwkKNHDlSknT33XerXbt2Sk9PlyQNHDhQc+bMUY8ePZSYmKgDBw5oypQpGjhwoCuUAACAwOVzGBk6dKiOHz+uqVOnKjc3V927d9e6detcg1qzs7PdWkImT54sm82myZMn67vvvtMll1yigQMH6oUXXqi5dwEAAOotm1EP+koKCgrUvHlz5efnKywszOriAAAAL3h7/Q7oZ9MAAADrEUYAAIClCCMAAMBShBEAAGCpgA8jOTnmc2lycqwuCQAAgSmgw0hGhhQbK/XrZ37NyLC6RAAABJ6ADSM5OdLo0ZLDYX7vcEgPPEALCQAA/hawYeTll0uCiFNxsXTggDXlAQAgUAVkGMnJkWbPLr88KEiKj/d/eQAACGQBGUb275c8zTv7+ONSdLT/ywMAQCALyDCSkCCVeZCw7Hbp0UetKQ8AAIEsIMNIdLS0cKHZLSOZXxcupFUEAAAr+PzU3oZi1CgpJcUcsBofTxABAMAqARtGJDOAEEIAALBWQHbTAACAuoMwAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBShBEAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBShBEAAGCpRlYXAAAQeBwOh86fP291MXCBGjdurKCgoAs+DmEEAOBX58+f18GDB+VwOKwuCmpAeHi4IiMjZbPZqn0MwggAwG8Mw9DRo0cVFBSkmJgY2e2MFqivDMPQmTNndOzYMUlSVFRUtY9VrTAyb948vfTSS8rNzVW3bt30yiuvqE+fPhVu/8MPP+jpp5/WihUrdOrUKcXGxmru3Lm67bbbql1wAED98/PPP+vMmTNq27atmjZtanVxcIGaNGkiSTp27JjatGlT7S4bn8PI8uXLNW7cOM2fP1+JiYmaO3euUlJStG/fPrVp06bc9ufPn9dNN92kNm3a6N1331W7du10+PBhhYeHV6vAAID6q7i4WJIUHBxscUlQU5yh8qeffvJfGJkzZ47uv/9+jRw5UpI0f/58rVmzRosXL9akSZPKbb948WKdOnVKmzdvVuPGjSVJcXFx1SosAKBhuJDxBahbauJn6VNn3fnz55WVlaXk5OSSA9jtSk5O1pYtWzzu8/777yspKUljx45VRESEOnfurOnTp7vSMQAACGw+hZETJ06ouLhYERERbssjIiKUm5vrcZ9///vfevfdd1VcXKy1a9dqypQpmj17tv7whz9UeJ6ioiIVFBS4vQAAqM/i4uI0d+5c1/c2m02rVq2qcPtDhw7JZrNp9+7dVR5748aNstls+uGHHy64nFao9btpHA6H2rRpo4ULFyooKEg9e/bUd999p5deeknTpk3zuE96erqeffbZ2i4aAACWOXr0qFq0aGF1MeoEn1pGWrduraCgIOXl5bktz8vLU2RkpMd9oqKidNlll7kNaunYsaNyc3MrnPAmLS1N+fn5rteRI0d8KSYAAHVeZGSkQkJCrC5GneBTGAkODlbPnj2VmZnpWuZwOJSZmamkpCSP+/Tt21cHDhxwm9zmm2++UVRUVIWjqUNCQhQWFub2AgDATU6OtGGD+bWWLVy4UG3bti03UdugQYN077336ttvv9WgQYMUERGhZs2aqXfv3vrnP/9Z6THLdtNs27ZNPXr0UGhoqHr16qVdu3ZdUJnfe+89XXnllQoJCVFcXJxmz57ttv61115TQkKCQkNDFRERoV//+teude+++666dOmiJk2aqFWrVkpOTlZhYeEFlacyPs82M27cOC1atEh/+ctftHfvXj344IMqLCx03V1z9913Ky0tzbX9gw8+qFOnTunRRx/VN998ozVr1mj69OkaO3Zszb0LAEBgyciQYmOlfv3MrxkZtXq63/zmNzp58qQ2bNjgWnbq1CmtW7dOw4cP1+nTp3XbbbcpMzNTu3bt0i233KKBAwcqOzvbq+OfPn1at99+uzp16qSsrCw988wzGj9+fLXLm5WVpd/+9re688479cUXX+iZZ57RlClT9Oabb0qSduzYoUceeUTPPfec9u3bp3Xr1ul//ud/JJndR6mpqbr33nu1d+9ebdy4Ub/85S9lGEa1y1MloxpeeeUVo3379kZwcLDRp08f47PPPnOtu/76640RI0a4bb9582YjMTHRCAkJMS699FLjhRdeMH7++Wevz5efn29IMvLz86tTXABAHXH27Fnjq6++Ms6ePVv9gxw5Yhh2u2FIJa+gIHN5LRo0aJBx7733ur5fsGCB0bZtW6O4uNjj9ldeeaXxyiuvuL6PjY01/vjHP7q+l2SsXLnSdaxWrVq51cvrr79uSDJ27dpVZdk2bNhgSDK+//57wzAMY9iwYcZNN93kts2ECROMTp06GYZhGO+9954RFhZmFBQUlDtWVlaWIck4dOhQlec1jMp/pt5ev6s1D+9DDz2kw4cPq6ioSFu3blViYqJr3caNG13JyykpKUmfffaZzp07p2+//VZPPfVUjTxYBwAQgPbvl8o+16a4WDpwoFZPO3z4cL333nsqKiqSJL399tu68847Zbfbdfr0aY0fP14dO3ZUeHi4mjVrpr1793rdMrJ371517dpVoaGhrmUVDX/w9nh9+/Z1W9a3b1/t379fxcXFuummmxQbG6tLL71Ud911l95++22dOXNGktStWzf1799fXbp00W9+8xstWrRI33//fbXL4g0eCgAAqF8SEqSyz7QJCpLi42v1tAMHDpRhGFqzZo2OHDmiTz75RMOHD5ckjR8/XitXrtT06dP1ySefaPfu3erSpUudfTLxxRdfrJ07d2rp0qWKiorS1KlT1a1bN/3www8KCgrShx9+qL///e/q1KmTXnnlFV1++eU6ePBgrZWHMAIAqF+io6WFC80AIplfFywwl9ei0NBQ/fKXv9Tbb7+tpUuX6vLLL9dVV10lSdq0aZPuueceDRkyRF26dFFkZKQOHTrk9bE7duyozz//XOfOnXMt++yzz6pd1o4dO2rTpk1uyzZt2uR2d2ujRo2UnJysmTNn6vPPP9ehQ4e0fv16Sebg2r59++rZZ5/Vrl27FBwcrJUrV1a7PFXhqb0AgPpn1CgpJcXsmomPr/Ug4jR8+HDdfvvt+vLLL/W73/3OtTwhIUErVqzQwIEDZbPZNGXKlHJ33lRm2LBhevrpp3X//fcrLS1Nhw4d0qxZs6pdzieeeEK9e/fW888/r6FDh2rLli169dVX9dprr0mSVq9erX//+9/6n//5H7Vo0UJr166Vw+HQ5Zdfrq1btyozM1M333yz2rRpo61bt+r48ePq2LFjtctTFcIIAKB+io72Wwhx6tevn1q2bKl9+/Zp2LBhruVz5szRvffeq2uuuUatW7fWxIkTfZo9vFmzZvrb3/6mMWPGqEePHurUqZNefPFF/epXv6pWOa+66ir99a9/1dSpU/X8888rKipKzz33nO655x5JUnh4uFasWKFnnnlG586dU0JCgpYuXaorr7xSe/fu1ccff6y5c+eqoKBAsbGxmj17tm699dZqlcUbNsOozXt1akZBQYGaN2+u/Px85hwBgHrs3LlzOnjwoDp06OA2WBP1V2U/U2+v34wZAQAAliKMAABQx40ZM0bNmjXz+BozZozVxbtgjBkBAKCOe+655yqckbUhDF8gjAAAUMe1adNGbdq0sboYtYZuGgAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADUQz/99JPVRagxhBEAQL2UkyNt2GB+9Yd169bp2muvVXh4uFq1aqXbb79d3377bany5Cg1NVUtW7bURRddpF69emnr1q2u9X/729/Uu3dvhYaGqnXr1hoyZIhrnc1m06pVq9zOFx4erjfffFOSdOjQIdlsNi1fvlzXX3+9QkND9fbbb+vkyZNKTU1Vu3bt1LRpU3Xp0kVLly51O47D4dDMmTMVHx+vkJAQtW/fXi+88IIk8ynEDz30kNv2x48fV3BwsDIzM2ui2rxCGAEA1DsZGVJsrNSvn/k1I6P2z1lYWKhx48Zpx44dyszMlN1u15AhQ+RwOHT69Gldf/31+u677/T+++/rX//6l5588kk5HA5J0po1azRkyBDddttt2rVrlzIzM9WnTx+fyzBp0iQ9+uij2rt3r1JSUnTu3Dn17NlTa9as0Z49ezR69Gjddddd2rZtm2uftLQ0zZgxQ1OmTNFXX32lJUuWKCIiQpJ03333acmSJSoqKnJt/9Zbb6ldu3bq16/fBdaYD4x6ID8/35Bk5OfnW10UAMAFOHv2rPHVV18ZZ8+erfYxjhwxDLvdMKSSV1CQudyfjh8/bkgyvvjiC2PBggXGxRdfbJw8edLjtklJScbw4cMrPJYkY+XKlW7LmjdvbrzxxhuGYRjGwYMHDUnG3LlzqyzXgAEDjCeeeMIwDMMoKCgwQkJCjEWLFnnc9uzZs0aLFi2M5cuXu5Z17drVeOaZZ6o8T+ljVPQz9fb6TcsIAKBe2b9f+m+Dg0txsXTgQG2fd79SU1N16aWXKiwsTHFxcZKk7Oxs7d69Wz169FDLli097rt7927179//gsvQq1cvt++Li4v1/PPPq0uXLmrZsqWaNWumDz74QNnZ2ZKkvXv3qqioqMJzh4aG6q677tLixYslSTt37tSePXt0zz33XHBZfcGD8gAA9UpCgmS3uweSoCApPr52zztw4EDFxsZq0aJFatu2rRwOhzp37qzz58+rSZMmle5b1XqbzSbDMNyWeRqgetFFF7l9/9JLL+nll1/W3Llz1aVLF1100UV67LHHdP78ea/OK5ldNd27d1dOTo7eeOMN9evXT7GxsVXuV5NoGQEA1CvR0dLChWYAkcyvCxaYy2vLyZMntW/fPk2ePFn9+/dXx44d9f3337vWd+3aVbt379apU6c87t+1a9dKB4RecsklOnr0qOv7/fv368yZM1WWa9OmTRo0aJB+97vfqVu3brr00kv1zTffuNYnJCSoSZMmlZ67S5cu6tWrlxYtWqQlS5bo3nvvrfK8NY2WEQBAvTNqlJSSYnbNxMfXbhCRpBYtWqhVq1ZauHChoqKilJ2drUmTJrnWp6amavr06Ro8eLDS09MVFRWlXbt2qW3btkpKStK0adPUv39//eIXv9Cdd96pn3/+WWvXrtXEiRMlmXe1vPrqq0pKSlJxcbEmTpyoxo0bV1muhIQEvfvuu9q8ebNatGihOXPmKC8vT506dZJkdsNMnDhRTz75pIKDg9W3b18dP35cX375pUaNGuU6zn333aeHHnpIF110kdtdPv5CywgAoF6KjpZuuKH2g4gk2e12LVu2TFlZWercubMef/xxvfTSS671wcHB+sc//qE2bdrotttuU5cuXTRjxgwF/bf55oYbbtA777yj999/X927d1e/fv3c7niZPXu2YmJidN1112nYsGEaP368mjZtWmW5Jk+erKuuukopKSm64YYbFBkZqcGDB7ttM2XKFD3xxBOaOnWqOnbsqKFDh+rYsWNu26SmpqpRo0ZKTU1VaGjoBdRU9diMsp1UdVBBQYGaN2+u/Px8hYWFWV0cAEA1nTt3TgcPHlSHDh0suejBs0OHDukXv/iFtm/frquuusqnfSv7mXp7/aabBgCAAPXTTz/p5MmTmjx5sq6++mqfg0hNoZsGAIAAtWnTJkVFRWn79u2aP3++ZeWgZQQAgAB1ww03lLul2Aq0jAAAAEsRRgAAgKUIIwAAv6sLXQOoGTXxsySMAAD8xjnvhnO6ctR/zplivZmkrSIMYAUA+E2jRo3UtGlTHT9+XI0bN5bdzt/E9ZVhGDpz5oyOHTum8PBwV9CsDsIIAMBvbDaboqKidPDgQR0+fNjq4qAGhIeHKzIy8oKOQRgBAPhVcHCwEhIS6KppABo3bnxBLSJOhBEAgN/Z7Xamg4cLnXU5OdKGDeZXAADgd4EdRjIypNhYqV8/82tGhtUlAgAg4ARuGMnJkUaPlhwO83uHQ3rgAVpIAADws8ANI/v3lwQRp+Ji6cABa8oDAECACtwwkpAglb2/PShIio+3pjwAAASowA0j0dHSwoVmAJHMrwsWmMsBAIDfBPatvaNGSSkpZtdMfDxBBAAACwR2GJHMAEIIAQDAMoHbTQMAAOoEwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALFWtMDJv3jzFxcUpNDRUiYmJ2rZtm1f7LVu2TDabTYMHD67OaQEAQAPkcxhZvny5xo0bp2nTpmnnzp3q1q2bUlJSdOzYsUr3O3TokMaPH6/rrruu2oUFAAANj89hZM6cObr//vs1cuRIderUSfPnz1fTpk21ePHiCvcpLi7W8OHD9eyzz+rSSy+9oAIDAICGxacwcv78eWVlZSk5ObnkAHa7kpOTtWXLlgr3e+6559SmTRuNGjXKq/MUFRWpoKDA7QUAABomn8LIiRMnVFxcrIiICLflERERys3N9bjPp59+qoyMDC1atMjr86Snp6t58+auV0xMjC/FBAAA9Uit3k3z448/6q677tKiRYvUunVrr/dLS0tTfn6+63XkyJFaLCUAALBSI182bt26tYKCgpSXl+e2PC8vT5GRkeW2//bbb3Xo0CENHDjQtczhcJgnbtRI+/bt0y9+8Yty+4WEhCgkJMSXogEAgHrKp5aR4OBg9ezZU5mZma5lDodDmZmZSkpKKrf9FVdcoS+++EK7d+92ve644w7deOON2r17N90vAADAt5YRSRo3bpxGjBihXr16qU+fPpo7d64KCws1cuRISdLdd9+tdu3aKT09XaGhoercubPb/uHh4ZJUbjkAAAhMPoeRoUOH6vjx45o6dapyc3PVvXt3rVu3zjWoNTs7W3Y7E7sCAADv2AzDMKwuRFUKCgrUvHlz5efnKywszOriAAAAL3h7/aYJAwAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcKIJOXkSBs2mF8BAIBfEUYyMqTYWKlfP/NrRobVJQIAIKAEdhjJyZFGj5b++yRhORzSAw/QQgIAgB8FdhjZv78kiDgVF0sHDlhTHgAAAlBgh5GEBKnsQ/2CgqT4eGvKAwBAAArsMBIdLS1caAYQyfy6YIG5HAAA+EUjqwtguVGjpJQUs2smPp4gAgCAnxFGJDOAEEIAALBEYHfTAAAAyxFGnJj4DAAASxBGJCY+AwDAQoQRJj4DAMBShBEmPgMAwFKEESY+AwDAUoQRJj4DAMBSzDMiMfEZAAAWIow4MfEZAACWoJumNOYaAQDA7wgjTsw1AgCAJQgjEnONAABgIcKIxFwjAABYiDAiMdcIAAAWIoxIzDUCAICFuLXXadQoqWtX6dNPpWuvlXr3trpEAAAEBMKIU0ZGySBWu91sKRk1yupSAQDQ4NFNI3E3DQAAFiKMSNxNAwCAhQgjEnfTAABgIcKIVP5uGrtdSk/nbhoAAPyAMOI0apQ0Y4YZRBwOadIkpoQHAMAPCCNOOTnSxIkMYgUAwM8II04MYgUAwBKEESdPg1jtdgaxAgBQywgjTs5BrDZbyTLDkD74wLoyAQAQAAgjpaWklA8jjBsBAKBWEUZKY9wIAAB+RxgpzdO4EUn65z/9XxYAAAIEYaS06GhzrpGyXnhBmjXL/+UBACAAEEbK6tXL8/Inn2TsCAAAtYAwUlZCgvsgVifDkF5+2f/lAQCggSOMlBUdLb34oud1s2bROgIAQA0jjHgyYYI0fLjndWlp/i0LAAANHGGkInfc4Xn5W29Jv/sdLSQAANQQwkhFrrmm4nVvvy3FxEhPP+2/8gAA0EARRioSHS3NnFn5NtOnS7ff7p/yAADQQBFGKjNhQtWtH2vWSL/8Jd02AABUE2GkKn/4Q9WBZOVKs9uG59gAAOAzwog3/vAH6aWXqt5u4UIzlHizLQAAkEQY8d748dKRI9LVV1e97ZNPcscNAABeqlYYmTdvnuLi4hQaGqrExERt27atwm0XLVqk6667Ti1atFCLFi2UnJxc6fZ1WnS0tGWL9PDDVW/rvOOGrhsAACrlcxhZvny5xo0bp2nTpmnnzp3q1q2bUlJSdOzYMY/bb9y4UampqdqwYYO2bNmimJgY3Xzzzfruu+8uuPCW+dOfvO+KoesGAIBK2QzDMHzZITExUb1799arr74qSXI4HIqJidHDDz+sSZMmVbl/cXGxWrRooVdffVV33323V+csKChQ8+bNlZ+fr7CwMF+KW7tycswZWd96y7vthwyR7rzTnMMkOrp2ywYAgMW8vX771DJy/vx5ZWVlKTk5ueQAdruSk5O1ZcsWr45x5swZ/fTTT2rZsmWF2xQVFamgoMDtVSdFR0v/7/953+qxcqU0dCgTpgEAUIpPYeTEiRMqLi5WRESE2/KIiAjl5uZ6dYyJEyeqbdu2boGmrPT0dDVv3tz1iomJ8aWY/ucc3DpmjPf7TJ9uDoZlPAkAIMD59W6aGTNmaNmyZVq5cqVCQ0Mr3C4tLU35+fmu15EjR/xYymqKjpZef90MJb/7nXf7bN1qtpIMHy799a8EEwBAQPIpjLRu3VpBQUHKy8tzW56Xl6fIyMhK9501a5ZmzJihf/zjH+ratWul24aEhCgsLMztVW/42nUjSUuWlHTfMNAVABBgfAojwcHB6tmzpzIzM13LHA6HMjMzlZSUVOF+M2fO1PPPP69169apV69e1S9tfVK668Zm836/J580p5enpQQAECB87qYZN26cFi1apL/85S/au3evHnzwQRUWFmrkyJGSpLvvvltpaWmu7V988UVNmTJFixcvVlxcnHJzc5Wbm6vTp0/X3Luoq5xdN9nZZrjo0cO7/UoPdB0+nFACAGjQfA4jQ4cO1axZszR16lR1795du3fv1rp161yDWrOzs3X06FHX9q+//rrOnz+vX//614qKinK9Zs2aVXPvoq6LjpZ+8xtp507f76JZsoTJ0wAADZrP84xYoc7OM1JdOTnSCy9I8+f7vu/tt0tTp0q9e9d8uQAAqEG1Ms8IakjpO298uR1Yklavlvr0MVtaAABoAAgjViobSnwZ6Pruu+ZAV7puAAD1HGGkLig70NWbJwNL5kBXxpMAAOo5wkhd4hzoumWLtG2bNHCgd/s5H8ZHKAEA1EOEkbqqd2/p/fd9G1dCKAEA1EOEkbqu9LiSIUO828cZSpjNFQBQDxBG6ovoaGnFCt8CxpNPmq0qtJIAAOowwkh945xm3tuH8S1YILVvL02YQCgBANRJhJH6qPTD+Ly5HdgwpFmzpNhYKSOj9ssHAIAPCCP12fjxJbcDe9NS4nBI999PCwkAoE5hOviGZPt2c3bWqlxxhfTII1KrVtI115gtLQAA1DCmgw9EvXtLM2dWvd3XX0u//33Jk4Gd40lycqQNG2g5AQD4FWGkoZkwwfuxJE6zZpmDXNu3l/r1Y8ArAMCvCCMNkXMsyfjx3ocSwzBfzn8z4BUA4CeEkYYqOtpsIcnOlq6/vnrHcDiYzRUAUOsIIw1ddLS0caP09NPV27+42HxWDmNJAAC1hLtpAklOjrR6tfTgg77tZ7OZXTd2uzRjhtSrl5SQwF04AIBKcTcNyouONqeH//OffRvg6syrDoc5xbxzkCvPvgEA1ADCSCAaNcq3ydI8MQwzmMyaVbNlAwAEnEZWFwAWiY6WfvMb89WtmxksqtNjN2GCdP68FB9ffgK1nBxp82bz30yuBgCoAGNGYMrJMQeqHjggPfVU9Y8zeLB0883Sv/4lLVxYEnBsNmnRIrNVBgAQELy9fhNGUF5GhvkMm5r+1bDbpaVLaSUBgADBAFZUX+kxJdOnSwMH+jbgtSIOR8kU9MxfAgD4L1pG4B1nN87770tvvVVzx5050xx3AgBocOimQe2ZNav6A149GTlS6txZuu4682F/khl+9u9nPhMAqMcII6hdzpaSkyelv/xF+uyzmjluYqJ5Z86SJSUTrS1cKKWkcGcOANQzhBH41/bt0po10rlz0osv1vzxnbPAOs2cyUywAFDHeXv9Zp4R1IzevUu6WBISav5unLLHevLJkn8PGyYNGkSLCQDUU7SMoHY4u3Ekc86R9HTzbpraNn689OijhBIAqAPopkHdkpNjTqh20UVSYaG0YoX0yiu1d77SrSWS94NhGTgLADWGMIK6b9YsaeLE2m8xKT3exDlDbKtWUocO0unTJcEjI0MaPdosj3PgbEUzxhJaAKBKhBHUD6VbTA4dMu/O2bRJevvtmp8BtjIPPSS99pp7MAoKMstUNmx4G1oILAACHGEE9VvpSdaWLDEv/GXvqPGHxx6TLrvMbElxdvnExlYdWnxpZQk0hDQgYBBG0HA4W0/i483vSw+MnT7dvwGlf38pM7P88tdfN8uxb5/Upo00ZYrnwCJ5ni/F0wW6IV60CWkIFA3x/281EEYQGHJypJdflv74R6m42OrSVG7MGGnBAvfw9MAD5tdFi0paf554QoqIKBlPU/aiXfpDTqo/H3g5Od61Kl3oOepLfaDhInS7EEYQWJytJ//8p/9bS/zlhRekr74qmZ1WKum6stulGTNKJoKT3APL5s3meBxnd1NtX6g9hYING6R+/cpvu2GDdMMNvgeJsttzAUBt8vb30x+huybVcoAnjCBwlR0UK0lNmkg7dkghIeYF3d8DZOuamTOl1FT3D6GcHN9Ci3N7yf0W6qwsz606nj6k7XbzUQIffVRxS5Anpe/EcgaxSZOsuwCUrYuaPGdtXiz81T1Y11qsfC2PL0G3qtDtT1W1ovohwBNGgMp4GiAbyBITpa1byy8fNky68krp2DFzLEyLFubyDz+UVq70/vgvvGDuu2mTtHRp1fXtDCkHD5rfO8PO5s3SsmXen9vTBaCiEFXdbq+MDPcZh202s9vNGcCqcxF27lc22E2aZAZFTw+VbNbMvb6qCpIvvyzNmeN992B11bW7zyoqT0W/F82aSVdfXT5EL13quZ69aRm5kPda+uddemqCyt6nzWYuM4ySn/Vvf1v+fdVCgCeMAN7ydHux06ZN0ltvWVY0XKBbbpHuuMP89/ffS+vXex6A7MmwYdK115Zf3qqV1LSptG2bFBoqTZ5cvpXNbpfGjpXmzSv5sHce7/vvzWc49ekjnTljruvQoSRIZGd7N//ObbdJMTHmOCRPxo83LzgHD7q3di1b5v1Tt+126fDhqoNN2YujVNLK9tBD7u/FZjPrpVcvc/tmzaS//lWaPbukTA88IHXrZv77QroWSwcMZx2nppYPFmlp5bt3vbl7r/SDPEsHwvffLwnddrs0bpw5M7TkHgJ96V7t0MEMGAsXupfLGVKDgszfx/h48/fzjjuq1/pbwy04hBGgppR+QrFTq1ZSXJy0eLH54eD8cOvY0byjJtBbWtBw9O9vdjuUbR1zhrv16/3T5Vm2lS4+3rxA79hRchdb6WXvved98LxQVkw7UFteeskMsjWEMAL4S+lbj51jL5zfHz0qPf+8tHp1w/mwAtBw1XBXDU/tBfwlOtr9P27p76OjzSbb0g8OjIsrGVh7+HBJk7yzLzckpOTBgna7OR6hsNB90G1D+ksMQN1RXGz+MeXngca0jABWK9uy4s0yqWScS+muIrvd7BMvKJDWrHEf+HjTTQ371mcAF86bcUI+oJsGCCTeBhrn8rJjYKSScTCFhe6Deb//Xjp+XLrkEvfxAkVF0oABUlRU+TuT7HZz8Oi6dSWtPsOGmV9r4rZqm0361a/McQFlB/P16GHehQLAd4wZqRhhBKgnKhs/UzokObuskpLMr56+d95FULpbyxmWSh+/9LZJSeby7dvNlqGQEPcAdfy4+ayh2283l61eLeXmmncznD1bPqCVfWhjYqJ5bOcAZWd3WVXdZs4wdu21JbdFX8hHb+nzOo/bqpX5F62nO2VK363j6RijR0utW9Nq5unnWHqZL92j118vffyxf+uzRw/zMRmeBtDb7dLvf2/+H3jnnfK/w847eyZMqNEiEUYAoCZUFrAkz89NKt3CVDo8eTpm2f3KTtQXGSn17Fmy3BnYPLV6OY9dWUCLjCwJY5UFRWdZKmsdc4a7nj3N93n6dEmZPQW+Zs3M9WXHSf32t+Xry1k+T610hw9Lq1aVXFCTk6WwsPLLfvWrknKUbg101svRo+518sEH5m3FxcUlF+fUVM8/b+e+ISHm96V/ds46L9sKWTpcl12WleUejCv6Paro96X0OZ31VtHvYEW/w8zAWjnCCAA0IBV1IV7oMWrruKg2wggAALCUt9dvux/LBAAAUA5hBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgqWqFkXnz5ikuLk6hoaFKTEzUtm3bKt3+nXfe0RVXXKHQ0FB16dJFa9eurVZhAQBAw+NzGFm+fLnGjRunadOmaefOnerWrZtSUlJ07Ngxj9tv3rxZqampGjVqlHbt2qXBgwdr8ODB2rNnzwUXHgAA1H8+TwefmJio3r1769VXX5UkORwOxcTE6OGHH9akSZPKbT906FAVFhZq9erVrmVXX321unfvrvnz53t1TqaDBwCg/vH2+t3Il4OeP39eWVlZSktLcy2z2+1KTk7WFudTBMvYsmWLxo0b57YsJSVFq1atqvA8RUVFKioqcn2fn58vyXxTAACgfnBet6tq9/ApjJw4cULFxcWKiIhwWx4REaGvv/7a4z65ubket8/Nza3wPOnp6Xr22WfLLY+JifGluAAAoA748ccf1bx58wrX+xRG/CUtLc2tNcXhcOjUqVNq1aqVbDZbjZ2noKBAMTExOnLkCN0/F4i6rFnUZ82hLmsOdVlzAqUuDcPQjz/+qLZt21a6nU9hpHXr1goKClJeXp7b8ry8PEVGRnrcJzIy0qftJSkkJEQhISFuy8LDw30pqk/CwsIa9C+DP1GXNYv6rDnUZc2hLmtOINRlZS0iTj7dTRMcHKyePXsqMzPTtczhcCgzM1NJSUke90lKSnLbXpI+/PDDCrcHAACBxedumnHjxmnEiBHq1auX+vTpo7lz56qwsFAjR46UJN19991q166d0tPTJUmPPvqorr/+es2ePVsDBgzQsmXLtGPHDi1cuLBm3wkAAKiXfA4jQ4cO1fHjxzV16lTl5uaqe/fuWrdunWuQanZ2tuz2kgaXa665RkuWLNHkyZP11FNPKSEhQatWrVLnzp1r7l1UU0hIiKZNm1auSwi+oy5rFvVZc6jLmkNd1hzq0p3P84wAAADUJJ5NAwAALEUYAQAAliKMAAAASxFGAACApQI6jMybN09xcXEKDQ1VYmKitm3bZnWR6pyPP/5YAwcOVNu2bWWz2co9U8gwDE2dOlVRUVFq0qSJkpOTtX//frdtTp06peHDhyssLEzh4eEaNWqUTp8+7cd3UTekp6erd+/euvjii9WmTRsNHjxY+/btc9vm3LlzGjt2rFq1aqVmzZrpV7/6VblJA7OzszVgwAA1bdpUbdq00YQJE/Tzzz/7861Y7vXXX1fXrl1dE0YlJSXp73//u2s99Vh9M2bMkM1m02OPPeZaRn1655lnnpHNZnN7XXHFFa711GMljAC1bNkyIzg42Fi8eLHx5ZdfGvfff78RHh5u5OXlWV20OmXt2rXG008/baxYscKQZKxcudJt/YwZM4zmzZsbq1atMv71r38Zd9xxh9GhQwfj7Nmzrm1uueUWo1u3bsZnn31mfPLJJ0Z8fLyRmprq53divZSUFOONN94w9uzZY+zevdu47bbbjPbt2xunT592bTNmzBgjJibGyMzMNHbs2GFcffXVxjXXXONa//PPPxudO3c2kpOTjV27dhlr1641WrdubaSlpVnxlizz/vvvG2vWrDG++eYbY9++fcZTTz1lNG7c2NizZ49hGNRjdW3bts2Ii4szunbtajz66KOu5dSnd6ZNm2ZceeWVxtGjR12v48ePu9ZTjxUL2DDSp08fY+zYsa7vi4uLjbZt2xrp6ekWlqpuKxtGHA6HERkZabz00kuuZT/88IMREhJiLF261DAMw/jqq68MScb27dtd2/z97383bDab8d133/mt7HXRsWPHDEnGRx99ZBiGWXeNGzc23nnnHdc2e/fuNSQZW7ZsMQzDDId2u93Izc11bfP6668bYWFhRlFRkX/fQB3TokUL489//jP1WE0//vijkZCQYHz44YfG9ddf7woj1Kf3pk2bZnTr1s3jOuqxcgHZTXP+/HllZWUpOTnZtcxutys5OVlbtmyxsGT1y8GDB5Wbm+tWj82bN1diYqKrHrds2aLw8HD16tXLtU1ycrLsdru2bt3q9zLXJfn5+ZKkli1bSpKysrL0008/udXnFVdcofbt27vVZ5cuXdyehJ2SkqKCggJ9+eWXfix93VFcXKxly5apsLBQSUlJ1GM1jR07VgMGDHCrN4nfS1/t379fbdu21aWXXqrhw4crOztbEvVYlTr51N7aduLECRUXF7v9wCUpIiJCX3/9tUWlqn9yc3MlyWM9Otfl5uaqTZs2busbNWqkli1burYJRA6HQ4899pj69u3rmo04NzdXwcHB5R4KWbY+PdW3c10g+eKLL5SUlKRz586pWbNmWrlypTp16qTdu3dTjz5atmyZdu7cqe3bt5dbx++l9xITE/Xmm2/q8ssv19GjR/Xss8/quuuu0549e6jHKgRkGAGsNnbsWO3Zs0effvqp1UWpty6//HLt3r1b+fn5evfddzVixAh99NFHVher3jly5IgeffRRffjhhwoNDbW6OPXarbfe6vp3165dlZiYqNjYWP31r39VkyZNLCxZ3ReQ3TStW7dWUFBQuVHMeXl5ioyMtKhU9Y+zriqrx8jISB07dsxt/c8//6xTp04FbF0/9NBDWr16tTZs2KDo6GjX8sjISJ0/f14//PCD2/Zl69NTfTvXBZLg4GDFx8erZ8+eSk9PV7du3fTyyy9Tjz7KysrSsWPHdNVVV6lRo0Zq1KiRPvroI/3pT39So0aNFBERQX1WU3h4uC677DIdOHCA38sqBGQYCQ4OVs+ePZWZmela5nA4lJmZqaSkJAtLVr906NBBkZGRbvVYUFCgrVu3uuoxKSlJP/zwg7KyslzbrF+/Xg6HQ4mJiX4vs5UMw9BDDz2klStXav369erQoYPb+p49e6px48Zu9blv3z5lZ2e71ecXX3zhFvA+/PBDhYWFqVOnTv55I3WUw+FQUVER9eij/v3764svvtDu3btdr169emn48OGuf1Of1XP69Gl9++23ioqK4veyKlaPoLXKsmXLjJCQEOPNN980vvrqK2P06NFGeHi42yhmmCPsd+3aZezatcuQZMyZM8fYtWuXcfjwYcMwzFt7w8PDjf/7v/8zPv/8c2PQoEEeb+3t0aOHsXXrVuPTTz81EhISAvLW3gcffNBo3ry5sXHjRrdb/86cOePaZsyYMUb79u2N9evXGzt27DCSkpKMpKQk13rnrX8333yzsXv3bmPdunXGJZdcEhC3/pU2adIk46OPPjIOHjxofP7558akSZMMm81m/OMf/zAMg3q8UKXvpjEM6tNbTzzxhLFx40bj4MGDxqZNm4zk5GSjdevWxrFjxwzDoB4rE7BhxDAM45VXXjHat29vBAcHG3369DE+++wzq4tU52zYsMGQVO41YsQIwzDM23unTJliREREGCEhIUb//v2Nffv2uR3j5MmTRmpqqtGsWTMjLCzMGDlypPHjjz9a8G6s5akeJRlvvPGGa5uzZ88av//9740WLVoYTZs2NYYMGWIcPXrU7TiHDh0ybr31VqNJkyZG69atjSeeeML46aef/PxurHXvvfcasbGxRnBwsHHJJZcY/fv3dwURw6AeL1TZMEJ9emfo0KFGVFSUERwcbLRr184YOnSoceDAAdd66rFiNsMwDGvaZAAAAAJ0zAgAAKg7CCMAAMBShBEAAGApwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsNT/B+rbbUMWr/X6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_len, y_vloss, 'o', c='red', markersize=3, label='valid_loss')\n",
    "plt.plot(x_len, y_acc, 'o', c='blue', markersize=3, label='accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b011355",
   "metadata": {},
   "source": [
    "### [실습] wine_test.csv => evaluate 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e08de8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1497, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.059</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.57</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.047</td>\n",
       "      <td>17.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.055</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99394</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.031</td>\n",
       "      <td>27.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.39</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.20</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.098</td>\n",
       "      <td>30.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99892</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5      6        7     8     9     10  11  \\\n",
       "0  10.0  0.73  0.43  2.3  0.059  15.0   31.0  0.99660  3.15  0.57  11.0   5   \n",
       "1   8.2  0.68  0.30  2.1  0.047  17.0  138.0  0.99500  3.22  0.71  10.8   4   \n",
       "2   8.8  0.24  0.35  1.7  0.055  13.0   27.0  0.99394  3.14  0.59  11.3   7   \n",
       "3   7.0  0.24  0.34  1.4  0.031  27.0  107.0  0.99000  3.06  0.39  11.9   6   \n",
       "4   7.5  0.77  0.20  8.1  0.098  30.0   92.0  0.99892  3.20  0.58   9.2   5   \n",
       "\n",
       "   12  \n",
       "0   1  \n",
       "1   0  \n",
       "2   1  \n",
       "3   0  \n",
       "4   1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('dataset/wine_test.csv', header=None)\n",
    "\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aca6de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_test.values\n",
    "\n",
    "X_test = dataset[:, 0:12]\n",
    "y_test = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dacdc12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05253753811120987, 0.9879759550094604]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a47fe",
   "metadata": {},
   "source": [
    "# 저장된 모델을 불러와서 사용하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06afaad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1d0123faf80>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "model2 = keras.models.load_model(\"./model/320-0.0545.hdf5\")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd4fe746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0531088262796402, 0.9859719276428223]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26cf6ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9999999 ],\n",
       "       [0.7337909 ],\n",
       "       [0.9999829 ],\n",
       "       ...,\n",
       "       [0.00649935],\n",
       "       [0.9999569 ],\n",
       "       [0.00445369]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추론\n",
    "model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeed6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
